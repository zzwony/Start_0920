{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "315c0d4c-ff7c-47d4-85f4-11e0cccdc8a1",
   "metadata": {},
   "source": [
    "# < 간단한 몇 가지 >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef846d8-271b-48fc-825e-514483230182",
   "metadata": {},
   "source": [
    "## → array, list, dictionary로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e833074-49c8-4b7e-94d8-412a395250de",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>displ</th>\n",
       "      <th>year</th>\n",
       "      <th>cyl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.8</td>\n",
       "      <td>1999</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.8</td>\n",
       "      <td>1999</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.8</td>\n",
       "      <td>1999</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   displ  year  cyl\n",
       "1    1.8  1999    4\n",
       "2    1.8  1999    4\n",
       "3    2.0  2008    4\n",
       "4    2.0  2008    4\n",
       "5    2.8  1999    6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydataset\n",
    "mpg = pydataset.data('mpg')\n",
    "\n",
    "df = mpg.iloc[:5, 2:5]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0361ec8a-075e-4dd8-a4e0-60461c202b05",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.800e+00, 1.999e+03, 4.000e+00],\n",
       "       [1.800e+00, 1.999e+03, 4.000e+00],\n",
       "       [2.000e+00, 2.008e+03, 4.000e+00],\n",
       "       [2.000e+00, 2.008e+03, 4.000e+00],\n",
       "       [2.800e+00, 1.999e+03, 6.000e+00]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. df를 array로 바꾸기\n",
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2be0469-7a77-4387-85a3-5cc4035a4c02",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'displ': {1: 1.8, 2: 1.8, 3: 2.0, 4: 2.0, 5: 2.8},\n",
       " 'year': {1: 1999, 2: 1999, 3: 2008, 4: 2008, 5: 1999},\n",
       " 'cyl': {1: 4, 2: 4, 3: 4, 4: 4, 5: 6}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. df를 딕셔너리로 바꾸기\n",
    "df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b75d49-0e7e-4d83-8372-01cf53023b82",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.8, 1999.0, 4.0],\n",
       " [1.8, 1999.0, 4.0],\n",
       " [2.0, 2008.0, 4.0],\n",
       " [2.0, 2008.0, 4.0],\n",
       " [2.8, 1999.0, 6.0]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. df를 리스트로 바꾸기\n",
    "df.values.tolist() #리스트로 바꾸려면 데이터프레임일때는 X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd839ff-e71f-4025-ac7e-925239d460a2",
   "metadata": {},
   "source": [
    "## → 리스트를 가로 방향으로 한 줄 세우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ad8fefb-0019-48d2-800c-59efc5bd57d9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.8,\n",
       " 1999.0,\n",
       " 4.0,\n",
       " 1.8,\n",
       " 1999.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 2008.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 2008.0,\n",
       " 4.0,\n",
       " 2.8,\n",
       " 1999.0,\n",
       " 6.0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df를 하나의 리스트로 만들기(가로로 줄 세우기)\n",
    "li = []\n",
    "for i in df.values.tolist():    #정석 방식\n",
    "    for j in i:\n",
    "        li.append(j)\n",
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c3ede71-d029-4534-a211-d231dc8aab4d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.8,\n",
       " 1999.0,\n",
       " 4.0,\n",
       " 1.8,\n",
       " 1999.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 2008.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 2008.0,\n",
       " 4.0,\n",
       " 2.8,\n",
       " 1999.0,\n",
       " 6.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values.reshape(-1).tolist()   #같은방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a1e47b6-c3be-408d-97ed-a1454c74d574",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.8,\n",
       " 1999.0,\n",
       " 4.0,\n",
       " 1.8,\n",
       " 1999.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 2008.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 2008.0,\n",
       " 4.0,\n",
       " 2.8,\n",
       " 1999.0,\n",
       " 6.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values.flatten().tolist() #flatten() '평평하게 편다'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82677674-6777-4d5c-9e07-267ac7ff279d",
   "metadata": {},
   "source": [
    "## → map 이용하여 딕셔너리 이름 할당하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3faf51dd-9f7e-4cbc-b08e-92960a5a6407",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     label  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "145      2  \n",
       "146      2  \n",
       "147      2  \n",
       "148      2  \n",
       "149      2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "iris_data = iris['data']\n",
    "iris_label = iris['target']\n",
    "\n",
    "#데이터 프레임으로 변환하기\n",
    "iris_df = pd.DataFrame(data = iris_data, columns=iris['feature_names'])\n",
    "\n",
    "#새로운 칼럼 만들기.(label)\n",
    "iris_df['label'] = iris['target']\n",
    "\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2b17097-c4e9-4e22-a2a6-2cc2f77efced",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "         label  \n",
       "0       setosa  \n",
       "1       setosa  \n",
       "2       setosa  \n",
       "3       setosa  \n",
       "4       setosa  \n",
       "..         ...  \n",
       "145  virginica  \n",
       "146  virginica  \n",
       "147  virginica  \n",
       "148  virginica  \n",
       "149  virginica  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map을 사용하여 딕셔너리로 이름 할당하기.\n",
    "iris_df['label'] = iris_df['label'].map({0:'setosa', 1:'versicolior', 2:'virginica'})\n",
    "iris_df\n",
    "# iris_df['label'].map(label_mapping)도 같은 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f431c1dc-df08-4c4e-9b5e-03e0d011e247",
   "metadata": {},
   "source": [
    "## → array상태로 빈도수 세기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e92c4f7-4c04-4997-812d-522e4818153e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine \n",
    "\n",
    "wine = load_wine()\n",
    "\n",
    "features = X = wine['data']\n",
    "labels = y = wine['target']\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(dt_clf, features, labels, cv=4, scoring='accuracy')\n",
    "\n",
    "labels  #위에는 labels 데이터를 만들기 위함임. 상관X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c7732b1-ef75-4f10-972c-58a0ad11ace8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 59, 1: 71, 2: 48})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#가공 없이 바로 빈도수 세주기.(이 단어가 몇 번 나왔지?)\n",
    "import collections, numpy\n",
    "\n",
    "collections.Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f44a6cdc-4609-490e-9e96-f0baa938c221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    71\n",
       "0    59\n",
       "2    48\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#한번 가공해서 빈도수 세기\n",
    "pd.Series(labels).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a31636-3798-4df3-aa49-d06282834235",
   "metadata": {},
   "source": [
    "# < 사이킷런 >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a94190-7284-42ac-aace-fa8e271bf427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5084e1-a0ea-4a8f-90d7-835d8370707b",
   "metadata": {},
   "source": [
    "## □ 붓꽃 품종 예측하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3224408c-e8db-4d89-86e6-178dd6b76a53",
   "metadata": {},
   "source": [
    "### 1. 데이터 세트 분리 : train_test_split( )\n",
    ": 데이터를 학습 데이터와 테스트 데이터로 분리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d11bfcff-6089-40c2-92c4-720564a8af87",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'iris.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split  #분리\n",
    "\n",
    "iris = load_iris()\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "782f9deb-12f8-47de-9b22-38ec0d8b360b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris) \n",
    "#Bunch라고 출력되지만 사실은 딕셔너리와 같은것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47511ba2-8fa1-4f5b-889b-e299de967732",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.keys()\n",
    "iris.values()\n",
    "iris.items() #key와 values를 동시에 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "972ff1e1-2028-4dbf-93c8-4777d9513d86",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = iris['data']\n",
    "iris_data  #딕셔너리에서 특정 값을 찾는 것과 같은 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54a94aff-4b51-4187-bbf0-578324ed4a94",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_label = iris['target']\n",
    "iris_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e88cfb7b-8c3d-4e85-bca7-578df5c2eb62",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(iris_data, iris_label)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label)\n",
    "# _train은 학습용 데이터, _test은 테스트용 데이터를 나타낸다.\n",
    "# iris_data -> X값   iris_label -> y값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48e8733a-a3d3-42d6-b132-1fa3c27ea635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ac433d-08b4-4090-9ed9-30f5ca23529d",
   "metadata": {},
   "source": [
    "데이터의 갯수는 112개라는 이야기.\n",
    "\n",
    "칼럼.특질.피쳐는 4개이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99d619e-974c-437e-9ff7-8f6f8cfb4540",
   "metadata": {},
   "source": [
    "#### → 주요 Key의 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3438c1a5-4bd1-43bf-8f4a-089b218a9df2",
   "metadata": {},
   "source": [
    "```\n",
    "- data : X(피처)의 데이터 세트\n",
    "\n",
    "- target : 최종적으로 구하려는 결괏값\n",
    "           (분류 시에는 레이블 값, 회귀 시에는 숫자 결괏값 데이터 세트로 나타난다.)\n",
    "\n",
    "- target_names : 개별 y(레이블)의 이름, 분류하고자 하는 대상\n",
    "\n",
    "- feature_names : 피처의 이름\n",
    "\n",
    "- DESCR : describe의 약자로 데이터에 대한 설명\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfd88a8-9dc9-4c46-8152-5dd1958be181",
   "metadata": {},
   "source": [
    "#### → train_test_split() Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f095096f-b77a-4837-9c10-cf497a1c981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_test_split(arrays, test_size, train_size, random_state, shuffle, stratify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6e3c47-00a2-45d8-81f9-b530d95ad83d",
   "metadata": {},
   "source": [
    "```\n",
    "- arrays : 분할시킬 데이터를 입력\n",
    "\n",
    "- test_size : 테스트 데이터셋의 비율(float)이나 갯수(int) (default = 0.25)\n",
    "\n",
    "- train_size : 학습 데이터셋의 비율(float)이나 갯수(int) (default = test_size의 나머지)\n",
    "\n",
    "- random_state : 데이터 분할시 셔플이 이루어지는데 이를 위한 시드값 (int나 RandomState로 입력)\n",
    "\n",
    "- shuffle : 셔플여부설정 (default = True)\n",
    "\n",
    "- stratify : 지정한 Data의 비율을 유지한다. \n",
    "             예를 들어, Label Set인 Y가 25%의 0과 75%의 1로 이루어진 Binary Set일 때, \n",
    "             stratify=Y로 설정하면 나누어진 데이터셋들도 0과 1을 각각 25%, 75%로 유지한 채                분할된다.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c82bc85-c0ea-40c6-9107-0115240ff778",
   "metadata": {},
   "source": [
    "### 2. 모델 학습\n",
    ": 학습 데이터를 기반으로 ML 알고리즘을 적용해 모델을 학습시킵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831f6187-5cf9-496c-8150-11ba1e17d7fc",
   "metadata": {},
   "source": [
    "#### 1) DecisionTreeClassifier( ) \n",
    ": 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba6e74e7-06b8-4c36-8e15-16183047dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier()\n",
    "# DecisionTreeClassifier 객체 생성(아직 아무런 기능 없다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5624fe-a5a1-4c8e-a04b-1ce01a83ac13",
   "metadata": {},
   "source": [
    "#### 2) fit( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d867d5d8-2315-49e6-89ec-cbc58042b8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf.fit(X_train, y_train)\n",
    "#fitting 적합한다. 학습한다. 훈련한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bffd8f-ef9f-4986-a336-04a80f41b1dc",
   "metadata": {},
   "source": [
    "DecisionTreeClassifier 객체는 학습 데이터를 기반으로 학습이 완료됌.\n",
    "\n",
    "이제 이 객체의 predict()에 테스트 데이터를 이용하여 예측값을 반환함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c50d640d-b048-4fd3-b636-7627ae55aba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape  #38개가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43352bf9-6c96-4f44-8bb9-e9c176b2a2ca",
   "metadata": {},
   "source": [
    "### 3. 예측 수행 : predict( )\n",
    ": 학습된 ML 모델을 이용해 테스트 데이터의 분류(즉, 붓꽃 종류)를 예측합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2571735-c35c-42ef-a1d5-1b74a4af567d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 0, 2, 2, 1, 1, 0, 2, 2, 1, 0, 2, 0, 1, 2, 0, 2, 1,\n",
       "       1, 1, 2, 1, 1, 0, 1, 0, 2, 1, 0, 0, 2, 0, 0, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dt_clf.predict(X_test)\n",
    "y_pred  #예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61d46e93-90ab-4695-9468-7b7afb2407b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 2, 0, 0, 2, 2, 1, 1, 0, 2, 2, 1, 0, 2, 0, 1, 2, 0, 2, 2,\n",
       "       1, 1, 2, 1, 1, 0, 1, 0, 2, 1, 0, 0, 2, 0, 0, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test  #정답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a9def9c-91d3-4b25-ab23-8dec73b72f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred == y_test  # 둘 간 얼마나 일치한가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1cf1593e-e933-424d-b091-310efa14430b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred == y_test) #일치 갯수는 36개, 처음에는 38개였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ae05512-afe9-4759-93a1-d938b56617d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d3e6bc-0310-4131-8c50-98de05587922",
   "metadata": {},
   "source": [
    "위에 y_test 출력값을 보면 1,0 이런식으로 되어있는데\n",
    "\n",
    "이 숫자가 의미하는 바는 위에 어레이의 인덱스를 표현한 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15a9c53-63cc-4f6a-bf28-9ec79e27c2b2",
   "metadata": {},
   "source": [
    "### 4. 평가 : accuracy_score( )\n",
    ": 이렇게 예측된 결괏값과 테스트 데이터의 실제 결괏값을 비교해 ML 모델 성능을 평가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "767299a7-2897-43c9-869c-f81245ae195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score  #정확도를 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1da1c12-c4bb-4702-b53b-0a0b72b40308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d484354-d78b-40ae-8e27-0c9c5fb64f28",
   "metadata": {},
   "source": [
    "# < 데이터 전처리 >\n",
    "```\n",
    "< 이유 >\n",
    "\n",
    "- 결손값, 즉 NaN, Null 값은 허용되지 않습니다. (이러한 경우 pandas로 처리)\n",
    "- 문자열 값을 입력값으로 허용하지 않습니다. (그래서 0,1 이런식으로 표현함.)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac1fbdb-d806-486a-9554-17351252b400",
   "metadata": {},
   "source": [
    "## □ 레이블 인코딩: LabelEncoder\n",
    "- LabelEncoder를 객체로 생성 후 fit()과 transform()을 호출해 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5c5a39e-2969-4a96-a23e-3fcbfc62d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "942a623e-3f9b-49cd-99a0-35a3f86402d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = encoder.fit_transform(['TV', '냉장고', '전자레인지'])\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b3ccff-abb1-4eb9-a510-d0363d35dc56",
   "metadata": {},
   "source": [
    "## □ 원-핫 인코딩\n",
    "One-Hot Encoding / '한 개만 불이 들어와요'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d90b542-3ea5-4947-9c8f-ca7838865a4d",
   "metadata": {},
   "source": [
    "### 1) 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d315ff0-050f-405e-9a0c-00208955899b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "items = ['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeb9b52-ac39-4893-baa7-e86a6a8746f8",
   "metadata": {},
   "source": [
    "### 2) 2차원 데이터로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10982fd6-8be0-4280-9087-a4ea2d2f1089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['TV'],\n",
       "       ['냉장고'],\n",
       "       ['전자레인지'],\n",
       "       ['컴퓨터'],\n",
       "       ['선풍기'],\n",
       "       ['선풍기'],\n",
       "       ['믹서'],\n",
       "       ['믹서']], dtype='<U5')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = np.array(items).reshape(-1,1)\n",
    "# 한줄로 쭉 서있는게 아니라 세로로 한줄로 들어가야한다.(열이 1개)\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaad602-c412-41fd-9aad-c22f52278903",
   "metadata": {},
   "source": [
    "### 3) OneHotEncoder 클래스로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "076d385b-476a-479d-88d3-c826706bf40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8x6 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder()\n",
    "one_hot_labels = encoder.fit_transform(items)\n",
    "one_hot_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f3b60e-4f73-45ac-9a4e-42cb941a604f",
   "metadata": {},
   "source": [
    "Sparse -> 희소행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c07328-408a-42ee-81ba-c4b7618db6cd",
   "metadata": {},
   "source": [
    "### 4) toarray( )\n",
    ":희소행렬 형태를 밀집행렬로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c131cfa-d082-4707-bd20-006c158f9a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_labels.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d08168f-0f1a-457d-8ad2-d754cb0cb680",
   "metadata": {},
   "source": [
    "### ▶ 또 다른 방법 : get_dummies( )\n",
    ": array로 바꿀 필요 없이 API 사용하면 간단하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f03b8cab-b196-434e-ac69-8f4d8fc456f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>냉장고</th>\n",
       "      <th>믹서</th>\n",
       "      <th>선풍기</th>\n",
       "      <th>전자레인지</th>\n",
       "      <th>컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TV  냉장고  믹서  선풍기  전자레인지  컴퓨터\n",
       "0   1    0   0    0      0    0\n",
       "1   0    1   0    0      0    0\n",
       "2   0    0   0    0      1    0\n",
       "3   0    0   0    0      0    1\n",
       "4   0    0   0    1      0    0\n",
       "5   0    0   0    1      0    0\n",
       "6   0    0   1    0      0    0\n",
       "7   0    0   1    0      0    0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = ['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
    "pd.get_dummies(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b779e7fd-3eb3-484d-8c4f-ae84a750cb5d",
   "metadata": {},
   "source": [
    "# < 교차검증 >\n",
    "- Cross Validation\n",
    "- 크로스는 여러번 이라는 뜻\n",
    "- 교차검증은 여러번 검증한다는 것(여러 경로는 통해서 검증)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaaef40-77e8-4bfd-a0d2-122c5c9e1917",
   "metadata": {},
   "source": [
    "## ▶ KFlod(n_splits = )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a46a12d9-c189-4349-ba43-e927ddf75d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()                   # 파일부르기\n",
    "\n",
    "iris_data = iris.data                # data(정보)와 target(매치대상) 저장\n",
    "iris_label= iris.target\n",
    "\n",
    "dt_clf=DecisionTreeClassifier()      # 의사결정 트리 \n",
    "\n",
    "kfold = KFold(n_splits = 5)          # 5번 검증한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a68922c8-3c80-437e-9fc5-a2dc1f0ab4d8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "------------------------------\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149] [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "------------------------------\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149] [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "------------------------------\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149] [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "------------------------------\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119] [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "cv_accuracy = []\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(iris_data):\n",
    "    print(train_index, test_index)\n",
    "    print(\"---\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba41791-2862-4750-8972-45c090686b37",
   "metadata": {},
   "source": [
    "```\n",
    "2개중 첫번째 인덱스는 4개에 대한 인덱스(train_data)\n",
    "뒤에는 나머지 한개의 인덱스(test_data)\n",
    "이렇게 1덩어리가 5개로 쪼개져있다.\n",
    "----------------------------------------\n",
    "0,1,2가 있는데 0,1은 50개씩 있는데 2가 5개밖에 없으면 train이나 test에 편중되어서\n",
    "2가 없는 상태로 학습이 되어서 맞추지 못하는 상황이 생긴다.\n",
    "\n",
    "즉, 비율을 맞춰야 한다.\n",
    "\n",
    "0이 100개 1은 40개 2가 10로 편중된 데이터가 있다면 \n",
    "100,40,10개 각각 7:3비율로 7은 train으로 3은 test로 골고루 분산되게끔 만들어야한다.\n",
    "\n",
    "test_size = 0.3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fc39c3c-154d-4eb7-b856-437f2b1e5f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "개별 검증 정확도:  [1.0]\n",
      "개별 검증 정확도:  [1.0, 1.0]\n",
      "개별 검증 정확도:  [1.0, 1.0, 0.8333333333333334]\n",
      "개별 검증 정확도:  [1.0, 1.0, 0.8333333333333334, 0.9333333333333333]\n",
      "개별 검증 정확도:  [1.0, 1.0, 0.8333333333333334, 0.9333333333333333, 0.7666666666666667]\n",
      "평균 검증 정확도: 0.9066666666666666\n"
     ]
    }
   ],
   "source": [
    "iris_data = iris.data\n",
    "                # data(정보)와 target(매치대상) 저장\n",
    "iris_label= iris.target\n",
    "\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()      # 의사결정 트리 \n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "cv_accuracy = []\n",
    "\n",
    "# KFold객체의 split( ) 호출하면 폴드 별 학습용, 검증용 테스트의 인덱스를 반환한다. 이거 중요함.  \n",
    "for train_index, test_index  in kfold.split(iris_data): \n",
    "    \n",
    "    # print(train_index, test_index)\n",
    "    # print(\"---\"*10)\n",
    "    # kfold.split( )으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n",
    "    X_train, X_test = iris_data[train_index], iris_data[test_index]\n",
    "    y_train, y_test = iris_label[train_index], iris_label[test_index]\n",
    "\n",
    "    \n",
    "    dt_clf.fit(X_train , y_train)    \n",
    "    pred = dt_clf.predict(X_test)\n",
    "    \n",
    "   \n",
    "    accuracy = accuracy_score(y_test,pred)   \n",
    "    cv_accuracy.append(accuracy)\n",
    " \n",
    "    print(\"개별 검증 정확도: \", cv_accuracy)\n",
    "    \n",
    "print('평균 검증 정확도:', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92377f01-a852-4db4-80bf-d8c683e90a05",
   "metadata": {},
   "source": [
    "p102, 103 줄인 모습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d59163-1880-477d-8ae1-e375eac3ebc5",
   "metadata": {},
   "source": [
    "```\n",
    "<< 여기서 split가 중요한 이유 >>\n",
    "\n",
    "- split는 입력값이 데이터프레임이 들어간다.\n",
    "- 그럼 출력값은 똑같이 데이터프레임인가? 아니다. 데이터프레임 인덱스를 출력하게 된다.\n",
    "- 해당 인덱스를 넣으면 거기에 해당하는 값이 출력하게 되는데 \n",
    "  그 원리를 이용한게 저 부분이다.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f42ca1-212e-456a-a853-94f3358179c0",
   "metadata": {},
   "source": [
    "### → StratifiedKFold : 제대로 분배X일때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c69b3f0a-4192-4303-8ba9-ab832b5a84a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34\n",
      "  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  67  68  69\n",
      "  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87\n",
      "  88  89  90  91  92  93  94  95  96  97  98  99 116 117 118 119 120 121\n",
      " 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139\n",
      " 140 141 142 143 144 145 146 147 148 149]\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
      "\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  34\n",
      "  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52\n",
      "  53  54  55  56  57  58  59  60  61  62  63  64  65  66  83  84  85  86\n",
      "  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104\n",
      " 105 106 107 108 109 110 111 112 113 114 115 133 134 135 136 137 138 139\n",
      " 140 141 142 143 144 145 146 147 148 149]\n",
      "[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  50  51\n",
      "  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  71  72  73  74  75  76  77  78  79  80  81  82 100 101 102 103 104\n",
      " 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132]\n",
      "[ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris #데이터 불러오기\n",
    "from sklearn.tree import DecisionTreeClassifier  #정해주기\n",
    "from sklearn.metrics import accuracy_score #평가기준\n",
    "from sklearn.model_selection import StratifiedKFold #층화된 kfold를 가져온다.\n",
    "\n",
    "iris = load_iris()\n",
    "features = X = iris_data = iris.data\n",
    "labels = y = iris_label = iris.target\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "s_kfold = StratifiedKFold(n_splits = 3)\n",
    "cv_accuracy = []\n",
    "\n",
    "for train_index, test_index in s_kfold.split(features, labels): #비율 다 감안해서 쪼갠것\n",
    "    print(train_index)\n",
    "    print(test_index)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a064b04-f4ca-464a-bd56-8b13b6edd34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "개별 정확도:  0.98\n",
      "개별 정확도:  0.94\n",
      "개별 정확도:  0.96\n",
      "정확도 모음:  [0.98, 0.94, 0.96]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris #데이터 불러오기\n",
    "from sklearn.tree import DecisionTreeClassifier  #정해주기\n",
    "from sklearn.metrics import accuracy_score #평가기준\n",
    "from sklearn.model_selection import StratifiedKFold #층화된 kfold를 가져온다.\n",
    "\n",
    "iris = load_iris()\n",
    "features = X = iris_data = iris.data\n",
    "labels = y = iris_label = iris.target\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "s_kfold = StratifiedKFold(n_splits = 3)\n",
    "cv_accuracy = []\n",
    "\n",
    "for train_index, test_index in s_kfold.split(features, labels):\n",
    "\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, pred)  #이 두 개를 비교해서 정확도 보가\n",
    "    cv_accuracy.append(acc)\n",
    "    print(\"개별 정확도: \", acc)\n",
    "    \n",
    "print('정확도 모음: ', cv_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe4efe9c-8dc4-4bdc-92ba-244a2b92c064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_accuracy).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94b6d2f-db4a-4a4f-9460-69f77c3d2eb0",
   "metadata": {},
   "source": [
    "## ▶★ cross_val_score( ) : 이거 하나면 끝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82c4ea0d-f340-4406-a032-e0afcf3f653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate #교차검증 점수\n",
    "\n",
    "iris = load_iris()\n",
    "data = features = X = iris_data = iris.data\n",
    "label = labels = y = iris_label = iris.target\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b8fca84-5665-47d6-a66b-7f332a1c08e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98, 0.92, 0.96])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(dt_clf, data, label, scoring = 'accuracy', cv = 3) #3번 쪼개기\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77890a7f-9c81-4529-9f4b-33662c374c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9533"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9fb600-0244-4416-ba3e-52f901a7c6fe",
   "metadata": {},
   "source": [
    "# < GridSearchCV : 최적 추출 >\n",
    ": 최적 하이퍼 파라미터 추출하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689a77fc-d449-481d-8ca8-bdc33173fa92",
   "metadata": {},
   "source": [
    "## 0) 기능\n",
    "- refit = True은 최적의 하이퍼 파라미터를 찾아 재학습한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75a8481-a130-4795-b915-466951993b19",
   "metadata": {},
   "source": [
    "## 1) max_depth, min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9fc303a-192c-4488-ae0d-970e018213b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "443ed96b-f9c7-4b9a-b0f8-125a49c935da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [1, 2, 3], 'min_samples_split': [2, 3]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = iris.data\n",
    "iris_label= iris.target\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size = 0.2, \n",
    "                                                    random_state=121) \n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "grid_parameters = {'max_depth':[1,2,3],\n",
    "                  'min_samples_split': [2,3]}\n",
    "\n",
    "grid_tree = GridSearchCV(dt_clf, param_grid=grid_parameters, cv=3, refit=True)\n",
    "\n",
    "grid_tree.fit(X_train, y_train) #학습이 이루어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed25318-0a18-4a87-aee7-072f9f13dc11",
   "metadata": {},
   "source": [
    "### → cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8901cd8-3a12-47a5-b2ef-b351bbdc723e",
   "metadata": {},
   "source": [
    "```\n",
    "cv_results_는 GridSearchcv의 결과 세트로서 딕셔너리 형태로 key값과 리스트 형태인 value값을 가진다.\n",
    "\n",
    "cv_results_는 데이터프레임으로 변환해야 보기 편하다.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a81c2910-7936-44c8-a87c-b3fe03dff1d9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3.118048e-02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3.118048e-02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>2.041241e-02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>2.041241e-02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_min_samples_split                                    params  \\\n",
       "0                       2  {'max_depth': 1, 'min_samples_split': 2}   \n",
       "1                       3  {'max_depth': 1, 'min_samples_split': 3}   \n",
       "2                       2  {'max_depth': 2, 'min_samples_split': 2}   \n",
       "3                       3  {'max_depth': 2, 'min_samples_split': 3}   \n",
       "4                       2  {'max_depth': 3, 'min_samples_split': 2}   \n",
       "5                       3  {'max_depth': 3, 'min_samples_split': 3}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0              0.700                0.7               0.70         0.700000   \n",
       "1              0.700                0.7               0.70         0.700000   \n",
       "2              0.925                1.0               0.95         0.958333   \n",
       "3              0.925                1.0               0.95         0.958333   \n",
       "4              0.975                1.0               0.95         0.975000   \n",
       "5              0.975                1.0               0.95         0.975000   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0    1.110223e-16                5  \n",
       "1    1.110223e-16                5  \n",
       "2    3.118048e-02                3  \n",
       "3    3.118048e-02                3  \n",
       "4    2.041241e-02                1  \n",
       "5    2.041241e-02                1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(grid_tree.cv_results_).iloc[:,5:] \n",
    "#보기 좋게 데이터프레임으로 변경함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2193ba-1507-422c-ab7a-9ac433dbbb0d",
   "metadata": {},
   "source": [
    "## 2) best_params_, grid_tree.best_score_\n",
    ": 최적 파라미터, 최고 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28394cc7-098e-40d4-aff5-35270ca5103b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f040614b-5809-4889-942d-9c59d06ba2f5",
   "metadata": {},
   "source": [
    "\n",
    "grid_parameters = {'max_depth':[1,2,3], 'min_samples_split': [2,3]} 에서 \n",
    "\n",
    "격자로 곱해줘서 가장 좋은걸 찾아줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6a89f1e-3fcc-4254-88cb-6a66130cd6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08e2b0bb-f18b-4ec4-b153-6427d9759dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 0, 0, 1, 1, 1, 1, 2, 2, 1, 1, 0, 0, 2, 1, 0, 2, 0, 2, 2,\n",
       "       1, 1, 1, 1, 0, 0, 2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = grid_tree.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55f3bda4-7c42-4bf3-af8e-29fb4e0f6868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de961d6c-4199-4603-a8e6-bb1a97c0d49f",
   "metadata": {},
   "source": [
    "# < 피처 스케일링 >\n",
    "- feature scaling\n",
    "- 서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업\n",
    "- 대표적인 방법으로 1) 표준화 2) 정규화가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ee1f8e-eb01-4ae6-9426-c102496832cf",
   "metadata": {},
   "source": [
    "## → 표준화(Standardization)\n",
    ": 이상치(극단적으로 크거나 작은값)에 영향을 적게 받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79f84780-0c45-456b-a0aa-5a666fb26cd9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3\n",
       "0    5.1  3.5  1.4  0.2\n",
       "1    4.9  3.0  1.4  0.2\n",
       "2    4.7  3.2  1.3  0.2\n",
       "3    4.6  3.1  1.5  0.2\n",
       "4    5.0  3.6  1.4  0.2\n",
       "..   ...  ...  ...  ...\n",
       "145  6.7  3.0  5.2  2.3\n",
       "146  6.3  2.5  5.0  1.9\n",
       "147  6.5  3.0  5.2  2.0\n",
       "148  6.2  3.4  5.4  2.3\n",
       "149  5.9  3.0  5.1  1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = iris['data']\n",
    "iris_df = pd.DataFrame(iris)\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be1c6b42-6640-433b-8480-dbb6b9018ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize( )으로 함수 만들기\n",
    "def standardize(x):\n",
    "    return (x - x.mean()) / x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70c53b72-b00f-42f1-a8b1-cf7b998d208f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -1.457168e-15\n",
       "1   -1.638319e-15\n",
       "2   -1.292300e-15\n",
       "3   -5.543714e-16\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.apply(standardize).mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ebc3f4-593c-4378-bca2-fb0c8eee4098",
   "metadata": {},
   "source": [
    "평균이 0이 나오면 잘 나온것 \n",
    "\n",
    "e-16 이런식으로 나오면 0으로 나온것임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b102377-59ef-48ed-8110-20582a30fca0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ▶ StandardScaler() : 한 번에 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f252edfa-12cf-4de1-ae29-15c8dce45336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5cfad06-1857-4999-a588-67b62830c521",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.00681170e-01,  1.01900435e+00, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00, -1.31979479e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.38535265e+00,  3.28414053e-01, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.50652052e+00,  9.82172869e-02, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  1.24920112e+00, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-5.37177559e-01,  1.93979142e+00, -1.16971425e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-1.50652052e+00,  7.88807586e-01, -1.34022653e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.02184904e+00,  7.88807586e-01, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.74885626e+00, -3.62176246e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00,  9.82172869e-02, -1.28338910e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-5.37177559e-01,  1.47939788e+00, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.26418478e+00,  7.88807586e-01, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.26418478e+00, -1.31979479e-01, -1.34022653e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-1.87002413e+00, -1.31979479e-01, -1.51073881e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-5.25060772e-02,  2.16998818e+00, -1.45390138e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.73673948e-01,  3.09077525e+00, -1.28338910e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-5.37177559e-01,  1.93979142e+00, -1.39706395e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-9.00681170e-01,  1.01900435e+00, -1.34022653e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.73673948e-01,  1.70959465e+00, -1.16971425e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-9.00681170e-01,  1.70959465e+00, -1.28338910e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-5.37177559e-01,  7.88807586e-01, -1.16971425e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-9.00681170e-01,  1.47939788e+00, -1.28338910e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-1.50652052e+00,  1.24920112e+00, -1.56757623e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-9.00681170e-01,  5.58610819e-01, -1.16971425e+00,\n",
       "        -9.20547742e-01],\n",
       "       [-1.26418478e+00,  7.88807586e-01, -1.05603939e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00, -1.31979479e-01, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  7.88807586e-01, -1.22655167e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-7.79513300e-01,  1.01900435e+00, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-7.79513300e-01,  7.88807586e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.38535265e+00,  3.28414053e-01, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.26418478e+00,  9.82172869e-02, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-5.37177559e-01,  7.88807586e-01, -1.28338910e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-7.79513300e-01,  2.40018495e+00, -1.28338910e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-4.16009689e-01,  2.63038172e+00, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00,  9.82172869e-02, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  3.28414053e-01, -1.45390138e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-4.16009689e-01,  1.01900435e+00, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00,  1.24920112e+00, -1.34022653e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-1.74885626e+00, -1.31979479e-01, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-9.00681170e-01,  7.88807586e-01, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  1.01900435e+00, -1.39706395e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.62768839e+00, -1.74335684e+00, -1.39706395e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.74885626e+00,  3.28414053e-01, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  1.01900435e+00, -1.22655167e+00,\n",
       "        -7.88915558e-01],\n",
       "       [-9.00681170e-01,  1.70959465e+00, -1.05603939e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-1.26418478e+00, -1.31979479e-01, -1.34022653e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-9.00681170e-01,  1.70959465e+00, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.50652052e+00,  3.28414053e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-6.58345429e-01,  1.47939788e+00, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  5.58610819e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [ 1.40150837e+00,  3.28414053e-01,  5.35408562e-01,\n",
       "         2.64141916e-01],\n",
       "       [ 6.74501145e-01,  3.28414053e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.28034050e+00,  9.82172869e-02,  6.49083415e-01,\n",
       "         3.95774101e-01],\n",
       "       [-4.16009689e-01, -1.74335684e+00,  1.37546573e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 7.95669016e-01, -5.92373012e-01,  4.78571135e-01,\n",
       "         3.95774101e-01],\n",
       "       [-1.73673948e-01, -5.92373012e-01,  4.21733708e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 5.53333275e-01,  5.58610819e-01,  5.35408562e-01,\n",
       "         5.27406285e-01],\n",
       "       [-1.14301691e+00, -1.51316008e+00, -2.60315415e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 9.16836886e-01, -3.62176246e-01,  4.78571135e-01,\n",
       "         1.32509732e-01],\n",
       "       [-7.79513300e-01, -8.22569778e-01,  8.07091462e-02,\n",
       "         2.64141916e-01],\n",
       "       [-1.02184904e+00, -2.43394714e+00, -1.46640561e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 6.86617933e-02, -1.31979479e-01,  2.51221427e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.89829664e-01, -1.97355361e+00,  1.37546573e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 3.10997534e-01, -3.62176246e-01,  5.35408562e-01,\n",
       "         2.64141916e-01],\n",
       "       [-2.94841818e-01, -3.62176246e-01, -8.98031345e-02,\n",
       "         1.32509732e-01],\n",
       "       [ 1.03800476e+00,  9.82172869e-02,  3.64896281e-01,\n",
       "         2.64141916e-01],\n",
       "       [-2.94841818e-01, -1.31979479e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  1.94384000e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 4.32165405e-01, -1.97355361e+00,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [-2.94841818e-01, -1.28296331e+00,  8.07091462e-02,\n",
       "        -1.30754636e-01],\n",
       "       [ 6.86617933e-02,  3.28414053e-01,  5.92245988e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 3.10997534e-01, -5.92373012e-01,  1.37546573e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 5.53333275e-01, -1.28296331e+00,  6.49083415e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 3.10997534e-01, -5.92373012e-01,  5.35408562e-01,\n",
       "         8.77547895e-04],\n",
       "       [ 6.74501145e-01, -3.62176246e-01,  3.08058854e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 9.16836886e-01, -1.31979479e-01,  3.64896281e-01,\n",
       "         2.64141916e-01],\n",
       "       [ 1.15917263e+00, -5.92373012e-01,  5.92245988e-01,\n",
       "         2.64141916e-01],\n",
       "       [ 1.03800476e+00, -1.31979479e-01,  7.05920842e-01,\n",
       "         6.59038469e-01],\n",
       "       [ 1.89829664e-01, -3.62176246e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [-1.73673948e-01, -1.05276654e+00, -1.46640561e-01,\n",
       "        -2.62386821e-01],\n",
       "       [-4.16009689e-01, -1.51316008e+00,  2.38717193e-02,\n",
       "        -1.30754636e-01],\n",
       "       [-4.16009689e-01, -1.51316008e+00, -3.29657076e-02,\n",
       "        -2.62386821e-01],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  8.07091462e-02,\n",
       "         8.77547895e-04],\n",
       "       [ 1.89829664e-01, -8.22569778e-01,  7.62758269e-01,\n",
       "         5.27406285e-01],\n",
       "       [-5.37177559e-01, -1.31979479e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.89829664e-01,  7.88807586e-01,  4.21733708e-01,\n",
       "         5.27406285e-01],\n",
       "       [ 1.03800476e+00,  9.82172869e-02,  5.35408562e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 5.53333275e-01, -1.74335684e+00,  3.64896281e-01,\n",
       "         1.32509732e-01],\n",
       "       [-2.94841818e-01, -1.31979479e-01,  1.94384000e-01,\n",
       "         1.32509732e-01],\n",
       "       [-4.16009689e-01, -1.28296331e+00,  1.37546573e-01,\n",
       "         1.32509732e-01],\n",
       "       [-4.16009689e-01, -1.05276654e+00,  3.64896281e-01,\n",
       "         8.77547895e-04],\n",
       "       [ 3.10997534e-01, -1.31979479e-01,  4.78571135e-01,\n",
       "         2.64141916e-01],\n",
       "       [-5.25060772e-02, -1.05276654e+00,  1.37546573e-01,\n",
       "         8.77547895e-04],\n",
       "       [-1.02184904e+00, -1.74335684e+00, -2.60315415e-01,\n",
       "        -2.62386821e-01],\n",
       "       [-2.94841818e-01, -8.22569778e-01,  2.51221427e-01,\n",
       "         1.32509732e-01],\n",
       "       [-1.73673948e-01, -1.31979479e-01,  2.51221427e-01,\n",
       "         8.77547895e-04],\n",
       "       [-1.73673948e-01, -3.62176246e-01,  2.51221427e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 4.32165405e-01, -3.62176246e-01,  3.08058854e-01,\n",
       "         1.32509732e-01],\n",
       "       [-9.00681170e-01, -1.28296331e+00, -4.30827696e-01,\n",
       "        -1.30754636e-01],\n",
       "       [-1.73673948e-01, -5.92373012e-01,  1.94384000e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 5.53333275e-01,  5.58610819e-01,  1.27429511e+00,\n",
       "         1.71209594e+00],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  7.62758269e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 1.52267624e+00, -1.31979479e-01,  1.21745768e+00,\n",
       "         1.18556721e+00],\n",
       "       [ 5.53333275e-01, -3.62176246e-01,  1.04694540e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 7.95669016e-01, -1.31979479e-01,  1.16062026e+00,\n",
       "         1.31719939e+00],\n",
       "       [ 2.12851559e+00, -1.31979479e-01,  1.61531967e+00,\n",
       "         1.18556721e+00],\n",
       "       [-1.14301691e+00, -1.28296331e+00,  4.21733708e-01,\n",
       "         6.59038469e-01],\n",
       "       [ 1.76501198e+00, -3.62176246e-01,  1.44480739e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 1.03800476e+00, -1.28296331e+00,  1.16062026e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 1.64384411e+00,  1.24920112e+00,  1.33113254e+00,\n",
       "         1.71209594e+00],\n",
       "       [ 7.95669016e-01,  3.28414053e-01,  7.62758269e-01,\n",
       "         1.05393502e+00],\n",
       "       [ 6.74501145e-01, -8.22569778e-01,  8.76433123e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 1.15917263e+00, -1.31979479e-01,  9.90107977e-01,\n",
       "         1.18556721e+00],\n",
       "       [-1.73673948e-01, -1.28296331e+00,  7.05920842e-01,\n",
       "         1.05393502e+00],\n",
       "       [-5.25060772e-02, -5.92373012e-01,  7.62758269e-01,\n",
       "         1.58046376e+00],\n",
       "       [ 6.74501145e-01,  3.28414053e-01,  8.76433123e-01,\n",
       "         1.44883158e+00],\n",
       "       [ 7.95669016e-01, -1.31979479e-01,  9.90107977e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 2.24968346e+00,  1.70959465e+00,  1.67215710e+00,\n",
       "         1.31719939e+00],\n",
       "       [ 2.24968346e+00, -1.05276654e+00,  1.78583195e+00,\n",
       "         1.44883158e+00],\n",
       "       [ 1.89829664e-01, -1.97355361e+00,  7.05920842e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.28034050e+00,  3.28414053e-01,  1.10378283e+00,\n",
       "         1.44883158e+00],\n",
       "       [-2.94841818e-01, -5.92373012e-01,  6.49083415e-01,\n",
       "         1.05393502e+00],\n",
       "       [ 2.24968346e+00, -5.92373012e-01,  1.67215710e+00,\n",
       "         1.05393502e+00],\n",
       "       [ 5.53333275e-01, -8.22569778e-01,  6.49083415e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 1.03800476e+00,  5.58610819e-01,  1.10378283e+00,\n",
       "         1.18556721e+00],\n",
       "       [ 1.64384411e+00,  3.28414053e-01,  1.27429511e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 4.32165405e-01, -5.92373012e-01,  5.92245988e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 3.10997534e-01, -1.31979479e-01,  6.49083415e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 6.74501145e-01, -5.92373012e-01,  1.04694540e+00,\n",
       "         1.18556721e+00],\n",
       "       [ 1.64384411e+00, -1.31979479e-01,  1.16062026e+00,\n",
       "         5.27406285e-01],\n",
       "       [ 1.88617985e+00, -5.92373012e-01,  1.33113254e+00,\n",
       "         9.22302838e-01],\n",
       "       [ 2.49201920e+00,  1.70959465e+00,  1.50164482e+00,\n",
       "         1.05393502e+00],\n",
       "       [ 6.74501145e-01, -5.92373012e-01,  1.04694540e+00,\n",
       "         1.31719939e+00],\n",
       "       [ 5.53333275e-01, -5.92373012e-01,  7.62758269e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 3.10997534e-01, -1.05276654e+00,  1.04694540e+00,\n",
       "         2.64141916e-01],\n",
       "       [ 2.24968346e+00, -1.31979479e-01,  1.33113254e+00,\n",
       "         1.44883158e+00],\n",
       "       [ 5.53333275e-01,  7.88807586e-01,  1.04694540e+00,\n",
       "         1.58046376e+00],\n",
       "       [ 6.74501145e-01,  9.82172869e-02,  9.90107977e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 1.89829664e-01, -1.31979479e-01,  5.92245988e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 1.28034050e+00,  9.82172869e-02,  9.33270550e-01,\n",
       "         1.18556721e+00],\n",
       "       [ 1.03800476e+00,  9.82172869e-02,  1.04694540e+00,\n",
       "         1.58046376e+00],\n",
       "       [ 1.28034050e+00,  9.82172869e-02,  7.62758269e-01,\n",
       "         1.44883158e+00],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  7.62758269e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 1.15917263e+00,  3.28414053e-01,  1.21745768e+00,\n",
       "         1.44883158e+00],\n",
       "       [ 1.03800476e+00,  5.58610819e-01,  1.10378283e+00,\n",
       "         1.71209594e+00],\n",
       "       [ 1.03800476e+00, -1.31979479e-01,  8.19595696e-01,\n",
       "         1.44883158e+00],\n",
       "       [ 5.53333275e-01, -1.28296331e+00,  7.05920842e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 7.95669016e-01, -1.31979479e-01,  8.19595696e-01,\n",
       "         1.05393502e+00],\n",
       "       [ 4.32165405e-01,  7.88807586e-01,  9.33270550e-01,\n",
       "         1.44883158e+00],\n",
       "       [ 6.86617933e-02, -1.31979479e-01,  7.62758269e-01,\n",
       "         7.90670654e-01]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "iris_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775896f3-1bf5-41ca-9084-d2dec106b431",
   "metadata": {},
   "source": [
    "### ▶ MinMaxScaler() : 데이터값을 0,1로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7a40095-2f12-475c-8e05-dc44b0447d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba9055cc-ee10-4dae-936e-34b6c0bbfea3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.08333333, 0.45833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.66666667, 0.06779661, 0.04166667],\n",
       "       [0.30555556, 0.79166667, 0.11864407, 0.125     ],\n",
       "       [0.08333333, 0.58333333, 0.06779661, 0.08333333],\n",
       "       [0.19444444, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.02777778, 0.375     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
       "       [0.30555556, 0.70833333, 0.08474576, 0.04166667],\n",
       "       [0.13888889, 0.58333333, 0.10169492, 0.04166667],\n",
       "       [0.13888889, 0.41666667, 0.06779661, 0.        ],\n",
       "       [0.        , 0.41666667, 0.01694915, 0.        ],\n",
       "       [0.41666667, 0.83333333, 0.03389831, 0.04166667],\n",
       "       [0.38888889, 1.        , 0.08474576, 0.125     ],\n",
       "       [0.30555556, 0.79166667, 0.05084746, 0.125     ],\n",
       "       [0.22222222, 0.625     , 0.06779661, 0.08333333],\n",
       "       [0.38888889, 0.75      , 0.11864407, 0.08333333],\n",
       "       [0.22222222, 0.75      , 0.08474576, 0.08333333],\n",
       "       [0.30555556, 0.58333333, 0.11864407, 0.04166667],\n",
       "       [0.22222222, 0.70833333, 0.08474576, 0.125     ],\n",
       "       [0.08333333, 0.66666667, 0.        , 0.04166667],\n",
       "       [0.22222222, 0.54166667, 0.11864407, 0.16666667],\n",
       "       [0.13888889, 0.58333333, 0.15254237, 0.04166667],\n",
       "       [0.19444444, 0.41666667, 0.10169492, 0.04166667],\n",
       "       [0.19444444, 0.58333333, 0.10169492, 0.125     ],\n",
       "       [0.25      , 0.625     , 0.08474576, 0.04166667],\n",
       "       [0.25      , 0.58333333, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.10169492, 0.04166667],\n",
       "       [0.13888889, 0.45833333, 0.10169492, 0.04166667],\n",
       "       [0.30555556, 0.58333333, 0.08474576, 0.125     ],\n",
       "       [0.25      , 0.875     , 0.08474576, 0.        ],\n",
       "       [0.33333333, 0.91666667, 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.5       , 0.03389831, 0.04166667],\n",
       "       [0.33333333, 0.625     , 0.05084746, 0.04166667],\n",
       "       [0.16666667, 0.66666667, 0.06779661, 0.        ],\n",
       "       [0.02777778, 0.41666667, 0.05084746, 0.04166667],\n",
       "       [0.22222222, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.625     , 0.05084746, 0.08333333],\n",
       "       [0.05555556, 0.125     , 0.05084746, 0.08333333],\n",
       "       [0.02777778, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.19444444, 0.625     , 0.10169492, 0.20833333],\n",
       "       [0.22222222, 0.75      , 0.15254237, 0.125     ],\n",
       "       [0.13888889, 0.41666667, 0.06779661, 0.08333333],\n",
       "       [0.22222222, 0.75      , 0.10169492, 0.04166667],\n",
       "       [0.08333333, 0.5       , 0.06779661, 0.04166667],\n",
       "       [0.27777778, 0.70833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.54166667, 0.06779661, 0.04166667],\n",
       "       [0.75      , 0.5       , 0.62711864, 0.54166667],\n",
       "       [0.58333333, 0.5       , 0.59322034, 0.58333333],\n",
       "       [0.72222222, 0.45833333, 0.66101695, 0.58333333],\n",
       "       [0.33333333, 0.125     , 0.50847458, 0.5       ],\n",
       "       [0.61111111, 0.33333333, 0.61016949, 0.58333333],\n",
       "       [0.38888889, 0.33333333, 0.59322034, 0.5       ],\n",
       "       [0.55555556, 0.54166667, 0.62711864, 0.625     ],\n",
       "       [0.16666667, 0.16666667, 0.38983051, 0.375     ],\n",
       "       [0.63888889, 0.375     , 0.61016949, 0.5       ],\n",
       "       [0.25      , 0.29166667, 0.49152542, 0.54166667],\n",
       "       [0.19444444, 0.        , 0.42372881, 0.375     ],\n",
       "       [0.44444444, 0.41666667, 0.54237288, 0.58333333],\n",
       "       [0.47222222, 0.08333333, 0.50847458, 0.375     ],\n",
       "       [0.5       , 0.375     , 0.62711864, 0.54166667],\n",
       "       [0.36111111, 0.375     , 0.44067797, 0.5       ],\n",
       "       [0.66666667, 0.45833333, 0.57627119, 0.54166667],\n",
       "       [0.36111111, 0.41666667, 0.59322034, 0.58333333],\n",
       "       [0.41666667, 0.29166667, 0.52542373, 0.375     ],\n",
       "       [0.52777778, 0.08333333, 0.59322034, 0.58333333],\n",
       "       [0.36111111, 0.20833333, 0.49152542, 0.41666667],\n",
       "       [0.44444444, 0.5       , 0.6440678 , 0.70833333],\n",
       "       [0.5       , 0.33333333, 0.50847458, 0.5       ],\n",
       "       [0.55555556, 0.20833333, 0.66101695, 0.58333333],\n",
       "       [0.5       , 0.33333333, 0.62711864, 0.45833333],\n",
       "       [0.58333333, 0.375     , 0.55932203, 0.5       ],\n",
       "       [0.63888889, 0.41666667, 0.57627119, 0.54166667],\n",
       "       [0.69444444, 0.33333333, 0.6440678 , 0.54166667],\n",
       "       [0.66666667, 0.41666667, 0.6779661 , 0.66666667],\n",
       "       [0.47222222, 0.375     , 0.59322034, 0.58333333],\n",
       "       [0.38888889, 0.25      , 0.42372881, 0.375     ],\n",
       "       [0.33333333, 0.16666667, 0.47457627, 0.41666667],\n",
       "       [0.33333333, 0.16666667, 0.45762712, 0.375     ],\n",
       "       [0.41666667, 0.29166667, 0.49152542, 0.45833333],\n",
       "       [0.47222222, 0.29166667, 0.69491525, 0.625     ],\n",
       "       [0.30555556, 0.41666667, 0.59322034, 0.58333333],\n",
       "       [0.47222222, 0.58333333, 0.59322034, 0.625     ],\n",
       "       [0.66666667, 0.45833333, 0.62711864, 0.58333333],\n",
       "       [0.55555556, 0.125     , 0.57627119, 0.5       ],\n",
       "       [0.36111111, 0.41666667, 0.52542373, 0.5       ],\n",
       "       [0.33333333, 0.20833333, 0.50847458, 0.5       ],\n",
       "       [0.33333333, 0.25      , 0.57627119, 0.45833333],\n",
       "       [0.5       , 0.41666667, 0.61016949, 0.54166667],\n",
       "       [0.41666667, 0.25      , 0.50847458, 0.45833333],\n",
       "       [0.19444444, 0.125     , 0.38983051, 0.375     ],\n",
       "       [0.36111111, 0.29166667, 0.54237288, 0.5       ],\n",
       "       [0.38888889, 0.41666667, 0.54237288, 0.45833333],\n",
       "       [0.38888889, 0.375     , 0.54237288, 0.5       ],\n",
       "       [0.52777778, 0.375     , 0.55932203, 0.5       ],\n",
       "       [0.22222222, 0.20833333, 0.33898305, 0.41666667],\n",
       "       [0.38888889, 0.33333333, 0.52542373, 0.5       ],\n",
       "       [0.55555556, 0.54166667, 0.84745763, 1.        ],\n",
       "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
       "       [0.77777778, 0.41666667, 0.83050847, 0.83333333],\n",
       "       [0.55555556, 0.375     , 0.77966102, 0.70833333],\n",
       "       [0.61111111, 0.41666667, 0.81355932, 0.875     ],\n",
       "       [0.91666667, 0.41666667, 0.94915254, 0.83333333],\n",
       "       [0.16666667, 0.20833333, 0.59322034, 0.66666667],\n",
       "       [0.83333333, 0.375     , 0.89830508, 0.70833333],\n",
       "       [0.66666667, 0.20833333, 0.81355932, 0.70833333],\n",
       "       [0.80555556, 0.66666667, 0.86440678, 1.        ],\n",
       "       [0.61111111, 0.5       , 0.69491525, 0.79166667],\n",
       "       [0.58333333, 0.29166667, 0.72881356, 0.75      ],\n",
       "       [0.69444444, 0.41666667, 0.76271186, 0.83333333],\n",
       "       [0.38888889, 0.20833333, 0.6779661 , 0.79166667],\n",
       "       [0.41666667, 0.33333333, 0.69491525, 0.95833333],\n",
       "       [0.58333333, 0.5       , 0.72881356, 0.91666667],\n",
       "       [0.61111111, 0.41666667, 0.76271186, 0.70833333],\n",
       "       [0.94444444, 0.75      , 0.96610169, 0.875     ],\n",
       "       [0.94444444, 0.25      , 1.        , 0.91666667],\n",
       "       [0.47222222, 0.08333333, 0.6779661 , 0.58333333],\n",
       "       [0.72222222, 0.5       , 0.79661017, 0.91666667],\n",
       "       [0.36111111, 0.33333333, 0.66101695, 0.79166667],\n",
       "       [0.94444444, 0.33333333, 0.96610169, 0.79166667],\n",
       "       [0.55555556, 0.29166667, 0.66101695, 0.70833333],\n",
       "       [0.66666667, 0.54166667, 0.79661017, 0.83333333],\n",
       "       [0.80555556, 0.5       , 0.84745763, 0.70833333],\n",
       "       [0.52777778, 0.33333333, 0.6440678 , 0.70833333],\n",
       "       [0.5       , 0.41666667, 0.66101695, 0.70833333],\n",
       "       [0.58333333, 0.33333333, 0.77966102, 0.83333333],\n",
       "       [0.80555556, 0.41666667, 0.81355932, 0.625     ],\n",
       "       [0.86111111, 0.33333333, 0.86440678, 0.75      ],\n",
       "       [1.        , 0.75      , 0.91525424, 0.79166667],\n",
       "       [0.58333333, 0.33333333, 0.77966102, 0.875     ],\n",
       "       [0.55555556, 0.33333333, 0.69491525, 0.58333333],\n",
       "       [0.5       , 0.25      , 0.77966102, 0.54166667],\n",
       "       [0.94444444, 0.41666667, 0.86440678, 0.91666667],\n",
       "       [0.55555556, 0.58333333, 0.77966102, 0.95833333],\n",
       "       [0.58333333, 0.45833333, 0.76271186, 0.70833333],\n",
       "       [0.47222222, 0.41666667, 0.6440678 , 0.70833333],\n",
       "       [0.72222222, 0.45833333, 0.74576271, 0.83333333],\n",
       "       [0.66666667, 0.45833333, 0.77966102, 0.95833333],\n",
       "       [0.72222222, 0.45833333, 0.69491525, 0.91666667],\n",
       "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
       "       [0.69444444, 0.5       , 0.83050847, 0.91666667],\n",
       "       [0.66666667, 0.54166667, 0.79661017, 1.        ],\n",
       "       [0.66666667, 0.41666667, 0.71186441, 0.91666667],\n",
       "       [0.55555556, 0.20833333, 0.6779661 , 0.75      ],\n",
       "       [0.61111111, 0.41666667, 0.71186441, 0.79166667],\n",
       "       [0.52777778, 0.58333333, 0.74576271, 0.91666667],\n",
       "       [0.44444444, 0.41666667, 0.69491525, 0.70833333]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "iris_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b4e1fd7-9343-479b-b990-9b49b57017e7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.08333333, 0.45833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.66666667, 0.06779661, 0.04166667],\n",
       "       [0.30555556, 0.79166667, 0.11864407, 0.125     ],\n",
       "       [0.08333333, 0.58333333, 0.06779661, 0.08333333],\n",
       "       [0.19444444, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.02777778, 0.375     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
       "       [0.30555556, 0.70833333, 0.08474576, 0.04166667],\n",
       "       [0.13888889, 0.58333333, 0.10169492, 0.04166667],\n",
       "       [0.13888889, 0.41666667, 0.06779661, 0.        ],\n",
       "       [0.        , 0.41666667, 0.01694915, 0.        ],\n",
       "       [0.41666667, 0.83333333, 0.03389831, 0.04166667],\n",
       "       [0.38888889, 1.        , 0.08474576, 0.125     ],\n",
       "       [0.30555556, 0.79166667, 0.05084746, 0.125     ],\n",
       "       [0.22222222, 0.625     , 0.06779661, 0.08333333],\n",
       "       [0.38888889, 0.75      , 0.11864407, 0.08333333],\n",
       "       [0.22222222, 0.75      , 0.08474576, 0.08333333],\n",
       "       [0.30555556, 0.58333333, 0.11864407, 0.04166667],\n",
       "       [0.22222222, 0.70833333, 0.08474576, 0.125     ],\n",
       "       [0.08333333, 0.66666667, 0.        , 0.04166667],\n",
       "       [0.22222222, 0.54166667, 0.11864407, 0.16666667],\n",
       "       [0.13888889, 0.58333333, 0.15254237, 0.04166667],\n",
       "       [0.19444444, 0.41666667, 0.10169492, 0.04166667],\n",
       "       [0.19444444, 0.58333333, 0.10169492, 0.125     ],\n",
       "       [0.25      , 0.625     , 0.08474576, 0.04166667],\n",
       "       [0.25      , 0.58333333, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.10169492, 0.04166667],\n",
       "       [0.13888889, 0.45833333, 0.10169492, 0.04166667],\n",
       "       [0.30555556, 0.58333333, 0.08474576, 0.125     ],\n",
       "       [0.25      , 0.875     , 0.08474576, 0.        ],\n",
       "       [0.33333333, 0.91666667, 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.5       , 0.03389831, 0.04166667],\n",
       "       [0.33333333, 0.625     , 0.05084746, 0.04166667],\n",
       "       [0.16666667, 0.66666667, 0.06779661, 0.        ],\n",
       "       [0.02777778, 0.41666667, 0.05084746, 0.04166667],\n",
       "       [0.22222222, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.625     , 0.05084746, 0.08333333],\n",
       "       [0.05555556, 0.125     , 0.05084746, 0.08333333],\n",
       "       [0.02777778, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.19444444, 0.625     , 0.10169492, 0.20833333],\n",
       "       [0.22222222, 0.75      , 0.15254237, 0.125     ],\n",
       "       [0.13888889, 0.41666667, 0.06779661, 0.08333333],\n",
       "       [0.22222222, 0.75      , 0.10169492, 0.04166667],\n",
       "       [0.08333333, 0.5       , 0.06779661, 0.04166667],\n",
       "       [0.27777778, 0.70833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.54166667, 0.06779661, 0.04166667],\n",
       "       [0.75      , 0.5       , 0.62711864, 0.54166667],\n",
       "       [0.58333333, 0.5       , 0.59322034, 0.58333333],\n",
       "       [0.72222222, 0.45833333, 0.66101695, 0.58333333],\n",
       "       [0.33333333, 0.125     , 0.50847458, 0.5       ],\n",
       "       [0.61111111, 0.33333333, 0.61016949, 0.58333333],\n",
       "       [0.38888889, 0.33333333, 0.59322034, 0.5       ],\n",
       "       [0.55555556, 0.54166667, 0.62711864, 0.625     ],\n",
       "       [0.16666667, 0.16666667, 0.38983051, 0.375     ],\n",
       "       [0.63888889, 0.375     , 0.61016949, 0.5       ],\n",
       "       [0.25      , 0.29166667, 0.49152542, 0.54166667],\n",
       "       [0.19444444, 0.        , 0.42372881, 0.375     ],\n",
       "       [0.44444444, 0.41666667, 0.54237288, 0.58333333],\n",
       "       [0.47222222, 0.08333333, 0.50847458, 0.375     ],\n",
       "       [0.5       , 0.375     , 0.62711864, 0.54166667],\n",
       "       [0.36111111, 0.375     , 0.44067797, 0.5       ],\n",
       "       [0.66666667, 0.45833333, 0.57627119, 0.54166667],\n",
       "       [0.36111111, 0.41666667, 0.59322034, 0.58333333],\n",
       "       [0.41666667, 0.29166667, 0.52542373, 0.375     ],\n",
       "       [0.52777778, 0.08333333, 0.59322034, 0.58333333],\n",
       "       [0.36111111, 0.20833333, 0.49152542, 0.41666667],\n",
       "       [0.44444444, 0.5       , 0.6440678 , 0.70833333],\n",
       "       [0.5       , 0.33333333, 0.50847458, 0.5       ],\n",
       "       [0.55555556, 0.20833333, 0.66101695, 0.58333333],\n",
       "       [0.5       , 0.33333333, 0.62711864, 0.45833333],\n",
       "       [0.58333333, 0.375     , 0.55932203, 0.5       ],\n",
       "       [0.63888889, 0.41666667, 0.57627119, 0.54166667],\n",
       "       [0.69444444, 0.33333333, 0.6440678 , 0.54166667],\n",
       "       [0.66666667, 0.41666667, 0.6779661 , 0.66666667],\n",
       "       [0.47222222, 0.375     , 0.59322034, 0.58333333],\n",
       "       [0.38888889, 0.25      , 0.42372881, 0.375     ],\n",
       "       [0.33333333, 0.16666667, 0.47457627, 0.41666667],\n",
       "       [0.33333333, 0.16666667, 0.45762712, 0.375     ],\n",
       "       [0.41666667, 0.29166667, 0.49152542, 0.45833333],\n",
       "       [0.47222222, 0.29166667, 0.69491525, 0.625     ],\n",
       "       [0.30555556, 0.41666667, 0.59322034, 0.58333333],\n",
       "       [0.47222222, 0.58333333, 0.59322034, 0.625     ],\n",
       "       [0.66666667, 0.45833333, 0.62711864, 0.58333333],\n",
       "       [0.55555556, 0.125     , 0.57627119, 0.5       ],\n",
       "       [0.36111111, 0.41666667, 0.52542373, 0.5       ],\n",
       "       [0.33333333, 0.20833333, 0.50847458, 0.5       ],\n",
       "       [0.33333333, 0.25      , 0.57627119, 0.45833333],\n",
       "       [0.5       , 0.41666667, 0.61016949, 0.54166667],\n",
       "       [0.41666667, 0.25      , 0.50847458, 0.45833333],\n",
       "       [0.19444444, 0.125     , 0.38983051, 0.375     ],\n",
       "       [0.36111111, 0.29166667, 0.54237288, 0.5       ],\n",
       "       [0.38888889, 0.41666667, 0.54237288, 0.45833333],\n",
       "       [0.38888889, 0.375     , 0.54237288, 0.5       ],\n",
       "       [0.52777778, 0.375     , 0.55932203, 0.5       ],\n",
       "       [0.22222222, 0.20833333, 0.33898305, 0.41666667],\n",
       "       [0.38888889, 0.33333333, 0.52542373, 0.5       ],\n",
       "       [0.55555556, 0.54166667, 0.84745763, 1.        ],\n",
       "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
       "       [0.77777778, 0.41666667, 0.83050847, 0.83333333],\n",
       "       [0.55555556, 0.375     , 0.77966102, 0.70833333],\n",
       "       [0.61111111, 0.41666667, 0.81355932, 0.875     ],\n",
       "       [0.91666667, 0.41666667, 0.94915254, 0.83333333],\n",
       "       [0.16666667, 0.20833333, 0.59322034, 0.66666667],\n",
       "       [0.83333333, 0.375     , 0.89830508, 0.70833333],\n",
       "       [0.66666667, 0.20833333, 0.81355932, 0.70833333],\n",
       "       [0.80555556, 0.66666667, 0.86440678, 1.        ],\n",
       "       [0.61111111, 0.5       , 0.69491525, 0.79166667],\n",
       "       [0.58333333, 0.29166667, 0.72881356, 0.75      ],\n",
       "       [0.69444444, 0.41666667, 0.76271186, 0.83333333],\n",
       "       [0.38888889, 0.20833333, 0.6779661 , 0.79166667],\n",
       "       [0.41666667, 0.33333333, 0.69491525, 0.95833333],\n",
       "       [0.58333333, 0.5       , 0.72881356, 0.91666667],\n",
       "       [0.61111111, 0.41666667, 0.76271186, 0.70833333],\n",
       "       [0.94444444, 0.75      , 0.96610169, 0.875     ],\n",
       "       [0.94444444, 0.25      , 1.        , 0.91666667],\n",
       "       [0.47222222, 0.08333333, 0.6779661 , 0.58333333],\n",
       "       [0.72222222, 0.5       , 0.79661017, 0.91666667],\n",
       "       [0.36111111, 0.33333333, 0.66101695, 0.79166667],\n",
       "       [0.94444444, 0.33333333, 0.96610169, 0.79166667],\n",
       "       [0.55555556, 0.29166667, 0.66101695, 0.70833333],\n",
       "       [0.66666667, 0.54166667, 0.79661017, 0.83333333],\n",
       "       [0.80555556, 0.5       , 0.84745763, 0.70833333],\n",
       "       [0.52777778, 0.33333333, 0.6440678 , 0.70833333],\n",
       "       [0.5       , 0.41666667, 0.66101695, 0.70833333],\n",
       "       [0.58333333, 0.33333333, 0.77966102, 0.83333333],\n",
       "       [0.80555556, 0.41666667, 0.81355932, 0.625     ],\n",
       "       [0.86111111, 0.33333333, 0.86440678, 0.75      ],\n",
       "       [1.        , 0.75      , 0.91525424, 0.79166667],\n",
       "       [0.58333333, 0.33333333, 0.77966102, 0.875     ],\n",
       "       [0.55555556, 0.33333333, 0.69491525, 0.58333333],\n",
       "       [0.5       , 0.25      , 0.77966102, 0.54166667],\n",
       "       [0.94444444, 0.41666667, 0.86440678, 0.91666667],\n",
       "       [0.55555556, 0.58333333, 0.77966102, 0.95833333],\n",
       "       [0.58333333, 0.45833333, 0.76271186, 0.70833333],\n",
       "       [0.47222222, 0.41666667, 0.6440678 , 0.70833333],\n",
       "       [0.72222222, 0.45833333, 0.74576271, 0.83333333],\n",
       "       [0.66666667, 0.45833333, 0.77966102, 0.95833333],\n",
       "       [0.72222222, 0.45833333, 0.69491525, 0.91666667],\n",
       "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
       "       [0.69444444, 0.5       , 0.83050847, 0.91666667],\n",
       "       [0.66666667, 0.54166667, 0.79661017, 1.        ],\n",
       "       [0.66666667, 0.41666667, 0.71186441, 0.91666667],\n",
       "       [0.55555556, 0.20833333, 0.6779661 , 0.75      ],\n",
       "       [0.61111111, 0.41666667, 0.71186441, 0.79166667],\n",
       "       [0.52777778, 0.58333333, 0.74576271, 0.91666667],\n",
       "       [0.44444444, 0.41666667, 0.69491525, 0.70833333]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #이렇게 써줘도 결과는 똑같다.\n",
    "iris_scaled = scaler.fit_transform(iris_df)\n",
    "iris_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5a6c01-f1ea-42fe-93a3-c4c6b02ca2ff",
   "metadata": {},
   "source": [
    "#### → 정규화 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2132c3e3-afcb-4166-80eb-47c9e6ff66af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#을 이용하여 정규화 시켜주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f69ec06-4d97-4614-bf39-c96ec237cd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.905556</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.230508</td>\n",
       "      <td>0.158333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.705556</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.230508</td>\n",
       "      <td>0.158333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.505556</td>\n",
       "      <td>2.366667</td>\n",
       "      <td>1.130508</td>\n",
       "      <td>0.158333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.405556</td>\n",
       "      <td>2.266667</td>\n",
       "      <td>1.330508</td>\n",
       "      <td>0.158333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.805556</td>\n",
       "      <td>2.766667</td>\n",
       "      <td>1.230508</td>\n",
       "      <td>0.158333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>5.505556</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>5.030508</td>\n",
       "      <td>2.258333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>5.105556</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>4.830508</td>\n",
       "      <td>1.858333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>5.305556</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>5.030508</td>\n",
       "      <td>1.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>5.005556</td>\n",
       "      <td>2.566667</td>\n",
       "      <td>5.230508</td>\n",
       "      <td>2.258333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>4.705556</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>4.930508</td>\n",
       "      <td>1.758333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3\n",
       "0    3.905556  2.666667  1.230508  0.158333\n",
       "1    3.705556  2.166667  1.230508  0.158333\n",
       "2    3.505556  2.366667  1.130508  0.158333\n",
       "3    3.405556  2.266667  1.330508  0.158333\n",
       "4    3.805556  2.766667  1.230508  0.158333\n",
       "..        ...       ...       ...       ...\n",
       "145  5.505556  2.166667  5.030508  2.258333\n",
       "146  5.105556  1.666667  4.830508  1.858333\n",
       "147  5.305556  2.166667  5.030508  1.958333\n",
       "148  5.005556  2.566667  5.230508  2.258333\n",
       "149  4.705556  2.166667  4.930508  1.758333\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "iris = load_iris()\n",
    "iris = iris['data']\n",
    "iris_df = pd.DataFrame(iris) \n",
    "\n",
    "iris_df.apply(lambda x:x-x.min()/(x.max()-x.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848c8a90-29f4-49b4-a590-265a56a4f620",
   "metadata": {},
   "source": [
    "#### < 주의 : fit >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041404d7-f940-43ff-9b13-8626dad98391",
   "metadata": {},
   "source": [
    "X_train, X_test = train_test_split(iris_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b10e75-2d44-477e-8759-cb0eabca49f6",
   "metadata": {},
   "source": [
    "X_train\n",
    "\n",
    "scaler.fit()\n",
    "scaler.fit_transform(X_train)\n",
    "\n",
    "1,2,1,2 ---> 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26328aa5-3b53-4f85-9c5d-047ea04721df",
   "metadata": {},
   "source": [
    "X_test\n",
    "\n",
    "scaler.transform(x_test)\n",
    "1,2,1,2 ----> 10? X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a2027-2732-4190-b56a-7f9202f51762",
   "metadata": {},
   "source": [
    "먼저 있는것을 정규화 시키고 쪼개라 \n",
    "\n",
    "쪼개놓고 각각 정규화 시키면 위의 fit기준과 아래의 fit기준이 달라지게 된다.\n",
    "\n",
    "즉, fit은 한번만 해줘야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8109828-e16a-4a03-a87a-5348b67c13c8",
   "metadata": {},
   "source": [
    "< 올바른 표현 >\n",
    "\n",
    "scaler.fit(x)\n",
    "scaler.transformm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abc68fa-9383-496a-9c95-470ddf81b021",
   "metadata": {},
   "source": [
    "## → 정규화(Normalization)\n",
    ": 데이터의 분포가 가우시안 분포가 아닌(혹은 분포를 알 수 없는) 경우 유용하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b10572dd-d550-473f-b9c8-8d7411a47396",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3\n",
       "0    5.1  3.5  1.4  0.2\n",
       "1    4.9  3.0  1.4  0.2\n",
       "2    4.7  3.2  1.3  0.2\n",
       "3    4.6  3.1  1.5  0.2\n",
       "4    5.0  3.6  1.4  0.2\n",
       "..   ...  ...  ...  ...\n",
       "145  6.7  3.0  5.2  2.3\n",
       "146  6.3  2.5  5.0  1.9\n",
       "147  6.5  3.0  5.2  2.0\n",
       "148  6.2  3.4  5.4  2.3\n",
       "149  5.9  3.0  5.1  1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "iris = iris['data']\n",
    "iris_df = pd.DataFrame(iris)\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b63c0e10-9668-4997-9ee8-261284724416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7.9\n",
       "1    4.4\n",
       "2    6.9\n",
       "3    2.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77a7e625-f125-4520-8da7-3bbd251b1918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.3\n",
       "1    2.0\n",
       "2    1.0\n",
       "3    0.1\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b168d9c-0d9a-4492-8e83-970e652b68eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max(x):\n",
    "    return (x - x.min()) / (x.max() - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68d451fc-7d5c-4a83-b24b-751391622668",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3\n",
       "0    0.222222  0.625000  0.067797  0.041667\n",
       "1    0.166667  0.416667  0.067797  0.041667\n",
       "2    0.111111  0.500000  0.050847  0.041667\n",
       "3    0.083333  0.458333  0.084746  0.041667\n",
       "4    0.194444  0.666667  0.067797  0.041667\n",
       "..        ...       ...       ...       ...\n",
       "145  0.666667  0.416667  0.711864  0.916667\n",
       "146  0.555556  0.208333  0.677966  0.750000\n",
       "147  0.611111  0.416667  0.711864  0.791667\n",
       "148  0.527778  0.583333  0.745763  0.916667\n",
       "149  0.444444  0.416667  0.694915  0.708333\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.apply(min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "351997a5-4645-4f83-8ef1-8a88ca4c1289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.apply(min_max).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "719e1c84-7dfd-425e-8c0f-626db56cd965",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3\n",
       "0    0.222222  0.625000  0.067797  0.041667\n",
       "1    0.166667  0.416667  0.067797  0.041667\n",
       "2    0.111111  0.500000  0.050847  0.041667\n",
       "3    0.083333  0.458333  0.084746  0.041667\n",
       "4    0.194444  0.666667  0.067797  0.041667\n",
       "..        ...       ...       ...       ...\n",
       "145  0.666667  0.416667  0.711864  0.916667\n",
       "146  0.555556  0.208333  0.677966  0.750000\n",
       "147  0.611111  0.416667  0.711864  0.791667\n",
       "148  0.527778  0.583333  0.745763  0.916667\n",
       "149  0.444444  0.416667  0.694915  0.708333\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#람다식을 이용한 같은 표현\n",
    "iris_df.apply(lambda x:(x - x.min()) / (x.max() - x.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaaaaf8-91b9-478e-ae2c-1eaa90b155ef",
   "metadata": {},
   "source": [
    "# < 오차 행렬 >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b598874-ce85-4ba2-95e0-75ee0e0ac838",
   "metadata": {},
   "source": [
    "```\n",
    "                                                             실제 클래스(Actual Class)\n",
    "                                              \n",
    "                                              \n",
    "                                                          Positive                Negative\n",
    "                                           Positive         TP           |           FP\n",
    "          예측 클래스(Predict Class)                   \n",
    "                                           Negative         FN           |           TN\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66c29b9-0272-4b67-a5c2-6852544127d5",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "- TP(Ture Positive) : Positive로 예측했고 True\n",
    "                      -> 예측값도 Positive 실제값도 Positive\n",
    "\n",
    "- TN(True Negative) : Negative로 예측했고 True\n",
    "                      -> 예측값도 Negative 실제값은 Positive\n",
    "\n",
    "- FP(False Positive) : Positive로 예측했고 False\n",
    "                       -> 예측값은 Positive이지만 틀렸으므로 실제값은 Negative이다.\n",
    "\n",
    "- FN(False Negative) : Negative로 예측했고 False\n",
    "                       -> 예측값은 Negative이지만 틀렸으므로 실제값은 Positive이다.\n",
    "             \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f53b2e9-1a79-4aa1-ae72-2864334a7bd1",
   "metadata": {},
   "source": [
    "# < 정밀도와 재현율 >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb918a7-e663-41de-8614-d2b4cd41da10",
   "metadata": {},
   "source": [
    "```\n",
    "                                            질병유무\n",
    "                                    유                  무\n",
    "                    질병            a          |        b\n",
    "      검사결과\n",
    "                    정상            c          |        d\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d312b40d-c0a6-432d-8418-56901a5885f1",
   "metadata": {},
   "source": [
    "```\n",
    "- 정밀도(Precision) = TP / (TP + FP) = a / a+b\n",
    "                      -> 질병이 있다고 예측한 것 중 실제 질병이 있는 경우\n",
    "- 재현율(Recall) = TP / (TP + FN) = a / a+c\n",
    "                   -> 실제 질병이 있는 경우, 실시한 검사에서 질병이 있다고 판정할 수 있는 능력\n",
    "                   -> 민감도 또는 TPR 이라고도 불림\n",
    "- 특이도(Specificity) = TN / (FP + TN) = d / b+d\n",
    "                        -> 실제 질병이 없는 경우, 실시한 검사에서 질병이 없다고 판정할 수 있는 능력\n",
    "- 조화평균 : 항목들의 역수에 대한 산술평균을 또 역수로 구한것\n",
    "            조화평균은 평균적인 변화율을 구할 때 주로 사용된다\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55b9bde-f54f-46a3-aadc-d6581955b8ab",
   "metadata": {},
   "source": [
    "```\n",
    "- 트레이드오프(Trade-off) : 정밀도와 재현율 중 어느 한 쪽을 강제로 높이면 다른 하나의 수치는 떨어진다.\n",
    "- F1 스코어(Score) : 정밀도와 재현율을 결합한 지표로 F1스코어가 높으면 무조건 좋다.\n",
    "                     정밀도나 재현율이 극단적인 파이를 가질 경우 좋은 평가 지표가 될 수 없기 때문에\n",
    "                     둘을 결합한 지표가 F1스코어이다.\n",
    "- ROC 곡선 : 가장좋은 수치는 최대로 위쪽에 달라붙는것. 일반적으로 1에 가까울수록 좋은 수치\n",
    "- AUC(Area Under Cover) : ROC 곡선의 아래쪽 넓이를 의미한다.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62a7013-906f-44b7-8826-8b3b418747e5",
   "metadata": {},
   "source": [
    "혼동행렬 :from sklearn.metrics import confusion_matrix\n",
    "정확도 : from sklearn.metrics import accuracy_score\n",
    "정밀도 : from sklearn.metrics import precision_score\n",
    "재현율 : from sklearn.metrics import recall_score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687848eb-6445-479c-986e-8a0a8080ff10",
   "metadata": {},
   "source": [
    "Recall과 Precision은 상호보완적관계로 trade off라고 한다.\n",
    "(한쪽이 높아지면 다른 한쪽은 낮아진다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13636381-c375-4390-b9df-5df62a1c93ce",
   "metadata": {},
   "source": [
    "보기에서 틀린 것을 고르세요.\n",
    "\n",
    "1. Positive 예측값이 많아지면 상대적으로 재현율 값이 높아진다.\n",
    "2. 임계값이 낮아질수록 Positive로 예측할 확률이 높아진다.\n",
    "3. '암환자중에 검사로 얼마나 암 환자를 잘 골라냈는가?'는 재현율과 관련이 없다.\n",
    "4. TP/(TP+FP)은 재현율의 공식이다.\n",
    "5. ROC 곡선은 X축으로 FPR, Y축으로 TPR를 설정한다.\n",
    "\n",
    "답은 3번."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5504a8bd-6c66-4a2f-a640-3508a91c613a",
   "metadata": {},
   "source": [
    "보기에서 틀린것을 고르세요.\n",
    "\n",
    "1. 정밀도와 재현율은 상호 보완적인 평가지표이다.\n",
    "2. 정밀도를 올리면 재현율이 떨어지는 현상을 트레이드오프라 한다.\n",
    "3. '정상인중에 얼마나 암환자로 오진했는가?'는 특이도와 관련이 있다.\n",
    "4. 임곗값을 낮출수록 True 값이 적어진다.\n",
    "5. ROC곡선 면적에 기반한 AUC값은 1에 가까울수록 좋은 수치이다.\n",
    "\n",
    "답은 4번."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28384256-19ba-4960-b8c4-eae071a0c9fd",
   "metadata": {},
   "source": [
    "보기에서 틀린것을 고르세요.\n",
    "\n",
    "1. 이진 분류 모델에서는 예측 확률이 큰 레이블 값으로 예측한다.\n",
    "2. 재현율이 중요한 경우는 양성지표를 Negative로 잘못 판단시 큰 영향을 가지는 경우이다.\n",
    "   : 암환자인 경우에 50:50으로 암일 확률이다. 긴가민가 할때는 암이라고 말 하고 \n",
    "     큰 병원에 가서 검사를 받는것이 좋은 선택이다.\n",
    "3. F1 스코어는 정밀도와 재현율을 결합한 지표이다.\n",
    "4. F1 스코어는 정밀도와 재현율이 큰 차이를 가질수록 높은 값을 가진다.\n",
    "5. FPR을 0으로 만들려면 임계값을 1로 지정한다.\n",
    "\n",
    "답은 4번."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee625367-3635-4845-ade0-9212b40bca13",
   "metadata": {},
   "source": [
    "보기에서 틀린것을 고르세요,\n",
    "\n",
    "1. 정밀도가 중요한 경우는 음성데이터를 양성으로 잘못 판단하면 큰 영향이 발생하는 경우이다.\n",
    "2. TP/(TP+FP)은 정밀도의 공식이다.\n",
    "3. True Positive Rate은 재현율이다.\n",
    "4. 전체 환자를 Positive라 예측하고 실제 양성인 환자가 n명이라면 재현율은 0이 된다.\n",
    "5. 전체 환자 중 1명만 Positive라 예측하고 나머지를 전부 Negative라 예측하면 정밀도는 1이 된다.\n",
    "\n",
    "답은 4번."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81f3307-ed00-47ae-b8b6-36968c7b97a9",
   "metadata": {},
   "source": [
    "# < 결정트리 >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079d59be-0920-412d-b636-9150e6fd13cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "의사결정나무는 분류(classification)와 회귀(regression) 모두 가능하다.\n",
    "\n",
    "\n",
    "지니지수 불순도: 불순도를 측정해주세요.\n",
    "전체 16개 중 빨간색 10개, 파란색 6개가 있다.\n",
    "-> 1 - (10/16)^2 - (6/16)^2 = 0.47\n",
    "\n",
    "\n",
    "불순도를 측정하는 대표적인 방법 2가지\n",
    "-> 지니지수, 엔트로피지수\n",
    "\n",
    "\n",
    "불순도가 0.5에서 0.4로 낮아질 때 0.1만큼 (정보 이득 = information gain)이 있다고 말한다.\n",
    "\n",
    "\n",
    "★ 중요함\n",
    "min_samples_split: 노드를 분할하기 위한 최소 샘플 갯수(마지막 노드를 말함.)\n",
    "    \n",
    "min_samples_leaf: 분할될경우 좌우 브랜치에서 가져야 할 최소 샘플 갯수\n",
    "    \n",
    "max_depth: 트리 최대 깊이\n",
    "    \n",
    "max_leaf_nodes: 말단 leaf의 총 갯수\n",
    "    \n",
    "max_features: 분할에 사용할 feature 갯수\n",
    "\n",
    "\n",
    "(과적합)은 학습 데이터에 대해 과하게 학습하여 적절한 일반화를 하지 못해서\n",
    "실제 데이터에 대한 오차가 증가하는 현상으로 이를 방지하기 위해 \n",
    "의사 결정 트리에서는 가지치기(pruning) 작업을 한다.\n",
    "\n",
    "\n",
    "싸이킷런 분류 알고리즘에서 predict할 때, 각 label의 확률을 보여주는 매서드는 무엇인가?\n",
    "predict_proba\n",
    "\n",
    "\n",
    "GridSearchCV 함수의 파라미터 'n_jobs=-1' 이란 무엇을 의미하는가?\n",
    "-> 수를 늘릴수록 그만큼 CPU 코어 사용, -1은 전체 사용\n",
    "\n",
    "\n",
    "결정 트리의 깊이(depth)가 깊을수록 예측 성능이 좋지 않다.\n",
    "\n",
    "\n",
    "의사결정나무는 스케일이나 평균을 원점에 맞추는 것과 같은 데이터 전처리가 \n",
    "거의 필요하지 않다.\n",
    "\n",
    "\n",
    "결정트리에서 지니 계수가 낮을수록 데이터의 균일도가 높음으로 해석한다.\n",
    "\n",
    "\n",
    "조화평균의 공식은 무엇인가요?\n",
    "-> 2ab / (a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110a417e-256c-41db-91f8-3330fe440164",
   "metadata": {},
   "outputs": [],
   "source": [
    "< split을 하는 이유 >\n",
    "training set을 training/validation으로 split을 한 이유는\n",
    "    -> 모델의 완성도를 좀 더 높이기 위해서이다.(여러번 검증함)\n",
    "    -> 과적합을 피하기 위해서이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c36dc08-73b0-447d-b66c-ca5d372fa68d",
   "metadata": {},
   "source": [
    "# < 앙상블 학습 >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cac948-c622-4454-ab79-b85837441ff1",
   "metadata": {},
   "source": [
    "학습 목표: \n",
    "머신러닝에서 여러개의 분류기로 데이터를 학습하고 각각 학습된 알고리즘으로 \n",
    "결과를 예측하고 그 결과들을 결합해 최종으로 더 나은 결과를 도출해내는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af80ded5-d735-4d6b-b4b8-c6535d20614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "앙상블 기법의 조건\n",
    "- 각각의 분류기는 상호 독립적이어야 한다.\n",
    "- 각 분류기의 오분률은 적어도 50% 보다는 낮아야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c341b7d7-8360-4f03-9eb7-e6d103e069d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting 분류기 정확도: 0.9561\n",
      "LogisticRegression 정확도: 0.9474\n",
      "KNeighborsClassifier 정확도: 0.9386\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "data_df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
    "\n",
    "vo_clf = VotingClassifier(estimators=[('lr', lr_clf), ('knn', knn_clf)], voting='soft')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target,\n",
    "                                                   test_size=0.2, random_state=156)\n",
    "\n",
    "vo_clf.fit(X_train, y_train)\n",
    "pred = vo_clf.predict(X_test)\n",
    "print('Voting 분류기 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))\n",
    "\n",
    "classifiers = [lr_clf, knn_clf]\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train, y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    class_name=classifier.__class__.__name__\n",
    "    print('{0} 정확도: {1:.4f}'.format(class_name, accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b70b1cc-ca6e-4b60-a0d0-d8153f993a69",
   "metadata": {},
   "source": [
    "## -> 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96491045-846e-458b-b5ff-b61eeb3245f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = error 오차\n",
    "loss function : 손실함수\n",
    "cost function : 비용함수\n",
    "objective function : 목적함수\n",
    "learning_rate(eta) : 학습률(에러를 조금씩 수정해 나가는데 얼마만큼 수정할 것인가?)\n",
    "n_estimators : weak learner를 사용할 것인가(분류기를 몇 개를 동원할 것인가?)\n",
    "subsample : overfitting을 방지하기 위해서 1보다 작은 값으로 설정 가능. \n",
    "            기본값은 1(전체데이터 사용)\n",
    "early_stopping_rounds : 조기중단(최소 오차지점에서 몇 번 더 검사를 할 것인가)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c6afbc-0f50-4f62-9697-77f835a9b62f",
   "metadata": {},
   "source": [
    "## -> 앙상블 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ffd8f1-4890-468b-a71a-d59b2d16c4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. GBM\n",
    "   - 경사하강법을 사용\n",
    "   - 랜덤포레스트 보다 예측성능이 뛰어나지만 시간이 오래 걸린다는 단점\n",
    "   - GBM보다 실행 속도가 빠른 알고리즘은 XGBoost, LightGBM 이다.\n",
    "2. 랜덤 포레스트\n",
    "   - 각자의 데이터 샘플링을 하고 최종적으로 소프트 보팅으로 예측 결정\n",
    "3. XGBoost\n",
    "   - XGBoost는 랜덤포레스트보다는 속도가 느리지만 GBM에 비해 학습 속도가 빠르다.\n",
    "   - XGBoost 에서 과적합 문제를 해결하기 위해 고려해야 할 사항\n",
    "     a. max_depth 값을 낮춘다. /너무 자세하게 하지 말아라\n",
    "     b. gamma 값을 높인다. /규제의 수준을 높인다.그렇게 되면 섬세하게 반응하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bb1c1b-7766-444b-a5bb-aa6152edef2d",
   "metadata": {},
   "source": [
    "## -> 앙상블 학습의 유형 : Voting Bagging Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96fdd93-16ee-4bcb-95aa-ffab55274074",
   "metadata": {},
   "source": [
    "- Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605cfc16-874e-4a5d-b935-8d876acdfdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "-> 하드 보팅(Hard Voting)\n",
    "\n",
    "다수결 원칙과 유사\n",
    "예측한 결과값들 중 다수의 분류기가 결정한 예측값을 최종 보팅 결과값으로 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bd0792-bab1-41ad-969d-5afa78b971b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "-> 소프트 보팅(Soft Voting)\n",
    "\n",
    "분류기들의 레이블 값 결정 확률을 모두 더해 이를 평균내서 확률이 가장 높은 레이블 값을 \n",
    "최종 보팅 결과값을 선정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7958688d-d86d-4902-8766-093e32952a48",
   "metadata": {},
   "source": [
    "- Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ffc46c-a9b9-48b8-b9c8-e397fa236b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "배깅(Bagging)은 부트스트랩(bootstrap)을 집계(Aggregating)하여 \n",
    "학습 데이터가 충분하지 않더라도 충분한 학습효과를 주어 높은 bias의 underfitting 문제나, \n",
    "높은 variance로 인한 overfitting 문제를 해결하는데 도움을 줌\n",
    "\n",
    "배깅 방식의 대표는 랜덤 포레스트이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f758610e-7753-4454-8ce8-d4889ecf799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "-> Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaeeb03-17e8-4d35-8672-43111a57c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "부트스트랩(bootstrap)은 통계학에서 사용하는 용어로, random sampling을 적용하는 방법\n",
    "\n",
    "각각의 분류기들이 학습시 상호영향을 주지 않은 상황에서(독립적) 학습이 끝난 다음 결과를 \n",
    "종합하는 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae13c6-371d-4b1c-b8a8-23d9fd1fe112",
   "metadata": {},
   "outputs": [],
   "source": [
    "-> Bootsrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa1b394-084c-497f-9aee-9ced739d922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bootstrapping으로 데이터를 나눌때 한 데이터가 여러번 뽑히거나 \n",
    "한 데이터가 아예 안 뽑힐 수도 있다.부트스트래핑이란 데이터를 중복을 허용하면서 \n",
    "샘플링하는 것이다. \n",
    "\n",
    "부스팅 방식은 잘못 예측한 데이터에 가중치를 부여해서 오류를 개선해가는 학습 방식이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c2d982-7876-4a00-85ee-2ed260cc5e53",
   "metadata": {},
   "source": [
    "- Voting과 Bagging 차이점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a1a5e7-c15d-43fc-86e3-aaafe52ec931",
   "metadata": {},
   "outputs": [],
   "source": [
    "-> voting: 모든 데이터에 대하여, 서로 다른 알고리즘을 가진 분류기를 결합한 것이다.\n",
    "-> Bagging: 1개의 알고리즘과 여러 개의 데이터 샘플을 나누어 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c76b6-c182-453d-8471-55d2450e5f34",
   "metadata": {},
   "source": [
    "- Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5106bbc-c47a-4827-84d2-485651b71342",
   "metadata": {},
   "outputs": [],
   "source": [
    "앙상블 학습 방식 중 맞추기 어려운 문제를 맞추는 것이 목적으로, 에러에 가중치를 주는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1211284a-4f2e-4209-8c95-4a00311965b5",
   "metadata": {},
   "source": [
    "# < 랜덤 포레스트 >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce4507-c960-4f69-aaf7-16c98a6d11e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. 가지를 나눌때마다 p개의 변수중 랜덤하게 m개(p보다 작음)의 변수만 고려한다.\n",
    "2. 소수의 변수들에 대해 상관성이나 원소가 가진 영향력을 제거할 수 있다.\n",
    "3. 여러 개의 데이터세트르 분할 할 때, 부트스트래핑(bootstrapping) 분할 방식을 이용하며,\n",
    "   이는 중첩(복원)을 허용한다.(데이터를 분할할때 부트스트래핑을 사용한다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014ccdbb-77de-41ba-80b0-95884cf2304e",
   "metadata": {},
   "source": [
    "# < LightGBM >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad40f43-5b09-4d6f-baf9-227d9c16dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "- 단점\n",
    "    적은 데이터 세트에 적용할 경우 과적합이 발생하기 쉽다.\n",
    "\n",
    "- XGBoost보다 나은 점\n",
    "    1. 학습시간이 더 빠르다.\n",
    "    2. 더 적은 메모리를 사용한다.\n",
    "\n",
    "-lightgbm의 파라미터 max_depth의 default값은 ?\n",
    " max_depth값을 따로 지정하지 않을 경우 어떤 의미를 가지는가?\n",
    "    디폴트 -1. 트리의 깊이에 제한이 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2fafac-ff43-443b-a43f-3a9e1de10c70",
   "metadata": {},
   "source": [
    "## -> predict_proba\n",
    "\n",
    "사이킷런 분류 알고리즘에서 각 label데이터의 확률을 보여주는 메서드는 무엇인가?\n",
    "-> predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8bffa73-1447-4ab7-919f-fc683f0a5a2d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.625671\tvalid_1's binary_logloss: 0.628248\n",
      "[2]\ttraining's binary_logloss: 0.588173\tvalid_1's binary_logloss: 0.601106\n",
      "[3]\ttraining's binary_logloss: 0.554518\tvalid_1's binary_logloss: 0.577587\n",
      "[4]\ttraining's binary_logloss: 0.523972\tvalid_1's binary_logloss: 0.556324\n",
      "[5]\ttraining's binary_logloss: 0.49615\tvalid_1's binary_logloss: 0.537407\n",
      "[6]\ttraining's binary_logloss: 0.470108\tvalid_1's binary_logloss: 0.519401\n",
      "[7]\ttraining's binary_logloss: 0.446647\tvalid_1's binary_logloss: 0.502637\n",
      "[8]\ttraining's binary_logloss: 0.425055\tvalid_1's binary_logloss: 0.488311\n",
      "[9]\ttraining's binary_logloss: 0.405125\tvalid_1's binary_logloss: 0.474664\n",
      "[10]\ttraining's binary_logloss: 0.386526\tvalid_1's binary_logloss: 0.461267\n",
      "[11]\ttraining's binary_logloss: 0.367027\tvalid_1's binary_logloss: 0.444274\n",
      "[12]\ttraining's binary_logloss: 0.350713\tvalid_1's binary_logloss: 0.432755\n",
      "[13]\ttraining's binary_logloss: 0.334601\tvalid_1's binary_logloss: 0.421371\n",
      "[14]\ttraining's binary_logloss: 0.319854\tvalid_1's binary_logloss: 0.411418\n",
      "[15]\ttraining's binary_logloss: 0.306374\tvalid_1's binary_logloss: 0.402989\n",
      "[16]\ttraining's binary_logloss: 0.293116\tvalid_1's binary_logloss: 0.393973\n",
      "[17]\ttraining's binary_logloss: 0.280812\tvalid_1's binary_logloss: 0.384801\n",
      "[18]\ttraining's binary_logloss: 0.268352\tvalid_1's binary_logloss: 0.376191\n",
      "[19]\ttraining's binary_logloss: 0.256942\tvalid_1's binary_logloss: 0.368378\n",
      "[20]\ttraining's binary_logloss: 0.246443\tvalid_1's binary_logloss: 0.362062\n",
      "[21]\ttraining's binary_logloss: 0.236874\tvalid_1's binary_logloss: 0.355162\n",
      "[22]\ttraining's binary_logloss: 0.227501\tvalid_1's binary_logloss: 0.348933\n",
      "[23]\ttraining's binary_logloss: 0.218988\tvalid_1's binary_logloss: 0.342819\n",
      "[24]\ttraining's binary_logloss: 0.210621\tvalid_1's binary_logloss: 0.337386\n",
      "[25]\ttraining's binary_logloss: 0.202076\tvalid_1's binary_logloss: 0.331523\n",
      "[26]\ttraining's binary_logloss: 0.194199\tvalid_1's binary_logloss: 0.326349\n",
      "[27]\ttraining's binary_logloss: 0.187107\tvalid_1's binary_logloss: 0.322785\n",
      "[28]\ttraining's binary_logloss: 0.180535\tvalid_1's binary_logloss: 0.317877\n",
      "[29]\ttraining's binary_logloss: 0.173834\tvalid_1's binary_logloss: 0.313928\n",
      "[30]\ttraining's binary_logloss: 0.167198\tvalid_1's binary_logloss: 0.310105\n",
      "[31]\ttraining's binary_logloss: 0.161229\tvalid_1's binary_logloss: 0.307107\n",
      "[32]\ttraining's binary_logloss: 0.155494\tvalid_1's binary_logloss: 0.303837\n",
      "[33]\ttraining's binary_logloss: 0.149125\tvalid_1's binary_logloss: 0.300315\n",
      "[34]\ttraining's binary_logloss: 0.144045\tvalid_1's binary_logloss: 0.297816\n",
      "[35]\ttraining's binary_logloss: 0.139341\tvalid_1's binary_logloss: 0.295387\n",
      "[36]\ttraining's binary_logloss: 0.134625\tvalid_1's binary_logloss: 0.293063\n",
      "[37]\ttraining's binary_logloss: 0.129167\tvalid_1's binary_logloss: 0.289127\n",
      "[38]\ttraining's binary_logloss: 0.12472\tvalid_1's binary_logloss: 0.288697\n",
      "[39]\ttraining's binary_logloss: 0.11974\tvalid_1's binary_logloss: 0.28576\n",
      "[40]\ttraining's binary_logloss: 0.115054\tvalid_1's binary_logloss: 0.282853\n",
      "[41]\ttraining's binary_logloss: 0.110662\tvalid_1's binary_logloss: 0.279441\n",
      "[42]\ttraining's binary_logloss: 0.106358\tvalid_1's binary_logloss: 0.28113\n",
      "[43]\ttraining's binary_logloss: 0.102324\tvalid_1's binary_logloss: 0.279139\n",
      "[44]\ttraining's binary_logloss: 0.0985699\tvalid_1's binary_logloss: 0.276465\n",
      "[45]\ttraining's binary_logloss: 0.094858\tvalid_1's binary_logloss: 0.275946\n",
      "[46]\ttraining's binary_logloss: 0.0912486\tvalid_1's binary_logloss: 0.272819\n",
      "[47]\ttraining's binary_logloss: 0.0883115\tvalid_1's binary_logloss: 0.272306\n",
      "[48]\ttraining's binary_logloss: 0.0849963\tvalid_1's binary_logloss: 0.270452\n",
      "[49]\ttraining's binary_logloss: 0.0821742\tvalid_1's binary_logloss: 0.268671\n",
      "[50]\ttraining's binary_logloss: 0.0789991\tvalid_1's binary_logloss: 0.267587\n",
      "[51]\ttraining's binary_logloss: 0.0761072\tvalid_1's binary_logloss: 0.26626\n",
      "[52]\ttraining's binary_logloss: 0.0732567\tvalid_1's binary_logloss: 0.265542\n",
      "[53]\ttraining's binary_logloss: 0.0706388\tvalid_1's binary_logloss: 0.264547\n",
      "[54]\ttraining's binary_logloss: 0.0683911\tvalid_1's binary_logloss: 0.26502\n",
      "[55]\ttraining's binary_logloss: 0.0659347\tvalid_1's binary_logloss: 0.264388\n",
      "[56]\ttraining's binary_logloss: 0.0636873\tvalid_1's binary_logloss: 0.263128\n",
      "[57]\ttraining's binary_logloss: 0.0613354\tvalid_1's binary_logloss: 0.26231\n",
      "[58]\ttraining's binary_logloss: 0.0591944\tvalid_1's binary_logloss: 0.262011\n",
      "[59]\ttraining's binary_logloss: 0.057033\tvalid_1's binary_logloss: 0.261454\n",
      "[60]\ttraining's binary_logloss: 0.0550801\tvalid_1's binary_logloss: 0.260746\n",
      "[61]\ttraining's binary_logloss: 0.0532381\tvalid_1's binary_logloss: 0.260236\n",
      "[62]\ttraining's binary_logloss: 0.0514074\tvalid_1's binary_logloss: 0.261586\n",
      "[63]\ttraining's binary_logloss: 0.0494837\tvalid_1's binary_logloss: 0.261797\n",
      "[64]\ttraining's binary_logloss: 0.0477826\tvalid_1's binary_logloss: 0.262533\n",
      "[65]\ttraining's binary_logloss: 0.0460364\tvalid_1's binary_logloss: 0.263305\n",
      "[66]\ttraining's binary_logloss: 0.0444552\tvalid_1's binary_logloss: 0.264072\n",
      "[67]\ttraining's binary_logloss: 0.0427638\tvalid_1's binary_logloss: 0.266223\n",
      "[68]\ttraining's binary_logloss: 0.0412449\tvalid_1's binary_logloss: 0.266817\n",
      "[69]\ttraining's binary_logloss: 0.0398589\tvalid_1's binary_logloss: 0.267819\n",
      "[70]\ttraining's binary_logloss: 0.0383095\tvalid_1's binary_logloss: 0.267484\n",
      "[71]\ttraining's binary_logloss: 0.0368803\tvalid_1's binary_logloss: 0.270233\n",
      "[72]\ttraining's binary_logloss: 0.0355637\tvalid_1's binary_logloss: 0.268442\n",
      "[73]\ttraining's binary_logloss: 0.0341747\tvalid_1's binary_logloss: 0.26895\n",
      "[74]\ttraining's binary_logloss: 0.0328302\tvalid_1's binary_logloss: 0.266958\n",
      "[75]\ttraining's binary_logloss: 0.0317853\tvalid_1's binary_logloss: 0.268091\n",
      "[76]\ttraining's binary_logloss: 0.0305626\tvalid_1's binary_logloss: 0.266419\n",
      "[77]\ttraining's binary_logloss: 0.0295001\tvalid_1's binary_logloss: 0.268588\n",
      "[78]\ttraining's binary_logloss: 0.0284699\tvalid_1's binary_logloss: 0.270964\n",
      "[79]\ttraining's binary_logloss: 0.0273953\tvalid_1's binary_logloss: 0.270293\n",
      "[80]\ttraining's binary_logloss: 0.0264668\tvalid_1's binary_logloss: 0.270523\n",
      "[81]\ttraining's binary_logloss: 0.0254636\tvalid_1's binary_logloss: 0.270683\n",
      "[82]\ttraining's binary_logloss: 0.0245911\tvalid_1's binary_logloss: 0.273187\n",
      "[83]\ttraining's binary_logloss: 0.0236486\tvalid_1's binary_logloss: 0.275994\n",
      "[84]\ttraining's binary_logloss: 0.0228047\tvalid_1's binary_logloss: 0.274053\n",
      "[85]\ttraining's binary_logloss: 0.0221693\tvalid_1's binary_logloss: 0.273211\n",
      "[86]\ttraining's binary_logloss: 0.0213043\tvalid_1's binary_logloss: 0.272626\n",
      "[87]\ttraining's binary_logloss: 0.0203934\tvalid_1's binary_logloss: 0.27534\n",
      "[88]\ttraining's binary_logloss: 0.0195552\tvalid_1's binary_logloss: 0.276228\n",
      "[89]\ttraining's binary_logloss: 0.0188623\tvalid_1's binary_logloss: 0.27525\n",
      "[90]\ttraining's binary_logloss: 0.0183664\tvalid_1's binary_logloss: 0.276485\n",
      "[91]\ttraining's binary_logloss: 0.0176788\tvalid_1's binary_logloss: 0.277052\n",
      "[92]\ttraining's binary_logloss: 0.0170059\tvalid_1's binary_logloss: 0.277686\n",
      "[93]\ttraining's binary_logloss: 0.0164317\tvalid_1's binary_logloss: 0.275332\n",
      "[94]\ttraining's binary_logloss: 0.015878\tvalid_1's binary_logloss: 0.276236\n",
      "[95]\ttraining's binary_logloss: 0.0152959\tvalid_1's binary_logloss: 0.274538\n",
      "[96]\ttraining's binary_logloss: 0.0147216\tvalid_1's binary_logloss: 0.275244\n",
      "[97]\ttraining's binary_logloss: 0.0141758\tvalid_1's binary_logloss: 0.275829\n",
      "[98]\ttraining's binary_logloss: 0.0136551\tvalid_1's binary_logloss: 0.276654\n",
      "[99]\ttraining's binary_logloss: 0.0131585\tvalid_1's binary_logloss: 0.277859\n",
      "[100]\ttraining's binary_logloss: 0.0126961\tvalid_1's binary_logloss: 0.279265\n",
      "[101]\ttraining's binary_logloss: 0.0122421\tvalid_1's binary_logloss: 0.276695\n",
      "[102]\ttraining's binary_logloss: 0.0118067\tvalid_1's binary_logloss: 0.278488\n",
      "[103]\ttraining's binary_logloss: 0.0113994\tvalid_1's binary_logloss: 0.278932\n",
      "[104]\ttraining's binary_logloss: 0.0109799\tvalid_1's binary_logloss: 0.280997\n",
      "[105]\ttraining's binary_logloss: 0.0105953\tvalid_1's binary_logloss: 0.281454\n",
      "[106]\ttraining's binary_logloss: 0.0102381\tvalid_1's binary_logloss: 0.282058\n",
      "[107]\ttraining's binary_logloss: 0.00986714\tvalid_1's binary_logloss: 0.279275\n",
      "[108]\ttraining's binary_logloss: 0.00950998\tvalid_1's binary_logloss: 0.281427\n",
      "[109]\ttraining's binary_logloss: 0.00915965\tvalid_1's binary_logloss: 0.280752\n",
      "[110]\ttraining's binary_logloss: 0.00882581\tvalid_1's binary_logloss: 0.282152\n",
      "[111]\ttraining's binary_logloss: 0.00850714\tvalid_1's binary_logloss: 0.280894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "import lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "cancer_df = pd.DataFrame(data=dataset.data, columns=dataset.feature_names)\n",
    "cancer_df['target']=dataset.target\n",
    "\n",
    "X_features = cancer_df.iloc[:, :-1]\n",
    "y_label = cancer_df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_label, test_size=.2, random_state=156)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=.1, random_state=156)\n",
    "\n",
    "lgbm_wrapper = LGBMClassifier(n_estimators=400, learning_rate=.05)\n",
    "\n",
    "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
    "lgbm_wrapper.fit(X_tr, y_tr, early_stopping_rounds=50, eval_metric='logloss',\n",
    "                eval_set=evals, verbose=True)\n",
    "preds = lgbm_wrapper.predict(X_test)\n",
    "pred_proba = lgbm_wrapper.predict_proba(X_test)[:,1]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d12a1215-159b-45fb-a512-a272feacf6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[34  3]\n",
      " [ 2 75]]\n",
      "정확도: 0.9561, 정밀도: 0.9615, 재현율: 0.9740,    F1: 0.9677, AUC:0.9877\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(y_test, preds, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f77f9a3e-2d66-49d6-9828-618f70017e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='Feature importance', ylabel='Features'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lightgbm import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,12))\n",
    "plot_importance(lgbm_wrapper, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a3d70b-d506-4538-bef3-a4be06ba7ccd",
   "metadata": {},
   "source": [
    "# < HyperOpt > : 최적의 하이퍼 파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7e730e-b1f4-4456-bead-c38702618e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "- 사용 순서\n",
    "a.함수 설정 b.범위 설정 c.fmin()으로 x,y값 찾기\n",
    "    -> b,a,c\n",
    "    \n",
    "-hyperopt의 hp모듈을 사용하여 -20 - 20까지 2간격을 가지는 입력변수와\n",
    "x와 -15 - 15까지 1간격으로 입력변수 y를 설정하세요.\n",
    "from hyperopt import hp\n",
    "search_space={'x':hp.quniform(-20,20,2),\n",
    "             'y':hp.quniform(-15,15,1)}\n",
    "\n",
    "hyperopt를 사용할 때 목적함수의 변환값들을 어떠한 클래스 객체로 저장한다.\n",
    "이때 사용하는 클래스는?\n",
    "    -> Trials\n",
    "\n",
    "HyperOpt 적용하여 최적의 파라미터 값을 찾을 때,\n",
    "교차 검증 정확도의 평균에 -1을 곱하여 목적함수의 입력값(fmin()의 인수)으로 넣는 이유는 무엇인가?\n",
    "    -> 정확도는 높은 값일수록 좋은 성능을 지닌 지표라고 판단하는 반면,\n",
    "       fmin() 함수는 값이 작을수록 더 좋은 최적화로 판단하기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbd3aa3-038b-4dec-8ba5-80fb81df32d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1a47ee1-7d34-426e-bcf4-8bc59aeafa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 범위 설정\n",
    "from hyperopt import hp\n",
    "\n",
    "search_space = {'x': hp.quniform('x', -10, 10, 1), 'y': hp.quniform('y',-15,15,1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4377f097-eaac-4349-b727-5a5db24a5d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 함수 설정\n",
    "def objective_func(search_space):\n",
    "    x = search_space['x']\n",
    "    y = search_space['y']\n",
    "    retval = x**2 - 20*y\n",
    "    \n",
    "    return retval\n",
    "\n",
    "# x=0, y=-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c60ed68a-9796-4a69-aaf7-d5ac8c3abdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 입력값을 유추하기\n",
    "from hyperopt import fmin, tpe, Trials\n",
    "trails = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad41d40e-3aef-4fd3-88a8-b560a4b2fd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 385.41trial/s, best loss: -224.0]\n"
     ]
    }
   ],
   "source": [
    "# 3. fmin()으로 x,y값 찾기\n",
    "import numpy as np\n",
    "\n",
    "best02 = fmin(fn= objective_func, space= search_space, algo= tpe.suggest, max_evals= 5,\n",
    "    trials= trails, rstate= np.random.default_rng(seed=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c96f3f4b-53a7-4cf4-b076-fc1e8de9980f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': -4.0, 'y': 12.0}\n"
     ]
    }
   ],
   "source": [
    "print(best02)  # 최적화를 위한 x,y를 찾아줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22171145-a1c0-4010-8e42-3f8c2dbd7961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 172.43trial/s, best loss: -299.0]\n",
      "{'x': -1.0, 'y': 15.0}\n"
     ]
    }
   ],
   "source": [
    "best03 = fmin(fn= objective_func, space= search_space, algo= tpe.suggest, max_evals= 100,  # 100번을 다시 돌렸다.\n",
    "    trials= trails, rstate= np.random.default_rng(seed=0))\n",
    "print(best03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5cbb30-c59a-435a-9ac0-d327158d8602",
   "metadata": {},
   "source": [
    "정확한 값을 바로 내진 못했지만 거의 근접한 값을 내주고 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a92e62aa-91fe-4c67-9fd1-09a221c3a2c0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trails' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 속성확인\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrails\u001b[49m\u001b[38;5;241m.\u001b[39mresults\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trails' is not defined"
     ]
    }
   ],
   "source": [
    "# 속성확인\n",
    "trails.results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f6f6d0-de19-4577-9487-368eb4066181",
   "metadata": {},
   "source": [
    "## -> 본격적으로 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aeddd13-7eb6-4432-adfe-7e9d85d84e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 50/50 [00:05<00:00,  9.94trial/s, best loss: -0.9670616939700244]\n",
      "best: {'colsample_bytree': 0.5424149213362504, 'learning_rate': 0.12601372924444681, 'max_depth': 17.0, 'min_child_weight': 2.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "X = features = dataset.data\n",
    "y = labels = dataset.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=.2, random_state=156)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=.1, random_state=156)\n",
    "\n",
    "from hyperopt import hp\n",
    "\n",
    "# max_depth는 5에서 20까지 1간격으로, min_child_weight는 1에서 2까지 1간격으로\n",
    "# colsample_bytree는 0.5에서 1사이, learning_rate는 0.01에서 0.2 사이 정규 분포된 값으로 검색.\n",
    "xgb_search_space = {'max_depth': hp.quniform('max_depth', 5, 20, 1), \n",
    "                    'min_child_weight': hp.quniform('min_child_weight', 1, 2, 1),\n",
    "                    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "                    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "                   }\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import STATUS_OK\n",
    "\n",
    "# fmin()에서 입력된 search_space 값으로 입력된 모든 값은 실수형임.\n",
    "# XGBClassifier의 정수형 하이퍼 파라미터는 정수형 변환을 해줘야 함.\n",
    "# 정확도는 높을수록 더 좋은 수치임. -1 * 정확도를 곱해서 큰 정확도 값일수록 최소가 되도록 변환\n",
    "def objective_func(search_space):\n",
    "    # 수행 시간 절약을 위해 nestimators는 100으로 축소\n",
    "    xgb_clf = XGBClassifier(n_estimators=100, max_depth=int(search_space['max_depth']),\n",
    "                            min_child_weight=int(search_space['min_child_weight']),\n",
    "                            learning_rate=search_space['learning_rate'],\n",
    "                            colsample_bytree=search_space['colsample_bytree'],\n",
    "                            eval_metric='logloss')\n",
    "    accuracy = cross_val_score(xgb_clf, X_train, y_train, scoring='accuracy', cv=3)\n",
    "    \n",
    "    # accuracy는 cv=3 개수만큼 roc-auc 결과를 리스트로 가짐. 이를 평균해서 반환하되 -1을 곱함.\n",
    "    return {'loss':-1 * np.mean(accuracy), 'status': STATUS_OK} \n",
    "\n",
    "from hyperopt import fmin, tpe, Trials\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "trial_val = Trials()\n",
    "best = fmin(fn=objective_func,\n",
    "            space=xgb_search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50, # 최대 반복 횟수를 지정합니다.\n",
    "            trials=trial_val, rstate=np.random.default_rng(seed=9))\n",
    "print('best:', best) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47947bdd-e854-4e7d-b15f-6fe74912e9b2",
   "metadata": {},
   "source": [
    "## -> 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f953e83d-5229-4c03-bd09-806f76143386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:28:00] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xgb_clf = XGBClassifier(n_estimators=100, max_depth=17,\n",
    "                            min_child_weight=2,\n",
    "                            learning_rate=.126,\n",
    "                            colsample_bytree=.54)\n",
    "\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "preds = xgb_clf.predict(X_test)\n",
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570ccc58-9a30-4a2d-bc95-67e40c9410e0",
   "metadata": {},
   "source": [
    "# < SMOTE >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5803b1d-22e7-4d2c-b308-cc8f1d1278ba",
   "metadata": {},
   "source": [
    "- Credit card fraud detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef429caf-1a6a-4d59-87a2-ab7bc1503b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "card = pd.read_csv('creditcard.csv')\n",
    "card.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c14f917-2037-4be0-afc6-13d0acf62ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "card.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d04bdd-07ee-4ce9-975d-fb6af4773344",
   "metadata": {},
   "source": [
    "- LogisticRegression 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6621000c-a281-4ab3-ac60-25aeb246d8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998275\n",
       "1    0.001725\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Time 칼럼을 삭제하기\n",
    "card = card.drop(['Time'], axis = 1)\n",
    "\n",
    "# 2. 데이터셋 분리\n",
    "from sklearn.model_selection  import train_test_split\n",
    "features = card.iloc[:, :-1]\n",
    "labels = card.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = .3, stratify = labels) \n",
    "\n",
    "y_train.value_counts()/len(y_train) #len(y_train)은 전체값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72c4e14d-d057-4c7b-984d-10790cc7787f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[85282    13]\n",
      " [   62    86]]\n",
      "정확도: 0.9991, 정밀도: 0.8687, 재현율: 0.5811,    F1: 0.6964, AUC:0.9745\n"
     ]
    }
   ],
   "source": [
    "# 3. 모델 생성하고 fit, predict, evaluate하기\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_clf = LogisticRegression(max_iter = 1000) #반복개수를 1000번\n",
    "lr_clf.fit(X_train, y_train)\n",
    "preds = lr_clf.predict(X_test)\n",
    "preds_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc)) \n",
    "    \n",
    "get_clf_eval(y_test, preds, preds_proba) #AUC 값을 내려고 preds_proba 시용함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151198d7-16aa-40e2-8f38-b03b5f3286c8",
   "metadata": {},
   "source": [
    "- LGBMClassifier 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b328e7dd-6e45-4772-aeec-84373978ecbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[85290     5]\n",
      " [   30   118]]\n",
      "정확도: 0.9996, 정밀도: 0.9593, 재현율: 0.7973,    F1: 0.8708, AUC:0.9785\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf =LGBMClassifier(n_estimators = 1000, num_leaves= 64, n_jobs= -1, boost_from_average= False) \n",
    "lgbm_clf.fit(X_train, y_train)\n",
    "preds = lgbm_clf.predict(X_test)\n",
    "preds_proba = lgbm_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "get_clf_eval(y_test, preds, preds_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931ef892-44e8-4aa3-8c4a-7d1d49ff9377",
   "metadata": {},
   "source": [
    "아까 91에서 117로 늘어났다.(높아졌다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3876d26e-6e0b-4883-a5cf-8e62468b9201",
   "metadata": {},
   "source": [
    "## -> 데이터 정제(Scaling) 후 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3df170e7-d831-4e69-a737-3225992b073a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    284807.000000\n",
       "mean         88.349619\n",
       "std         250.120109\n",
       "min           0.000000\n",
       "25%           5.600000\n",
       "50%          22.000000\n",
       "75%          77.165000\n",
       "max       25691.160000\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card['Amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79e35496-0980-4bc2-9059-d6676b731354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "\n",
       "        V25       V26       V27       V28    Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  0.244964      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724 -0.342475      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  1.160686      0  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 표준화 하기\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "card['Amount'] = scaler.fit_transform(card['Amount'].values.reshape(-1,1))\n",
    "card[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82fc82b3-1c98-4334-b055-24ba9eed0411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[85284    11]\n",
      " [   55    93]]\n",
      "정확도: 0.9992, 정밀도: 0.8942, 재현율: 0.6284,    F1: 0.7381, AUC:0.9690\n"
     ]
    }
   ],
   "source": [
    "# 표준화 후 결과\n",
    "from sklearn.model_selection  import train_test_split\n",
    "features = card.iloc[:, :-1]\n",
    "labels = card.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = .3, stratify = labels)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression(max_iter = 1000) #반복개수를 1000번\n",
    "lr_clf.fit(X_train, y_train)\n",
    "preds = lr_clf.predict(X_test)\n",
    "preds_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "get_clf_eval(y_test, preds, preds_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69b24bef-64bc-4ee7-927d-c3e3bc33d867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[85292     3]\n",
      " [   32   116]]\n",
      "정확도: 0.9996, 정밀도: 0.9748, 재현율: 0.7838,    F1: 0.8689, AUC:0.9804\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf =LGBMClassifier(n_estimators = 1000, num_leaves= 64, n_jobs= -1, boost_from_average= False) \n",
    "lgbm_clf.fit(X_train, y_train)\n",
    "preds = lgbm_clf.predict(X_test)\n",
    "preds_proba = lgbm_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "get_clf_eval(y_test, preds, preds_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3042bd-767a-4859-8a53-feee6529e648",
   "metadata": {},
   "source": [
    "## -> 데이터 정제(로그변환) 후 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1866fe5b-db0f-4109-bb9b-d29eba30d242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>5.014760</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>1.305626</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>5.939276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "\n",
       "        V25       V26       V27       V28    Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  5.014760      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724  1.305626      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  5.939276      0  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "card = pd.read_csv('creditcard.csv')\n",
    "card = card.drop(['Time'], axis = 1)\n",
    "\n",
    "# 로그변환 하기\n",
    "card['Amount'] = np.log1p(card['Amount'])\n",
    "card[:3]  #로그를 사용하는 이유: 숫자가 너무 커서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e14f2493-689e-4f1a-bd61-eca5d43ad02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[85276    19]\n",
      " [   49    99]]\n",
      "정확도: 0.9992, 정밀도: 0.8390, 재현율: 0.6689,    F1: 0.7444, AUC:0.9779\n",
      "None\n",
      "\n",
      "오차 행렬\n",
      "[[85287     8]\n",
      " [   28   120]]\n",
      "정확도: 0.9996, 정밀도: 0.9375, 재현율: 0.8108,    F1: 0.8696, AUC:0.9814\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "features = card.iloc[:, :-1]\n",
    "labels = card.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = .3, stratify = labels)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression(max_iter = 1000)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "preds = lr_clf.predict(X_test)\n",
    "preds_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(get_clf_eval(y_test, preds, preds_proba))\n",
    "print()\n",
    "\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf =LGBMClassifier(n_estimators = 1000, num_leaves= 64, n_jobs= -1, boost_from_average= False) \n",
    "lgbm_clf.fit(X_train, y_train)\n",
    "preds = lgbm_clf.predict(X_test)\n",
    "preds_proba = lgbm_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(get_clf_eval(y_test, preds, preds_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df334e71-4120-42e6-9adf-fd61a28ea0a9",
   "metadata": {},
   "source": [
    "## -> 이상치 데이터 제거 후 모델 학습 /예측 /평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df02400f-c4c6-4d16-b300-6925f118a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 이상치 찾기\n",
    "IQR = 3/4 - 1/4\n",
    "\n",
    "3/4 + 1.5IQR\n",
    "1/4 - 1.5IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73ba7add-5a99-48f1-9aba-551a4a6c662f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b4f046b-3ccb-4c44-96ae-93de27e6f01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>-2.772272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>-0.838587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>6.272877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>-1.525412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>5.484506</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>-4.801637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>4.094345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>-2.447469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279863</th>\n",
       "      <td>-1.927883</td>\n",
       "      <td>1.125653</td>\n",
       "      <td>-4.518331</td>\n",
       "      <td>1.749293</td>\n",
       "      <td>-1.566487</td>\n",
       "      <td>-2.010494</td>\n",
       "      <td>-0.882850</td>\n",
       "      <td>0.697211</td>\n",
       "      <td>-2.064945</td>\n",
       "      <td>-5.587794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778584</td>\n",
       "      <td>-0.319189</td>\n",
       "      <td>0.639419</td>\n",
       "      <td>-0.294885</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>0.788395</td>\n",
       "      <td>0.292680</td>\n",
       "      <td>0.147968</td>\n",
       "      <td>5.968708</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280143</th>\n",
       "      <td>1.378559</td>\n",
       "      <td>1.289381</td>\n",
       "      <td>-5.004247</td>\n",
       "      <td>1.411850</td>\n",
       "      <td>0.442581</td>\n",
       "      <td>-1.326536</td>\n",
       "      <td>-1.413170</td>\n",
       "      <td>0.248525</td>\n",
       "      <td>-1.127396</td>\n",
       "      <td>-3.232153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370612</td>\n",
       "      <td>0.028234</td>\n",
       "      <td>-0.145640</td>\n",
       "      <td>-0.081049</td>\n",
       "      <td>0.521875</td>\n",
       "      <td>0.739467</td>\n",
       "      <td>0.389152</td>\n",
       "      <td>0.186637</td>\n",
       "      <td>0.565314</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280149</th>\n",
       "      <td>-0.676143</td>\n",
       "      <td>1.126366</td>\n",
       "      <td>-2.213700</td>\n",
       "      <td>0.468308</td>\n",
       "      <td>-1.120541</td>\n",
       "      <td>-0.003346</td>\n",
       "      <td>-2.234739</td>\n",
       "      <td>1.210158</td>\n",
       "      <td>-0.652250</td>\n",
       "      <td>-3.463891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751826</td>\n",
       "      <td>0.834108</td>\n",
       "      <td>0.190944</td>\n",
       "      <td>0.032070</td>\n",
       "      <td>-0.739695</td>\n",
       "      <td>0.471111</td>\n",
       "      <td>0.385107</td>\n",
       "      <td>0.194361</td>\n",
       "      <td>4.368054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281144</th>\n",
       "      <td>-3.113832</td>\n",
       "      <td>0.585864</td>\n",
       "      <td>-5.399730</td>\n",
       "      <td>1.817092</td>\n",
       "      <td>-0.840618</td>\n",
       "      <td>-2.943548</td>\n",
       "      <td>-2.208002</td>\n",
       "      <td>1.058733</td>\n",
       "      <td>-1.632333</td>\n",
       "      <td>-5.245984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583276</td>\n",
       "      <td>-0.269209</td>\n",
       "      <td>-0.456108</td>\n",
       "      <td>-0.183659</td>\n",
       "      <td>-0.328168</td>\n",
       "      <td>0.606116</td>\n",
       "      <td>0.884876</td>\n",
       "      <td>-0.253700</td>\n",
       "      <td>5.505332</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281674</th>\n",
       "      <td>1.991976</td>\n",
       "      <td>0.158476</td>\n",
       "      <td>-2.583441</td>\n",
       "      <td>0.408670</td>\n",
       "      <td>1.151147</td>\n",
       "      <td>-0.096695</td>\n",
       "      <td>0.223050</td>\n",
       "      <td>-0.068384</td>\n",
       "      <td>0.577829</td>\n",
       "      <td>-0.888722</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164350</td>\n",
       "      <td>-0.295135</td>\n",
       "      <td>-0.072173</td>\n",
       "      <td>-0.450261</td>\n",
       "      <td>0.313267</td>\n",
       "      <td>-0.289617</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>-0.015309</td>\n",
       "      <td>3.773450</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "541    -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545 -2.537387   \n",
       "623    -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823  0.325574   \n",
       "4920   -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788  0.562320   \n",
       "6108   -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536 -3.496197   \n",
       "6329    1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746  1.713445   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "279863 -1.927883  1.125653 -4.518331  1.749293 -1.566487 -2.010494 -0.882850   \n",
       "280143  1.378559  1.289381 -5.004247  1.411850  0.442581 -1.326536 -1.413170   \n",
       "280149 -0.676143  1.126366 -2.213700  0.468308 -1.120541 -0.003346 -2.234739   \n",
       "281144 -3.113832  0.585864 -5.399730  1.817092 -0.840618 -2.943548 -2.208002   \n",
       "281674  1.991976  0.158476 -2.583441  0.408670  1.151147 -0.096695  0.223050   \n",
       "\n",
       "              V8        V9       V10  ...       V21       V22       V23  \\\n",
       "541     1.391657 -2.770089 -2.772272  ...  0.517232 -0.035049 -0.465211   \n",
       "623    -0.067794 -0.270953 -0.838587  ...  0.661696  0.435477  1.375966   \n",
       "4920   -0.399147 -0.238253 -1.525412  ... -0.294166 -0.932391  0.172726   \n",
       "6108   -0.248778 -0.247768 -4.801637  ...  0.573574  0.176968 -0.436207   \n",
       "6329   -0.496358 -1.282858 -2.447469  ... -0.379068 -0.704181 -0.656805   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "279863  0.697211 -2.064945 -5.587794  ...  0.778584 -0.319189  0.639419   \n",
       "280143  0.248525 -1.127396 -3.232153  ...  0.370612  0.028234 -0.145640   \n",
       "280149  1.210158 -0.652250 -3.463891  ...  0.751826  0.834108  0.190944   \n",
       "281144  1.058733 -1.632333 -5.245984  ...  0.583276 -0.269209 -0.456108   \n",
       "281674 -0.068384  0.577829 -0.888722  ... -0.164350 -0.295135 -0.072173   \n",
       "\n",
       "             V24       V25       V26       V27       V28    Amount  Class  \n",
       "541     0.320198  0.044519  0.177840  0.261145 -0.143276  0.000000      1  \n",
       "623    -0.293803  0.279798 -0.145362 -0.252773  0.035764  6.272877      1  \n",
       "4920   -0.087330 -0.156114 -0.542628  0.039566 -0.153029  5.484506      1  \n",
       "6108   -0.053502  0.252405 -0.657488 -0.827136  0.849573  4.094345      1  \n",
       "6329   -1.632653  1.488901  0.566797 -0.010016  0.146793  0.693147      1  \n",
       "...          ...       ...       ...       ...       ...       ...    ...  \n",
       "279863 -0.294885  0.537503  0.788395  0.292680  0.147968  5.968708      1  \n",
       "280143 -0.081049  0.521875  0.739467  0.389152  0.186637  0.565314      1  \n",
       "280149  0.032070 -0.739695  0.471111  0.385107  0.194361  4.368054      1  \n",
       "281144 -0.183659 -0.328168  0.606116  0.884876 -0.253700  5.505332      1  \n",
       "281674 -0.450261  0.313267 -0.289617  0.002988 -0.015309  3.773450      1  \n",
       "\n",
       "[492 rows x 30 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 조건에 만족하는 것을 뽑아내었다.\n",
    "fraud = card[card['Class'] == 1]\n",
    "fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "643542e3-9ea0-420b-b0d1-e9786df8f1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8296   -19.214325\n",
       "8615   -18.822087\n",
       "9035   -18.493773\n",
       "9252   -18.049998\n",
       "Name: V14, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fraud['V14'] <- 여기서 이상치 찾아내기\n",
    "pct25 = np.percentile(fraud.V14, 25)\n",
    "pct75 = np.percentile(fraud.V14, 75)\n",
    "\n",
    "IQR = pct75 - pct25\n",
    "\n",
    "upper_out = pct75 + 1.5 * IQR\n",
    "under_out = pct25 - 1.5 * IQR\n",
    "\n",
    "cond1 = fraud['V14'] >= upper_out\n",
    "cond2 = fraud['V14'] <= under_out\n",
    "fraud.V14[cond1 | cond2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c524733-bd9f-478e-8bca-96db6aecd280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([8296, 8615, 9035, 9252], dtype='int64')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier = fraud[(fraud['V14'] > upper_out) | (fraud['V14'] < under_out)]\n",
    "outlier.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d59b890e-37af-4593-84ba-e1833ea09500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>5.014760</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>1.305626</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>5.939276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "\n",
       "        V25       V26       V27       V28    Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  5.014760      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724  1.305626      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  5.939276      0  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card.drop(outlier.index, axis=0, inplace=True)\n",
    "card[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0341ea6f-289d-4395-b865-0a6b8e39a398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[85283    12]\n",
      " [   60    86]]\n",
      "정확도: 0.9992, 정밀도: 0.8776, 재현율: 0.5890,    F1: 0.7049, AUC:0.9814\n",
      "None\n",
      "\n",
      "오차 행렬\n",
      "[[85289     6]\n",
      " [   25   121]]\n",
      "정확도: 0.9996, 정밀도: 0.9528, 재현율: 0.8288,    F1: 0.8864, AUC:0.9819\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "features = card.iloc[:, :-1]\n",
    "labels = card.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = .3, stratify = labels)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression(max_iter = 1000)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "preds = lr_clf.predict(X_test)\n",
    "preds_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(get_clf_eval(y_test, preds, preds_proba))\n",
    "print()\n",
    "\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf =LGBMClassifier(n_estimators = 1000, num_leaves= 64, n_jobs= -1, boost_from_average= False) \n",
    "lgbm_clf.fit(X_train, y_train)\n",
    "preds = lgbm_clf.predict(X_test)\n",
    "preds_proba = lgbm_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(get_clf_eval(y_test, preds, preds_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caed336-d42e-4909-8d5f-aed605efbd85",
   "metadata": {},
   "source": [
    "## -> SMOTE로 오버샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65b93699-662a-455e-92bf-179981703e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[83349  1946]\n",
      " [   17   129]]\n",
      "정확도: 0.9770, 정밀도: 0.0622, 재현율: 0.8836,    F1: 0.1162, AUC:0.9724\n",
      "None\n",
      "\n",
      "오차 행렬\n",
      "[[85280    15]\n",
      " [   34   112]]\n",
      "정확도: 0.9994, 정밀도: 0.8819, 재현율: 0.7671,    F1: 0.8205, AUC:0.9670\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 데이터셋 분리\n",
    "features = card.iloc[:, :-1]\n",
    "labels = card.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = .3, stratify = labels)\n",
    "\n",
    "# SMOTE 적용\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train) #y_train을 oversampling해주었다.\n",
    "\n",
    "# 모델 생성1\n",
    "lr_clf = LogisticRegression(max_iter = 1000)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "preds = lr_clf.predict(X_test)\n",
    "preds_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(get_clf_eval(y_test, preds, preds_proba))\n",
    "print()\n",
    "\n",
    "#모델 생성2\n",
    "lgbm_clf =LGBMClassifier(n_estimators = 1000, num_leaves= 64, n_jobs= -1, boost_from_average= False) \n",
    "lgbm_clf.fit(X_train, y_train)\n",
    "preds = lgbm_clf.predict(X_test)\n",
    "preds_proba = lgbm_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(get_clf_eval(y_test, preds, preds_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260f2a17-2b86-44ed-858b-d528fcef34ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "false가 많아졌는데 이유는 oversampling을 했기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cf5efc-8367-46ca-8d2d-c0ec84d390e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
