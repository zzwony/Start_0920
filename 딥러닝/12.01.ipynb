{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf9df234-9dbd-486b-9091-4294e5d1b468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[1.],\n",
       "       [1.]], dtype=float32)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모두 1 또는 0인 텐서\n",
    "import tensorflow as tf\n",
    "x = tf.ones(shape=(2,1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de0179e-528e-4b25-9d74-18873c43dd09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[0.],\n",
       "       [0.]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.zeros(shape=(2,1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8830f4ea-edef-4184-b8a4-f92dd66bb9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
       "array([[-0.21667375],\n",
       "       [-2.2618635 ],\n",
       "       [-0.6545166 ]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤 텐서\n",
    "x = tf.random.normal(shape=(3,1), mean=0, stddev=1.)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f30685-1a96-4507-b680-36ecb2b98e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
       "array([[0.26768947],\n",
       "       [0.80077565],\n",
       "       [0.17020035]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform(shape=(3,1), minval=0, maxval=1.)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3e8c0fb-9056-4e80-88b6-b257e5d23ac0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 텐서플로 텐서에 값을 할당하지 못함\u001b[39;00m\n\u001b[0;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mones(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m x[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "# 텐서플로 텐서에 값을 할당하지 못함\n",
    "x = tf.ones(shape=(2,2))\n",
    "x[0, 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928873cc-659a-4090-8146-1b1e79a497c3",
   "metadata": {},
   "source": [
    "```\n",
    "튜플처럼 에러가 발생한다.\n",
    "해결 방법은 이걸 변할수 있게 하는 Variable() 안에 넣어주면 변경 가능하게 해준다.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6706434-54b4-4d8a-acdf-591461c59270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ae8a3fe-f945-4b51-9eba-618231876c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 2) dtype=float32, numpy=\n",
       "array([[10.,  1.],\n",
       "       [ 1.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0].assign(10)   # 할당해주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8362365-2ba4-4499-815b-defef0c78920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 2) dtype=float32, numpy=\n",
       "array([[11.,  2.],\n",
       "       [ 2.,  2.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.assign_add(tf.ones((2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6255008-8a88-48d2-b20c-49ad71d8f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientTape\n",
    "input_var = tf.Variable(initial_value=3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    result = tf.square(input_var)\n",
    "gradient = tape.gradient(result, input_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3dec401-69aa-4a90-b74a-51337c38d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상수 텐서 입력과 Gradient Tape\n",
    "input_const = tf.constant(3.) # constant는 상수라는 뜻\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(input_const)  # watch는 잘 감시하라는 것\n",
    "    result = tf.square(input_const)\n",
    "gradient = tape.gradient(result, input_const)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca8e062-272b-45e1-ab8c-da44b019c507",
   "metadata": {},
   "source": [
    "```\n",
    "텐서플로는 기본적으로 훈련 가능한 변수만 추적한다.\n",
    "상수 텐서의 경우 tape.watch()를 호출하여 추적한다는 것을 수동으로 알려줘야 한다.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34ab9b9d-859c-4bb2-9419-4a672276d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중첩 Gradient Tape(이계 도함수)\n",
    "time = tf.Variable(10.)  # time은 10\n",
    "with tf.GradientTape() as outer_tape:\n",
    "    with tf.GradientTape() as inner_tape:\n",
    "        position = 4.9 * time**2\n",
    "    speed = inner_tape.gradient(position, time)  # speed = 4.9 * 2 * time\n",
    "acceleration = outer_tape.gradient(speed, time)  # acceleration의 결과물은 9.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23b7914e-e94e-4772-a40c-3de9f397913e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=98.0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45568077-e705-46e0-aa25-7186b4e67be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=9.8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca402ed1-cda9-4eba-a6ba-e74e86bc167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = tf.Variable(tf.ones((2,2)))\n",
    "with tf.GradientTape() as outer_tape:\n",
    "    with tf.GradientTape() as inner_tape:\n",
    "        position = 4.9 * time**2\n",
    "    speed = inner_tape.gradient(position, time)\n",
    "acceleration = outer_tape.gradient(speed, time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5eb5c1-c0bf-4e65-8199-8ba457c730f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0481a01b-3d97-44d6-b3dc-be474d6ea44e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9208c7-b528-449e-8b50-eb4f9fd2690f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7015d2b-0d66-421f-804e-515d97e0826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer의 서브클래스로 구현한 Dense 층\n",
    "from tensorflow import keras\n",
    "\n",
    "class SimpleDense(keras.layers.Layer):  ## 새로 만드는 댄스 레이어는 위에서 레이어를 만들어놓은것을 그대로 상속받았다는것\n",
    "\n",
    "\n",
    "    def __init__(self, units, activation=None):\n",
    "        super(SimpleDense, self).__init__()   ##중요. 위에서 상속받을때 부모클래스인 Layer에서 init가 오버리아딩 되니까 위의 부모클래서 init를 불러오라는것\n",
    "\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "\n",
    "    def build(self, input_shape):  ## 여기서 가중치의 틀을 잡아준다.ihputshape가 들어옴\n",
    "        input_dim = input_shape[-1]  ## -1은 맨 뒤어꺼만 똑 땐다.\n",
    "        self.W = self.add_weight(shape=(input_dim, self.units),\n",
    "                    ## add_weight( )는 가중치를 간편하게 만들 수 있는 메서드이다.\n",
    "                    ## 이 메서드는 독립적으로 변수를 생성하고 층의 속성으로 할당할 수도 있다.\n",
    "                                 initializer='random_normal')  ## 초기값 설정\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                 initializer='zeros')\n",
    "\n",
    "    def call(self, inputs):  ## 처리하는 연산을 call을 통해 만들기\n",
    "        y = tf.matmul(inputs, self.W) + self.b\n",
    "        if self.activation is not None:\n",
    "            y = self.activation(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03aba0ec-9066-4860-a4c0-2084dc52ce86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 32])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인스턴스가 마치 함수처럼 사용된다.\n",
    "\n",
    "my_dense = SimpleDense(units=32, activation=tf.nn.relu)  ## activation은 위의 self.activation에 들어간다.\n",
    "input_tensor = tf.ones(shape=(2, 784))\n",
    "output_tensor = my_dense(input_tensor)\n",
    "\n",
    "output_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f37b98-4106-4550-9ab1-fd3cd80cd4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dense = SimpleDense(units=32, activation=tf.nn.relu)\n",
    "input_tensor = tf.ones(shape=(2, 784))\n",
    "output_tensor = my_dense(input_tensor)\n",
    "\n",
    "output_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777b214d-c034-44b0-8d4d-5d3ecc778fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92f04ba0-374b-4f25-be1b-bad209f8e264",
   "metadata": {},
   "source": [
    "손실함수 종류 3가지 정리해두기 p138\n",
    "올바른 손실 함수 선택하기 p232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46962ece-6912-4b46-8e5f-214ee4a5db41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1db8c54-f9d1-4d85-bc4e-aa83e689a195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cbba44cb-56fe-43ea-ba6a-6cdece6704bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.arange(1, 31)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf98d70a-b96a-4c5e-86e9-518be3b85035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8:2로 나누고 섞기\n",
    "np.random.shuffle(x)\n",
    "num = int(len(x)*0.8)\n",
    "train_data = x[:num]\n",
    "train_val = x[num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b9855568-a365-405c-92fc-41dd4d98c604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 24,  6, 13, 26, 22,  2, 18, 23, 29, 20, 21, 27, 19,  8,  5,  9,\n",
       "        4,  7, 14, 12,  1, 15, 10])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "747377a4-6a7e-49a5-8383-93d18cd5d3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 28, 16, 11, 30, 25])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3776b909-1581-4c69-a94b-24a3343ebfbb",
   "metadata": {},
   "source": [
    "```\n",
    "위에와 동일 방법\n",
    "train_test_split(x, test_size=0.2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722cbb3e-1edb-4de6-8159-3e93dced49d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bab6e6-4c77-4b5b-af15-c0410176fec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a18e6a-ddb0-4cdb-8239-1b0f19c4d299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c98991a5-b5ad-419f-9b7e-8bbe4b2bdb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "795e965f-4fcf-48eb-8918-c7ff9fad09d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\anaconda3\\lib\\site-packages (from kaggle) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\admin\\anaconda3\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\lib\\site-packages (from kaggle) (2.27.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\anaconda3\\lib\\site-packages (from kaggle) (4.64.0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\admin\\anaconda3\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from kaggle) (1.26.9)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tqdm->kaggle) (0.4.4)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73049 sha256=2883abedad7830979807eb1d6bb10dad62ee7d8b91660336fb821d6d030695e2\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\ac\\b2\\c3\\fa4706d469b5879105991d1c8be9a3c2ef329ba9fe2ce5085e\n",
      "Successfully built kaggle\n",
      "Installing collected packages: kaggle\n",
      "Successfully installed kaggle-1.5.12\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c38511f9-6503-4637-aab3-21ca2696b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2c08a435-19cb-4d1f-8da1-8c1ea6554c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dir = pathlib.Path('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "824517e3-9788-4afe-8fb0-a474301d5b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_base_dir = pathlib.Path('cats_vs_dogs_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7e0fb134-dd36-41e4-bbea-ab90e3fc3292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in ('cat', 'dog'):\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        os.makedirs(dir)\n",
    "        fnames = [f'{category}.{i}.jpg'\n",
    "                 for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=original_dir / fname,\n",
    "                           dst=dir / fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e165768d-3c8a-41de-9e13-bae7318be8ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train\\\\cat.1.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [93]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmake_subset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m make_subset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m, start_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, end_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1500\u001b[39m)\n\u001b[0;32m      3\u001b[0m make_subset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, start_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1500\u001b[39m, end_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2500\u001b[39m)\n",
      "Input \u001b[1;32mIn [92]\u001b[0m, in \u001b[0;36mmake_subset\u001b[1;34m(subset_name, start_index, end_index)\u001b[0m\n\u001b[0;32m      5\u001b[0m fnames \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_index, end_index)]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moriginal_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mdst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\shutil.py:264\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    262\u001b[0m     os\u001b[38;5;241m.\u001b[39msymlink(os\u001b[38;5;241m.\u001b[39mreadlink(src), dst)\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[0;32m    267\u001b[0m                 \u001b[38;5;66;03m# macOS\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train\\\\cat.1.jpg'"
     ]
    }
   ],
   "source": [
    "make_subset('train', start_index=0, end_index=1000)\n",
    "make_subset('validation', start_index=1000, end_index=1500)\n",
    "make_subset('test', start_index=1500, end_index=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506c4d7c-db56-451e-bf8e-0d4dd769f3c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644a0900-5c50-4e22-bf24-dbf9daf681f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b16a13-f0df-4a9e-909e-6aae7ccfecf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53951b6c-2666-4326-ad56-bf0867073664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5e2a3a-6665-48e8-aa79-2cc6be1e20d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d31423c-f516-4ee1-a066-b81678b85b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6590307-bcf3-4fd8-8291-060fd0ddbb59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1574a81-18d9-4bcd-928a-a1fea06b0a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0f670235-ff1d-4cfa-b59e-9b80a2670b76",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train\\\\cat.0.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [84]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[0;32m     13\u001b[0m             shutil\u001b[38;5;241m.\u001b[39mcopyfile(src\u001b[38;5;241m=\u001b[39moriginal_dir \u001b[38;5;241m/\u001b[39m fname,\n\u001b[0;32m     14\u001b[0m                            dst\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m/\u001b[39m fname)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mmake_subset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m make_subset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m, start_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, end_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1500\u001b[39m)\n\u001b[0;32m     18\u001b[0m make_subset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, start_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1500\u001b[39m, end_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2500\u001b[39m)\n",
      "Input \u001b[1;32mIn [84]\u001b[0m, in \u001b[0;36mmake_subset\u001b[1;34m(subset_name, start_index, end_index)\u001b[0m\n\u001b[0;32m     10\u001b[0m fnames \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     11\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_index, end_index)]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[1;32m---> 13\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moriginal_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mdst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\shutil.py:264\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    262\u001b[0m     os\u001b[38;5;241m.\u001b[39msymlink(os\u001b[38;5;241m.\u001b[39mreadlink(src), dst)\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[0;32m    267\u001b[0m                 \u001b[38;5;66;03m# macOS\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train\\\\cat.0.jpg'"
     ]
    }
   ],
   "source": [
    "# 이미지를 훈련, 검증, 테스트 디렉터리로 복사하기\n",
    "import os, shutil, pathlib\n",
    "\n",
    "original_dir = pathlib.Path('train')\n",
    "new_base_dir = pathlib.Path('cat_vs_dogs_small')\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in ('cat', 'dog'):\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        os.makedirs(dir)\n",
    "        fnames = [f'{category}.{i}.jpg'\n",
    "                 for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=original_dir / fname,\n",
    "                           dst=dir / fname)\n",
    "\n",
    "make_subset('train', start_index=0, end_index=1000)\n",
    "make_subset('validation', start_index=1000, end_index=1500)\n",
    "make_subset('test', start_index=1500, end_index=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6bdae21a-693f-4148-ae02-cfa8e34d34c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 강아지 vs 고양이 분류 모델 만들기\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b539bf96-b8f5-4889-b31f-44dbc753b056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 180, 180, 3)]     0         \n",
      "                                                                 \n",
      " rescaling_2 (Rescaling)     (None, 180, 180, 3)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 178, 178, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 89, 89, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 87, 87, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 43, 43, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 41, 41, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 20, 20, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 18, 18, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 9, 9, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 7, 7, 256)         590080    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 12545     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 991,041\n",
      "Trainable params: 991,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "57f6a47f-0c0d-4ab4-956d-9695743c74e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련 설정하기\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='rmsprop',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "96c4e620-642e-4d06-b89a-7a3394c76329",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_base_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [75]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image_dataset_from_directory\n\u001b[0;32m      3\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m image_dataset_from_directory(\n\u001b[1;32m----> 4\u001b[0m                 \u001b[43mnew_base_dir\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m                 image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m180\u001b[39m, \u001b[38;5;241m180\u001b[39m),\n\u001b[0;32m      6\u001b[0m                 batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m      8\u001b[0m validation_dataset \u001b[38;5;241m=\u001b[39m image_dataset_from_directory(\n\u001b[0;32m      9\u001b[0m                         new_base_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m                         image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m180\u001b[39m, \u001b[38;5;241m180\u001b[39m),\n\u001b[0;32m     11\u001b[0m                         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m     13\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m image_dataset_from_directory(\n\u001b[0;32m     14\u001b[0m                 new_base_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     15\u001b[0m                 image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m180\u001b[39m, \u001b[38;5;241m180\u001b[39m),\n\u001b[0;32m     16\u001b[0m                 batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_base_dir' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / 'train',\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "                        new_base_dir / 'validation',\n",
    "                        image_size=(180, 180),\n",
    "                        batch_size=32)\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "                new_base_dir / 'test',\n",
    "                image_size=(180, 180),\n",
    "                batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4a1a45de-a305-4734-bf37-5100b3cf4ff9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validation_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train_data, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(\u001b[43mvalidation_data\u001b[49m), callbacks\u001b[38;5;241m=\u001b[39mcallbacks)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'validation_data' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, epochs=30, validation_data=validation_data, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c0cd0f-9ce3-4a78-b7f3-a3686aa0dbbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
