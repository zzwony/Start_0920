{"cells":[{"cell_type":"markdown","metadata":{"id":"nFdlbveu0bOO"},"source":["\"모든 참가자의 '제출'을 목표로 합니다\"를 기반으로 하여 만든 klue/roberta를 이용한 베이스라인입니다. \n","\n","pytorch를 처음 접하시는 분들을 위해 라인마다 아는대로 설명을 써놨으나 \n","\n","저도 배운지 얼마 안되어서 부족한 면도 있으니 양해부탁드립니다."]},{"cell_type":"markdown","metadata":{"id":"zFwpcHCd0bOT"},"source":["우선 필요한 패키지들을 import합니다. 처음 보실법한 패키지들을 설명드리면\n","\n","1. transformers : Huggingface에 등록된 pretrained model/tokenizer를 불러올 수 있는 패키지\n","2. torch : 머신러닝 패키지\n","3. tqdm : batch별로 프로세스할 때 진행상황을 바로 보여주는 패키지\n","\n","나머지는 아실거라 짐작하고 넘어가겠습니다."]},{"cell_type":"code","source":["pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5V5PyG29CFP4","executionInfo":{"status":"ok","timestamp":1674711795900,"user_tz":-540,"elapsed":10404,"user":{"displayName":"김희진","userId":"08208273043312286751"}},"outputId":"c128f6fb-55cd-494c-9d56-d40af60702b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cjJxhWX-Cbow","executionInfo":{"status":"ok","timestamp":1674711782328,"user_tz":-540,"elapsed":21688,"user":{"displayName":"김희진","userId":"08208273043312286751"}},"outputId":"32b66459-5957-4dd1-9da1-1e71978ee8a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x8UMdhFd0bOU"},"outputs":[],"source":["# https://dacon.io/en/competitions/official/236037/overview/description\n","\n","import pandas as pd\n","import numpy as np\n","import torch\n","import os\n","import random\n","from sklearn.model_selection import train_test_split\n","from transformers import AutoModel, AutoTokenizer\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torch import nn\n","from tqdm import tqdm\n","\n","# for graphing\n","import seaborn as sns\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["import torch\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","device  # pt 코드에서 필요함"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XfrtKpyADoq5","executionInfo":{"status":"ok","timestamp":1674711813766,"user_tz":-540,"elapsed":6168,"user":{"displayName":"김희진","userId":"08208273043312286751"}},"outputId":"78ce4256-d6d9-47ef-fcaa-daa16e9ec5ed"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["path = '/content/drive/MyDrive/3차프로젝트5팀/[참고자료] 문장 유형 분류 AI 경진대회/open'"],"metadata":{"id":"7gaRSziH0q3v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ccMFuf_Z0bOV"},"source":["우선 데이터를 불러와야겠죠?\n","\n","예측하는데 ID는 필요없기 때문에 drop 해줬습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oAUsFbWq0bOV"},"outputs":[],"source":["train_original = pd.read_csv(path+'/train.csv')\n","train_original.drop(columns=['ID'], inplace=True)\n","test = pd.read_csv(path+'/test.csv')\n","test.drop(columns=['ID'], inplace=True)\n","submission = pd.read_csv(path+'/sample_submission.csv')"]},{"cell_type":"markdown","metadata":{"id":"qotbGaqB0bOW"},"source":["아래 코드는 reproducibility를 위한 설정들이고 데이콘에서 제공한 베이스라인 코드에서 따왔습니다.\n","\n","자세한 설명은 : https://tempdev.tistory.com/28\n","\n","m1 reproducibility 추가\n","\n","CFG안에 key, value에 대해서 설명하자면\n","1. epochs\n","    - 총 트레이닝을 몇번 반복할지\n","    - training set를 처음부터 끝까지 도는걸 몇번할지\n","2. learning_rate\n","    - 트레이닝 속도 \n","    - 높으면 optimize 값으로 빨리 접근할 수는 있지만 지나칠 수 있다.\n","    - 낮으면 optimizer 값으로 느리게 접근하지만 지나치지는 않는다. --> training에 소요되는 시간 증가\n","3. batch_size\n","    - 한번에 몇개의 training items를 가지고 neural network의 weight를 조정할 것인가\n","    - 예를 들어 1000개의 items를 training할 때 batch_size가 32라고 하면 1000개를 32개씩 쪼개서 한번에 32개의 item만을 가지고 training하고 weights를 업데이트하고 다음 32개로 넘어간다. 이때 마지막 그룹은 32개보다 적다. \n","    - batch_size가 작으면 weights를 자주 업데이트하고 크면 weights를 덜 자주 업데이트 한다 --> batch_size가 작으면 sample size가 작은거랑 비슷하므로 그룹마다 차이가 크다 / batch_size가 크면 sample size가 큰거랑 비슷하므로 그룹마다 차이가 작다.\n","\n","\n","이 코드를 돌린 디바이스가 m1 mac이므로 torch.device('mps')를 썼지만 맥이 아닌 gpu를 쓸때는 'cuda'를 쓰면 된다. gpu가 없다면 'cpu'로 설정하면 되는데 그러면 속도가 많이 느려질 것이다. gpu가 있는지 알아보기 위해서는 torch.cuda.is_available()를 돌려보면 true 아니면 false가 나올 것이다. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8GJkgt6Z0bOX"},"outputs":[],"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","CFG = {\n","    'EPOCHS':20,\n","    'LEARNING_RATE':1e-5,\n","    'BATCH_SIZE':32,\n","    'SEED':41\n","}\n","\n","seed_everything(CFG['SEED']) # Seed 고정"]},{"cell_type":"markdown","metadata":{"id":"id3FPCw10bOX"},"source":["그 다음으로는 train_test_split를 이용해서 train와 val을 나눠줍니다. \n","\n","유형(type), 극성(polarity), 시제(tense), 확실성(certainty) 중에서 imbalanced한 label도 있기때문에\n","\n","stratify를 추가해주는게 좋다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ci5_HEzm0bOY"},"outputs":[],"source":["train, val, _, _ = train_test_split(train_original, train_original['label'], test_size=0.2, random_state=CFG['SEED'])\n","train = train.reset_index(drop=True)\n","val = val.reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{"id":"YeVorc8d0bOY"},"source":["위에서 언급했듯이 transformers 패키지를 통해서 pretrained된 모델을 불러올 수 있다.\n","\n","불러오는 방법은 https://huggingface.co/models 여기서 model 이름을 검색하고 \n","\n","모델은 AutoModel.from_pretrained()을 통해서, 토크나이저는 AutoTokenizer.from_pretrained()을 통해서 \n","\n","모델이름을 파라미터로 넣어주면 된다. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"liS7XKfN0bOY","outputId":"2756c640-a749-409e-ef1a-01025a94bc94","colab":{"base_uri":"https://localhost:8080/","height":321,"referenced_widgets":["38c595c1895e4ef98bc462e7fa326694","7fa81a44b1194ea3b966355bbde8ed25","f7172bf8c4d241f5ac21c92a7d214a40","ce7c498c94144fc0bed01993218bfae3","c3d5c617eb7a4ba88b89c096902edb8c","d12a0cb16d9a4aa5ae5422c88a34f4c0","6fb3d2f5f6434a578d2da1b07fa7c0a5","65fc8a54043b4d5f891e311deb1b81c2","148b5e32eed249b8901387cad050b8bd","7c3e9da9e4c54f2b86a3ccd5ff4e6592","ce7a415f5e90479aacea0c116e3c0210","3168b02d357949988c3d0301a6c44eba","35ae58439cfc4a4c85df319bfce4ec3b","d26fa52660c94c40b3837e0ae450d34c","21cf4b94d0ed43c3a5808e2c8833dd4b","4035f6226c044800b903701c6e2f5b69","2e52c00a914942eebbc3096f3647a252","c62bf76fbf02497097a0e5eea6f3ee38","b8e7b842f73a47db9859f6ccdd89f907","626cc6fcc44a48749c3e19a44df7101e","ce413867e10b46c097cb90ef8f1f6b52","38cf2a2ad30442308b89809759a8c635","ed04d02aaf2441759271cd4da2e50662","c53e63cdceab468885eb2292be9bbd96","b4542c91db974723a641f7f2474b8382","054a66f980e8403f82fcac0c94d559b6","30bbd106a08f47c6b786ef205854364d","e9a13797fca649849afd8cf6015d414e","10634896bdfc4060b3d7afc1f8ed916b","53613abaec4d44a68c95d665f2df8b5f","3cf49fdb25954c31a3e6a76852c9b759","467c7473d5384e07bf4e9b1f60a0cc04","9ef00f2b81574a5f9c11cc67e23e638e","16c8521a29cb45beab61ef0146cd88fc","1b68464257df43b381af822615c96086","9e358229407a40109fb679de2f4f9f73","7346b92a033043b8abbaca8e5de5e0d0","fb6413a472df4bc1a8232a3563813077","00e0507d2dde4e76a506c4a62883edbd","2e5713c265924e1882a0bea3eb4e013d","ad1e2b0e1daf4bad9f710d515192a282","42ff018ce2854c038b1680acf15fe2c9","859f2d1ea0f441d3907400d3594d75c8","6bc1c3847c4745c499be5a04dd61ffe4","34d5293e57084b1ab8c13f5d3cbda554","f3e99f1faba14f06bdcaaff9c4b4a471","31b2c0d286d94a1bbf24dd06f44947cd","a5fa1936856f453b8e2f2d687f8e90ba","b2558c60c7b144d9a9b538a22e8388ab","a4d467ff634c4f7ebcb69d7ecc3af1f0","b75b9c714e354189a1c7cb82176352c9","7695fe0750dd42a187338e9f8d49bd3b","d627736d83554deeaeed84b9bb4276e9","b3e21d2cf4f04b5e88131ef4402becc1","364b6aae14514b599f3728c2be871bc5","7a38d70c76184d7ab372360f45fb57ee","e52434da4e1e49acb03cf5a0c44b3f5f","8bb4fd2895d94d6eb6d578415b0aff3d","fc0c8ea8371f4a5ca9ae204134584078","ed58ed4951144ba59e8ba8fd071aee12","19a1389da8464d4081565d58ef9d33d8","f1976fc3276349cc8a5812eb76bc52de","e59b8a92929549f7a1d98843582474b1","774e37e0d6d046e5afe8d2558631f2e0","f8d3f693237b4257b23c7796f6e0a5b3","a5fe4c9ef3714bf780ae288f63e19771"]},"executionInfo":{"status":"ok","timestamp":1674712104893,"user_tz":-540,"elapsed":15326,"user":{"displayName":"김희진","userId":"08208273043312286751"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/545 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38c595c1895e4ef98bc462e7fa326694"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/273M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3168b02d357949988c3d0301a6c44eba"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-small were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/375 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed04d02aaf2441759271cd4da2e50662"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16c8521a29cb45beab61ef0146cd88fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/752k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34d5293e57084b1ab8c13f5d3cbda554"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a38d70c76184d7ab372360f45fb57ee"}},"metadata":{}}],"source":["model_nm = 'klue/roberta-small'\n","base_model = AutoModel.from_pretrained(model_nm)\n","tokenizer = AutoTokenizer.from_pretrained(model_nm)"]},{"cell_type":"markdown","metadata":{"id":"hiEunCVo0bOa"},"source":["*토크나이저의* 역할은 문장을 토큰이라고 하는 작은 단위 (더이상 나눌 수 없는 가장 작은 단위)로 나누어주고 pretrained tokenizer에 그 토큰이 어디에 저장되어 있는지 input_ids로 되돌려준다.\n","\n","밑 코드는 그 input_ids 길이가 어떤지 histogram으로 그려본 것이다.\n","\n","(저도 이 분야는 신생아라 틀린 부분이 있을 수 있습니다.)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"umb4cuv80bOb","outputId":"ab6ff04d-fd49-48c4-a3e7-aac5a5c17086","colab":{"base_uri":"https://localhost:8080/","height":283},"executionInfo":{"status":"ok","timestamp":1674712123468,"user_tz":-540,"elapsed":3595,"user":{"displayName":"김희진","userId":"08208273043312286751"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["log value : 90.4092368060602\n"]}],"source":["tokenizer_len = [len(tokenizer(s)['input_ids']) for s in train['문장']]\n","sns.histplot(tokenizer_len)\n","plt.show()\n","\n","print(f'log value : {np.mean(tokenizer_len)+3*np.std(tokenizer_len)}') # 표준분산 3배수 안에 99프로의 데이터가존재, 표준분산 2배수안에는 95프로의 데이터가 존재"]},{"cell_type":"markdown","metadata":{"id":"NN6N8HP00bOc"},"source":["따라서, log를 취해주면"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ALbxo5og0bOc","outputId":"00627ce3-e15b-43b9-e819-06ffd73a06b8","colab":{"base_uri":"https://localhost:8080/","height":302},"executionInfo":{"status":"ok","timestamp":1674712127907,"user_tz":-540,"elapsed":8,"user":{"displayName":"김희진","userId":"08208273043312286751"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["log value : 4.8974082584991345\n","original value : 133.94218592094492\n"]}],"source":["tokenizer_log = np.log(tokenizer_len)\n","sns.histplot(tokenizer_log)\n","plt.show()\n","\n","print(f'log value : {np.mean(tokenizer_log)+3*np.std(tokenizer_log)}') \n","print(f'original value : {np.exp(np.mean(tokenizer_log)+3*np.std(tokenizer_log))}')"]},{"cell_type":"markdown","metadata":{"id":"cPStZ7gQ0bOc"},"source":["따라서, 적정선은 90에서 134 사이가 아닐까 생각된다."]},{"cell_type":"markdown","metadata":{"id":"VjO0HpfD0bOc"},"source":["위 값은 잠깐 뒤로하고 아래 코드를 위부터 설명하자면,\n","\n","torch.utils.data의 Dataset의 child class인 SentenceTypeDataset을 만들어준다. 이는 pytorch neural network에 내 맘대로 \n","x가 뭔지 y가 뭔지 정한 dataset을 제공하기 위한 클래스이다. 만드는데 꼭 필요한 function은 총 3가지이다.\n","\n","_ _ init _ _()\n","- x랑 y가 뭔지 저장해줘야 한다. \n","- 이때 이번에는 텍스트 데이터를 다뤄주기때문에 dataframe, tokenizer, labels를 parameter로 넣어줬고 dataframe의 문장을 tokenizer로 토큰화 시킨다음 self.texts에 저장해주고 입력받은 labels는 그대로 self.labels에 저장해줬다. \n","- batch에 들어가는 입력들은 input size가 다 같아야 한다. 따라서 tokenizer로 나온 값들을 그대로 넣어버리면 오류가 난다. 위 히스토그램에서 볼 수 있듯이 문장마다 다르기 때문. 따라서 위 값(90)으로 tokenizer의 max_length를 정해주고 max_length보다 작은 길이들은 padding으로 채워주고 긴 길이들은 truncation으로 잘라준다. 이때 max_length는 길면 길수록 training time이 늘어난다.\n","- tokenizer안에 return_tensors의 pt는 tensor로 tokenizer값을 리턴해준다는 뜻이다.\n","\n","_ _ len _ _()\n","- self.texts의 길이는 리턴해줍니다.\n","\n","_ _ getitem _ _()\n","- idx에 해당되는 x와 y를 리턴해줍니다.\n","- x는 self.texts에서 가져오고 y는 그 텍스트(x)에 해당되는 type, polarity, tense, certainty를 리턴하면 됩니다.\n","- 나중 코드에서 나오겠지만 미리 설명을 하자면 labels는 train, val set에서만 dictionary형태로 주어진다. 이때 type, polarity, tense, certainty가 key고 해당 레이블에 해당되는 값을 one-hot encoding한게 value다. \n","- dictionary에 저장된 형태는 list고 pytorch에는 tensor 형태로 넣어줘야하기 때문에 torch.Tensor()로 형태를 바꾸어준다.\n","- test set의 경우 labels이 주어지지 않기 때문에 똑같은 길이지만 -1로 채워놓은 tensor를 리턴해준다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xzo031u70bOd"},"outputs":[],"source":["class SentenceTypeDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, labels=None):\n","        texts = dataframe['문장'].values.tolist()\n","\n","        self.texts = [tokenizer(text, padding='max_length', max_length=90, truncation=True, return_tensors='pt') for text in texts]   # pt pyorch, tf tensorflow\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","\n","        if self.labels is not None:\n","            type_tmp = self.labels['type'][idx]\n","            polarity_tmp = self.labels['polarity'][idx]\n","            tense_tmp = self.labels['tense'][idx]\n","            certainty_tmp = self.labels['certainty'][idx]\n","            return text, torch.Tensor(type_tmp), torch.Tensor(polarity_tmp), torch.Tensor(tense_tmp), torch.Tensor(certainty_tmp)\n","        else:\n","            return text, torch.Tensor([-1,-1,-1,-1]), torch.Tensor([-1,-1,-1]), torch.Tensor([-1,-1,-1]), torch.Tensor([-1,-1])"]},{"cell_type":"markdown","metadata":{"id":"GIVNBPQE0bOd"},"source":["다음으로는 Classifier class를 만드는 것이다.\n","\n","\\__init__()\n","- 우선 nn.Module의 child class이기 때문에 \\__init__() 안에 super().\\__init__()을 불러주고 base_model을 통해서 받을 pretrained_model을 self.klue에 저장한다.\n","이때 klue의 output features는 768이다. 확인방법은 base_model을 셀에 쳐보면 된다. (더 쉬운 방법이 있으면 알려주세요)\n","\n","- transfer learning의 기본적인 방법은 중간에 hidden layer는 pretrained_model의 것을 이용하고 output layer를 내가 원하는 방향으로 만들어서 training 하는 것이다. 따라서, self.fc1, self.type_clf, self.softmax 등등 다양한 레이어들을 추가해줬다. 이때 self.fc1에는 nn.Linear(768, 32)를 저장해줬는데, 이는 in_feature로 768, out_feature로는 32를 내보낸다는 뜻이다. 일반적으로 알고 있는 dense layer의 역할을 한다. 그 다음으로는 self.relu에 nn.ReLU()를 저장해서 activation function으로 사용해줬다. 그 다음으로는 multilabel classification 문제이기 때문에 각 label마다 nn.Linear(32, # of types)으로 레이어를 만들어줬다. 이때 # of types만큼의 out_feature가 필요한 이유는 types들을 one-hot encoding을 해줬기 때문이다. 그 다음으로는 classification에 많이 사용되는 nn.Softmax(dim=1)을 넣어줬다. softmax에서 나온 값들의 합은 1로써 어느 type에 해당되는지 확률들을 리턴해준다. 이때 합해져야되는 값들이 dim=1에 있기때문에 dim=1이라는 파라미터를 넣어주었다.\n","\n","\\__forward__()\n","- 그 다음으로 꼭 작성해줘야 하는 function은 forward다. (backward는 필요없음) 여기서는 위에서 작성한 레이어들을 어느 순서로 지나칠지 순서를 정해주는 단계이다. 우선, pretrained_model을 지나고 나온 output을 fc1과 relu에 넘겨주고 그 다음으로는 각 label의 clf-softmax 페어를 지나쳐준다. 그리고 나온 4개의 output을 리턴해주면 된다. \n","- multilabel이기 때문에 4개의 값을 리턴해주는거지 단순하게 binary 또는 multiclassification이면 보통 1개의 output만을 리턴해주면 된다.\n","- 아래 코드에 써있듯이 input_ids는 토큰에 해당되는 ids들, attention_mask는 어느 토큰에 집중해야되는지 알려주는 역할을 한다. 이는 왜 필요하나 하면 padding 단계에서 추가된 padding token에 대한 접근을 막기위해 사용된다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"niWOJikK0bOd"},"outputs":[],"source":["class SentenceClassifier(nn.Module):\n","    def __init__(self, base_model):\n","        super().__init__()\n","        self.klue = base_model # from transformers package\n","\n","        self.fc1 = nn.Linear(768, 32)\n","        self.relu = nn.ReLU()\n","        self.type_clf = nn.Linear(32,4)\n","        self.polarity_clf = nn.Linear(32,3)\n","        self.tense_clf = nn.Linear(32,3)\n","        self.certainty_clf = nn.Linear(32,2)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, input_ids, attention_mask):\n","        # input_ids : token's id / attention_mask : make a model to focus on which token\n","        klue_out = self.klue(input_ids= input_ids, attention_mask = attention_mask)[0][:,0]\n","\n","        x = self.fc1(klue_out)\n","        x = self.relu(x)\n","\n","        type_output = self.type_clf(x)\n","        type_output = self.softmax(type_output)\n","        polarity_output = self.polarity_clf(x)\n","        polarity_output = self.softmax(polarity_output)\n","        tense_output = self.tense_clf(x)\n","        tense_output = self.softmax(tense_output)\n","        certainty_output = self.certainty_clf(x)\n","        certainty_output = self.softmax(certainty_output)\n","\n","        return type_output, polarity_output, tense_output, certainty_output"]},{"cell_type":"markdown","metadata":{"id":"NTzsKob70bOd"},"source":["다음으로는! training 단계이다.\n","\n","우선 val_loss를 기준으로 early_stop을 할건지 말건지 정하기 때문에 best_val_loss를 설정해주었고, crossentropyloss를 이용할건데 작아질수록 좋은 값이기 때문에 최초값은 높은 값으로 설정해주었다. \n","\n","그 다음으로는 criterion인데 이는 loss function이다. 4개의 다른 label들이 있기 때문에 dictionary에 4개를 넣어주었다. 나중 단계에서 criterion에 있는 CrossEntropyLoss를 통해서 true값과 pred값의 차이를 구하고 어떤 방향으로 weights를 조정해야되는지 정한다.\n","\n","optimizer는 어떤 방식으로 최적화를 한걸지 정해주는 변수인데, 일반적으로 많이 쓰이는 Adam을 써줬다. Adam 안에는 모델의 파라미터(model.parameters())와 learning_rate를 넣어주었다. 위에서 언급했듯이 이때 learning_rate가 큰지 작은지에 따라 training 속도가 결정난다. 그 다음으로는 모델을 gpu로 보내주었다. 이 코드가 있어야 gpu를 사용해서 training 한다.\n","- mac m칩 유저의 경우 “PYTORCH_ENABLE_MPS_FALLBACK=1”를 설정해줘야 mps가 안되는 코드는 cpu로 계산을 해준다. (2022/12/16 cumsum은 mps로 계산이 안됨)\n","\n","그리고 주어진 epochs만큰 for loop을 돌리는데 그 밑에 있는 total_acc_train은 total_f1_train으로 바뀌어야 맞다. 이 부분은 중간에 f1 계산하는 코드 넣는거를 까먹고 못하고 코드를 그대로 돌려서 남은 것이니 만약 이 코드 그대로 돌린다고 하면 바꾸어주길 바란다. 그 밑에 total_loss_train은 epoch별로 loss 값이 어땠는지 기록해주기 위해 만든 변수다.\n","\n","그 다음으로는 model.train()이 있는데 이는 model을 training 모드로 만들어주는거다. 이렇게 해야 weight들이 업데이트된다. 이와 반대로 나중에 val이나 test set을 모델에 넘겨줄때는 model.eval()을 불러줘야한다. 이래야 weights들이 업데이트 되지 않는다.\n","\n","그 다음으로는 train_dataloader를 for loop으로 돌려주는데 뒤에 나오겠지만 dataloader는 지정해준 batch_size만큼 item의 x와 y를 넘겨준다. 이때 쓰이는 것이 위에서 만들어준 SentenceTypeDataset의 getitem()이다. 따라서, 5개의 변수 (train_input, type_label, polarity_label, tense_label, certainty_label)로 받아야한다. 그 다음으로는 train_input에 있는 attention_mask와 input_ids와 label들을 device로 넘겨준다.\n","\n","그리고 training을 시작하기 전에 optimizer.grad()를 설정해줘서 매 epoch마다 전에 썼던 값들을 기억하는 것이 아니라 0 베이스에서 시작하게 해준다. epoch를 통한 값들의 정확한 업데이트를 위해서는 꼭 필요한 코드다.\n","\n","그리고 나서 model에 input_ids와 attention_mask를 넣어서 얻은 4개의 값들을 저장해준다. 이때 이 값들은 각 label마다 one-hot encoding된 컬럼에 해당될 확률들이다. 바로 다음에 이 값들은 criterion에 있는 CrossEntropyLoss()로 들어가서 실제와 얼마나 유사한지 계산되고 그 계산된 값을 total_loss_train에 저장해준다.\n","\n","그 다음으로는 계산된 loss 값을 바탕으로 backpropagation(loss.backward()과 optimizer.step()을 통해서)을 진행하여 weights들을 업데이트해준다.\n","\n","이렇게 training data를 다 거쳤다면 그 다음은 validation data 차례다. 우선 with torch.no_grad()과 model.eval()을 불러주어서 weights들을 업데이트하는게 아니라는 것을 선언해준다. 그 후에는 training data에서 했던 방식이랑 다 같지만 optimizer.zero_grad(), loss.backward(), optimier.step()만 빠진다. weights들을 업데이트하지 않기 때문.\n","\n","그 다음으로는 지금까지 저장한 loss와 metric을 프린트해주고, val_loss가 좋아졌는지 여부에 따라서 모델을 저장할 것인지 early stop 할 것인지 정해준다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O_HbSYDT0bOe"},"outputs":[],"source":["def sentence_train(model, train_dataloader, val_dataloader, learning_rate, epochs, model_nm):\n","    best_val_loss = 99999999999999 # setting max (act as infinity)\n","    early_stopping_threshold_count = 0\n","\n","    criterion = {\n","        'type' : nn.CrossEntropyLoss().to(device),\n","        'polarity' : nn.CrossEntropyLoss().to(device),\n","        'tense' : nn.CrossEntropyLoss().to(device),\n","        'certainty' : nn.CrossEntropyLoss().to(device)\n","    }\n","\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","    model = model.to(device)\n","\n","    for epoch in range(epochs):\n","        total_acc_train = 0\n","        total_loss_train = 0\n","        \n","        model.train() # sets into the training mode\n","        \n","        for train_input, type_label, polarity_label, tense_label, certainty_label in tqdm(train_dataloader):\n","            attention_mask = train_input['attention_mask'].to(device)\n","            input_ids = train_input['input_ids'].squeeze(1).to(device)\n","            type_label = type_label.to(device)\n","            polarity_label = polarity_label.to(device)\n","            tense_label = tense_label.to(device)\n","            certainty_label = certainty_label.to(device)\n","\n","            optimizer.zero_grad()\n","            \n","            type_output, polarity_output, tense_output, certainty_output = model(input_ids, attention_mask) # from the forward function\n","            \n","            loss = 0.25*criterion['type'](type_output, type_label.float()) + \\\n","                   0.25*criterion['polarity'](polarity_output, polarity_label.float()) + \\\n","                   0.25*criterion['tense'](tense_output, tense_label.float()) + \\\n","                   0.25*criterion['certainty'](certainty_output, certainty_label.float())\n","            total_loss_train += loss.item()\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","\n","        with torch.no_grad(): # since we should not change gradient for validation \n","            total_acc_val = 0\n","            total_loss_val = 0\n","            \n","            model.eval() # deactivate training\n","            \n","            # same process as the above\n","            for val_input, vtype_label, vpolarity_label, vtense_label, vcertainty_label in tqdm(val_dataloader):\n","                attention_mask = val_input['attention_mask'].to(device)\n","                input_ids = val_input['input_ids'].squeeze(1).to(device)\n","\n","                vtype_label = vtype_label.to(device)\n","                vpolarity_label = vpolarity_label.to(device)\n","                vtense_label = vtense_label.to(device)\n","                vcertainty_label = vcertainty_label.to(device)\n","                \n","                vtype_output, vpolarity_output, vtense_output, vcertainty_output = model(input_ids, attention_mask) # from the forward function\n","\n","                loss = 0.25*criterion['type'](vtype_output, vtype_label.float()) + \\\n","                        0.25*criterion['polarity'](vpolarity_output, vpolarity_label.float()) + \\\n","                        0.25*criterion['tense'](vtense_output, vtense_label.float()) + \\\n","                        0.25*criterion['certainty'](vcertainty_output, vcertainty_label.float())\n","\n","                total_loss_val += loss.item()\n","\n","            \n","            print(f'Epochs: {epoch + 1} '\n","                  f'| Train Loss: {total_loss_train / len(train_dataloader): .3f} '\n","                  f'| Train Accuracy: {total_acc_train / (len(train_dataloader.dataset)): .3f} '\n","                  f'| Val Loss: {total_loss_val / len(val_dataloader): .3f} '\n","                  f'| Val Accuracy: {total_acc_val / len(val_dataloader.dataset): .3f}')\n","            \n","            if best_val_loss > total_loss_val:\n","                best_val_loss = total_loss_val # saving only the best one\n","                torch.save(model, f\"model/{model_nm}.pt\")\n","                print(\"Saved model\")\n","                early_stopping_threshold_count = 0\n","            else:\n","                early_stopping_threshold_count += 1 # checking how many epochs have passed that val_loss didn't increase\n","                \n","            if early_stopping_threshold_count >= 3: # ==> patience=1\n","                print(\"Early stopping\")\n","                break"]},{"cell_type":"markdown","metadata":{"id":"OTc0sbLQ0bOe"},"source":["필요한 class, function들은 다 적었으니 이제 dataset들을 준비할 차례다.\n","\n","우선 train에서 label을 제외한 나머지 컬럼들만 킵해주고 그중에서도 유형,극성,시제,확실성을 pd.get_dummies로 one-hot encoding해준다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"77AaV_Th0bOf","outputId":"6928e7e6-fb63-45ed-818e-ab389ca937ef","colab":{"base_uri":"https://localhost:8080/","height":606},"executionInfo":{"status":"ok","timestamp":1674635456345,"user_tz":-540,"elapsed":16,"user":{"displayName":"허진욱 (히포)","userId":"12047922749448634421"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                      문장  유형_대화형  유형_사실형  \\\n","0      용산구청 관계자는 ＂재정이 열악한 지자체로서는 1800억원을 마련할 수 없다＂며 서...       0       1   \n","1      부산시는 이처럼 부산이 가파른 상승세를 보이는 이유에 대해 지난해부터 추진하고 있는...       0       1   \n","2      그러나 미숙아, 만성호흡기질환, 선천 심장병, 선천 면역결핍질환, 암환자 등의 고위...       0       1   \n","3                          탁구 종목에서 중국 대표팀 위상이 뛰어나기 때문이다.       0       0   \n","4      이 논문에 따르면 ＇BT-11＇은 뇌의 신경전달물질인 아세틸콜린을 분해하는 효소의 ...       0       1   \n","...                                                  ...     ...     ...   \n","13227                          우리가 익히 아는 대로 임꺽정은 신출귀몰했다.       0       1   \n","13228  김 상무보는 ＂실제 이용자 수와 인당 사용시간 등 주요 데이터가 매년 두 자릿수 상...       0       1   \n","13229  ＇디폴트 옵션＇의 필요성을 주장해온 쪽이 항상 사례로 들어온 것이 ＇401K＇로 불...       1       0   \n","13230  1992년부터 선양시 조선족노인협회를 후원하기 시작해 1997년에는 1500㎡ 건물...       0       1   \n","13231               차량은 고속 상태지만 운전자는 정체모드에서 사고가 많이 발생한다.       0       1   \n","\n","       유형_예측형  유형_추론형  극성_긍정  극성_미정  극성_부정  시제_과거  시제_미래  시제_현재  확실성_불확실  \\\n","0           0       0      1      0      0      1      0      0        0   \n","1           0       0      1      0      0      1      0      0        0   \n","2           0       0      1      0      0      0      0      1        0   \n","3           0       1      1      0      0      0      0      1        0   \n","4           0       0      1      0      0      0      0      1        0   \n","...       ...     ...    ...    ...    ...    ...    ...    ...      ...   \n","13227       0       0      1      0      0      1      0      0        0   \n","13228       0       0      1      0      0      1      0      0        0   \n","13229       0       0      1      0      0      0      0      1        0   \n","13230       0       0      1      0      0      1      0      0        0   \n","13231       0       0      1      0      0      0      0      1        0   \n","\n","       확실성_확실  \n","0           1  \n","1           1  \n","2           1  \n","3           1  \n","4           1  \n","...       ...  \n","13227       1  \n","13228       1  \n","13229       1  \n","13230       1  \n","13231       1  \n","\n","[13232 rows x 13 columns]"],"text/html":["\n","  <div id=\"df-3b6d3773-e2bd-4d2d-be7c-fcb607b8a9b7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>문장</th>\n","      <th>유형_대화형</th>\n","      <th>유형_사실형</th>\n","      <th>유형_예측형</th>\n","      <th>유형_추론형</th>\n","      <th>극성_긍정</th>\n","      <th>극성_미정</th>\n","      <th>극성_부정</th>\n","      <th>시제_과거</th>\n","      <th>시제_미래</th>\n","      <th>시제_현재</th>\n","      <th>확실성_불확실</th>\n","      <th>확실성_확실</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>용산구청 관계자는 ＂재정이 열악한 지자체로서는 1800억원을 마련할 수 없다＂며 서...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>부산시는 이처럼 부산이 가파른 상승세를 보이는 이유에 대해 지난해부터 추진하고 있는...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>그러나 미숙아, 만성호흡기질환, 선천 심장병, 선천 면역결핍질환, 암환자 등의 고위...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>탁구 종목에서 중국 대표팀 위상이 뛰어나기 때문이다.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>이 논문에 따르면 ＇BT-11＇은 뇌의 신경전달물질인 아세틸콜린을 분해하는 효소의 ...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13227</th>\n","      <td>우리가 익히 아는 대로 임꺽정은 신출귀몰했다.</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13228</th>\n","      <td>김 상무보는 ＂실제 이용자 수와 인당 사용시간 등 주요 데이터가 매년 두 자릿수 상...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13229</th>\n","      <td>＇디폴트 옵션＇의 필요성을 주장해온 쪽이 항상 사례로 들어온 것이 ＇401K＇로 불...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13230</th>\n","      <td>1992년부터 선양시 조선족노인협회를 후원하기 시작해 1997년에는 1500㎡ 건물...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13231</th>\n","      <td>차량은 고속 상태지만 운전자는 정체모드에서 사고가 많이 발생한다.</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13232 rows × 13 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b6d3773-e2bd-4d2d-be7c-fcb607b8a9b7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3b6d3773-e2bd-4d2d-be7c-fcb607b8a9b7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3b6d3773-e2bd-4d2d-be7c-fcb607b8a9b7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}],"source":["train_tmp = train[['문장', '유형', '극성', '시제', '확실성']]\n","train_tmp = pd.get_dummies(train_tmp, columns=['유형', '극성', '시제', '확실성'])\n","train_tmp"]},{"cell_type":"markdown","metadata":{"id":"EhSmIffP0bOf"},"source":["그 다음으로는 각 label별로 뽑아서 train_labels에 dictionary형태로 저장해준다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AHle8GPk0bOf"},"outputs":[],"source":["train_type = train_tmp.iloc[:,1:5].values.tolist()\n","train_polarity = train_tmp.iloc[:,5:8].values.tolist()\n","train_tense = train_tmp.iloc[:,8:11].values.tolist()\n","train_certainty = train_tmp.iloc[:,11:13].values.tolist()\n","train_labels = {\n","    'type': train_type,\n","    'polarity': train_polarity,\n","    'tense': train_tense,\n","    'certainty': train_certainty\n","}"]},{"cell_type":"markdown","metadata":{"id":"xlOgh1YJ0bOf"},"source":["똑같은 방식으로 validation data도 만든다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ILkgeKU0bOf"},"outputs":[],"source":["val_tmp = val[['문장', '유형', '극성', '시제', '확실성']]\n","val_tmp = pd.get_dummies(val_tmp, columns=['유형', '극성', '시제', '확실성'])\n","\n","val_type = val_tmp.iloc[:,1:5].values.tolist()\n","val_polarity = val_tmp.iloc[:,5:8].values.tolist()\n","val_tense = val_tmp.iloc[:,8:11].values.tolist()\n","val_certainty = val_tmp.iloc[:,11:13].values.tolist()\n","val_labels = {\n","    'type': val_type,\n","    'polarity': val_polarity,\n","    'tense': val_tense,\n","    'certainty': val_certainty\n","}"]},{"cell_type":"markdown","metadata":{"id":"DGhG2d8X0bOf"},"source":["train, val set가 준비되었다면 위에서 만든 SetenceTypeDataset에 dataframe, tokenizer, labels들을 넣어주고 SentenceTypeDataset, batch_size는 필수적으로 값을 정해서 DataLoader에 넣어준다. 위에서 잠깐 언급했듯이 DataLoader는 지정된 batch_size만큼 item들을 모델에 넘겨주어서 training 할 수 있게 해준다. \n","\n","여기서 shuffle는 item들을 랜덤하게 고른다는 의미고 num_workers는 설명을 봐도 잘 모르겠다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5JD0Zp4f0bOg"},"outputs":[],"source":["train_dataloader = DataLoader(SentenceTypeDataset(train_tmp, tokenizer, train_labels), batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=0) # num_workers: how many subprocesses to use for data loading  \n","val_dataloader = DataLoader(SentenceTypeDataset(val_tmp, tokenizer, val_labels), batch_size=CFG['BATCH_SIZE'], num_workers=0)"]},{"cell_type":"markdown","metadata":{"id":"EajYclyr0bOg"},"source":["그 다음으로는 base_model (klue를 이용한 pretrained_model)을 기반으로해서 SentenceClassifier를 불러준다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dusG4YEv0bOg"},"outputs":[],"source":["model = SentenceClassifier(base_model)"]},{"cell_type":"markdown","metadata":{"id":"fNg3olly0bOg"},"source":["그리고 이제서야 training을 할 수 있는 상태에 온 것이다. \n","\n","위에서 만든 sentence_train function에 필요한 파라미터들을 보내주어서 training을 시작해준다.\n","\n","(위에서 말했듯이 f1을 계산 안하고 accuracy를 그대로 남겨주었기 때문에 accuracy는 계속 0이다.)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cgxVNeH-0bOg","outputId":"030a85ce-cd91-4f0f-a033-6344b1bfe782","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1674635586485,"user_tz":-540,"elapsed":13544,"user":{"displayName":"허진욱 (히포)","userId":"12047922749448634421"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/414 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        ...,\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]]], device='cuda:0')\n","tensor([[   0, 3727, 3977,  ...,    1,    1,    1],\n","        [   0, 6241, 2440,  ...,    1,    1,    1],\n","        [   0,  641, 4274,  ...,    1,    1,    1],\n","        ...,\n","        [   0, 5409, 6584,  ...,    1,    1,    1],\n","        [   0, 3727, 1965,  ...,    1,    1,    1],\n","        [   0, 5476, 3766,  ...,    1,    1,    1]], device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 2/414 [00:03<10:20,  1.51s/it]"]},{"output_type":"stream","name":"stdout","text":["tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        ...,\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]]], device='cuda:0')\n","tensor([[    0, 15029,    16,  ...,     1,     1,     1],\n","        [    0,  4842,  2170,  ...,     1,     1,     1],\n","        [    0,  6271,  2299,  ...,     1,     1,     1],\n","        ...,\n","        [    0, 16105,  2073,  ...,     1,     1,     1],\n","        [    0,  6679,  1839,  ...,     1,     1,     1],\n","        [    0,  3678,  6696,  ...,     1,     1,     1]], device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 3/414 [00:03<06:20,  1.08it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        ...,\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]]], device='cuda:0')\n","tensor([[    0,  4442,  7608,  ...,     1,     1,     1],\n","        [    0, 19681,  2069,  ...,     1,     1,     1],\n","        [    0,   918,     3,  ...,     1,     1,     1],\n","        ...,\n","        [    0,  7270, 13907,  ...,     1,     1,     1],\n","        [    0,  1883,  2067,  ...,     1,     1,     1],\n","        [    0,   558,  2116,  ...,     1,     1,     1]], device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 4/414 [00:04<04:29,  1.52it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 1, 1, 1]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        ...,\n","\n","        [[1, 1, 1,  ..., 1, 1, 1]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]]], device='cuda:0')\n","tensor([[    0,  3659,  2116,  ...,     1,     1,     1],\n","        [    0, 15225,  2259,  ...,  2267,    12,     2],\n","        [    0,  1504,  2200,  ...,     1,     1,     1],\n","        ...,\n","        [    0, 20830,  2055,  ...,  2259,   886,     2],\n","        [    0,  4421, 26626,  ...,     1,     1,     1],\n","        [    0,  1504,  2031,  ...,     1,     1,     1]], device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 5/414 [00:04<03:27,  1.97it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        ...,\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]]], device='cuda:0')\n","tensor([[    0,  1168,  3871,  ...,     1,     1,     1],\n","        [    0,  4323,  2089,  ...,     1,     1,     1],\n","        [    0,  1891,  7345,  ...,     1,     1,     1],\n","        ...,\n","        [    0,  3667,  3962,  ...,     1,     1,     1],\n","        [    0,  3819,  1376,  ...,     1,     1,     1],\n","        [    0, 12407, 11534,  ...,     1,     1,     1]], device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|▏         | 6/414 [00:04<02:49,  2.40it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 1, 1, 1]],\n","\n","        ...,\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]]], device='cuda:0')\n","tensor([[    0,    21,  2015,  ...,     1,     1,     1],\n","        [    0,  7012,  2259,  ...,     1,     1,     1],\n","        [    0, 22961,  2073,  ...,     3,    12,     2],\n","        ...,\n","        [    0,    21,  2057,  ...,     1,     1,     1],\n","        [    0,     3, 11158,  ...,     1,     1,     1],\n","        [    0, 12626,  2313,  ...,     1,     1,     1]], device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["\r  2%|▏         | 7/414 [00:04<02:26,  2.77it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        ...,\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]]], device='cuda:0')\n","tensor([[    0, 24155,  2376,  ...,     1,     1,     1],\n","        [    0,  4345, 27135,  ...,     1,     1,     1],\n","        [    0,  5697, 29309,  ...,     1,     1,     1],\n","        ...,\n","        [    0,  3774,  2084,  ...,     1,     1,     1],\n","        [    0,  3744,  2170,  ...,     1,     1,     1],\n","        [    0,  4914,  3716,  ...,     1,     1,     1]], device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["\r  2%|▏         | 8/414 [00:05<02:10,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        ...,\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]]], device='cuda:0')\n","tensor([[   0, 6196, 2075,  ...,    1,    1,    1],\n","        [   0,   22, 2429,  ...,    1,    1,    1],\n","        [   0, 3819, 4163,  ...,    1,    1,    1],\n","        ...,\n","        [   0,    3,  574,  ...,    1,    1,    1],\n","        [   0, 5691, 1383,  ...,    1,    1,    1],\n","        [   0, 8903,  549,  ...,    1,    1,    1]], device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["\r  2%|▏         | 9/414 [00:05<02:01,  3.33it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        ...,\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]]], device='cuda:0')\n","tensor([[    0,  3843,  3934,  ...,     1,     1,     1],\n","        [    0,  3738,  3666,  ...,     1,     1,     1],\n","        [    0, 10460, 27135,  ...,     1,     1,     1],\n","        ...,\n","        [    0,  1485, 29945,  ...,     1,     1,     1],\n","        [    0, 12456,  2056,  ...,     1,     1,     1],\n","        [    0,  3666, 27135,  ...,     1,     1,     1]], device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["\r  2%|▏         | 10/414 [00:05<01:53,  3.56it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        ...,\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]]], device='cuda:0')\n","tensor([[    0,  8842, 28176,  ...,     1,     1,     1],\n","        [    0,     3,  1512,  ...,     1,     1,     1],\n","        [    0,   170,  1079,  ...,     1,     1,     1],\n","        ...,\n","        [    0,  7480,  2119,  ...,     1,     1,     1],\n","        [    0,  6724,  2259,  ...,     1,     1,     1],\n","        [    0,  6739,    22,  ...,     1,     1,     1]], device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["\r  3%|▎         | 11/414 [00:05<01:47,  3.73it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        ...,\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]]], device='cuda:0')\n","tensor([[    0,  8011,  6414,  ...,     1,     1,     1],\n","        [    0,  1485, 29945,  ...,     1,     1,     1],\n","        [    0,  1168,  3871,  ...,     1,     1,     1],\n","        ...,\n","        [    0, 27141,  2656,  ...,     1,     1,     1],\n","        [    0,  3669,  4054,  ...,     1,     1,     1],\n","        [    0,  4845,  2440,  ...,     1,     1,     1]], device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["\r  3%|▎         | 12/414 [00:05<01:44,  3.84it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        ...,\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]]], device='cuda:0')\n","tensor([[    0,  4385,  2116,  ...,     1,     1,     1],\n","        [    0,  4326, 13113,  ...,     1,     1,     1],\n","        [    0,    24,  2440,  ...,     1,     1,     1],\n","        ...,\n","        [    0,     3,  3810,  ...,     1,     1,     1],\n","        [    0,   636,  2259,  ...,     1,     1,     1],\n","        [    0,  4264,  4880,  ...,     1,     1,     1]], device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["\r  3%|▎         | 13/414 [00:06<01:42,  3.93it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        ...,\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 0, 0, 0]]], device='cuda:0')\n","tensor([[    0,  4619,  2079,  ...,     1,     1,     1],\n","        [    0,  4549,  2069,  ...,     1,     1,     1],\n","        [    0, 13011,  7285,  ...,     1,     1,     1],\n","        ...,\n","        [    0,  4174,  6023,  ...,     1,     1,     1],\n","        [    0,  3775, 21023,  ...,     1,     1,     1],\n","        [    0,  4642,   100,  ...,     1,     1,     1]], device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["\r  3%|▎         | 13/414 [00:06<03:14,  2.07it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-bd6426753ef5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentence_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LEARNING_RATE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EPOCHS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kclue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-14-c80bd1331094>\u001b[0m in \u001b[0;36msentence_train\u001b[0;34m(model, train_dataloader, val_dataloader, learning_rate, epochs, model_nm)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolarity_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtense_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcertainty_label\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["sentence_train(model, train_dataloader, val_dataloader, CFG['LEARNING_RATE'], CFG['EPOCHS'], 'kclue')"]},{"cell_type":"markdown","metadata":{"id":"PqzjYlwR0bOg"},"source":["training이 끝났으면 test data를 이용해 예측을 해야되는데 이때 방법은 validation때와 비슷하다. 따라서, 설명은 생략하겠습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pvj-8fx70bOg"},"outputs":[],"source":["def get_type_predictions(model, loader):\n","\n","    model = model.to(device)\n","    \n","    type_probs, polarity_probs, tense_probs, clarity_probs = [], [], [], []\n","    with torch.no_grad():\n","        model.eval()\n","        for data_input, _, _, _, _ in tqdm(loader):\n","            attention_mask = data_input['attention_mask'].to(device)\n","            input_ids = data_input['input_ids'].squeeze(1).to(device)\n","\n","\n","            type_output, polarity_output, tense_output, clarity_output = model(input_ids, attention_mask)\n","            type_probs.append(type_output)\n","            polarity_probs.append(polarity_output)\n","            tense_probs.append(tense_output)\n","            clarity_probs.append(clarity_output)\n","    \n","    return torch.cat(type_probs).cpu().detach().numpy(), \\\n","            torch.cat(polarity_probs).cpu().detach().numpy(), \\\n","            torch.cat(tense_probs).cpu().detach().numpy(), \\\n","            torch.cat(clarity_probs).cpu().detach().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7a1TV3ob0bOh"},"outputs":[],"source":["model = torch.load(\"model/kclue.pt\")\n","test_dataloader = DataLoader(SentenceTypeDataset(test, tokenizer), batch_size=CFG['BATCH_SIZE'], shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L0kVD-Nr0bOh"},"outputs":[],"source":["#val_pred_type, val_pred_polarity, val_pred_tense, val_pred_certainty = get_type_predictions(model, val_dataloader)\n","\n","#val_type = ['대화형' if i==0 else '사실형' if i==1 else '예측형' if i==2 else '추론형' for i in [np.argmax(p) for p in val_pred_type]]\n","#val_polarity = ['긍정' if i==0 else '미정' if i==1 else '부정' for i in [np.argmax(p) for p in val_pred_polarity]]\n","#val_type = ['과거' if i==0 else '미래' if i==1 else '현재' for i in [np.argmax(p) for p in val_pred_tense]]\n","#val_type = ['불확실' if i==0 else '확실' for i in [np.argmax(p) for p in val_pred_certainty]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nCvEOKDa0bOh","outputId":"6a6ed4aa-2888-415f-a5fc-3bf96eba4d22"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 222/222 [01:22<00:00,  2.68it/s]\n"]}],"source":["test_pred_type, test_pred_polarity, test_pred_tense, test_pred_certainty = get_type_predictions(model, test_dataloader)"]},{"cell_type":"markdown","metadata":{"id":"lMrrtDOF0bOh"},"source":["여기서 잠깐 test_pred_tense가 어떻게 생겼는지 살펴보면"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PsEZa2X30bOh","outputId":"4af00adf-e4a6-43cf-cf4d-9055d19df13e"},"outputs":[{"data":{"text/plain":["array([[1.4494439e-03, 6.3607551e-04, 9.9791449e-01],\n","       [1.2099826e-03, 5.7527551e-04, 9.9821484e-01],\n","       [9.9835777e-01, 3.6566349e-04, 1.2766798e-03],\n","       ...,\n","       [6.3049151e-03, 9.8560274e-01, 8.0923596e-03],\n","       [2.1634096e-01, 6.3935834e-01, 1.4430077e-01],\n","       [9.9855858e-01, 4.0949532e-04, 1.0319587e-03]], dtype=float32)"]},"execution_count":184,"metadata":{},"output_type":"execute_result"}],"source":["test_pred_tense"]},{"cell_type":"markdown","metadata":{"id":"6DiLt2AT0bOi"},"source":["위에 보이는 것과 같이 tense에는 3개의 타입이 있으므로 3개의 컬럼들을 볼 수 있다. 그리고 각 컬럼에 해당될 확률이 어느정도인지 저장되어 있는 형태이다. 이때 같은 row에 위치한 값들을 더해보면"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B2uzs6L40bOi","outputId":"35ff1e16-f05a-4a21-fd54-0d174fda1c5b"},"outputs":[{"data":{"text/plain":["1.0000000124564394"]},"execution_count":185,"metadata":{},"output_type":"execute_result"}],"source":["sum(test_pred_tense[0])"]},{"cell_type":"markdown","metadata":{"id":"Ra-mgwtS0bOi"},"source":["1인것을 알 수 있다. 위에 softmax에서 설명한 그대로이다.\n","\n","따라서, 이제 이 값들을 np.argmax()를 통해서 어느 인덱스에 최고 값이 있는지 알아보고 그 인덱스에 맞춰서 맞는 label로 변형해줘야 한다.\n","그 후 저장하면 제출할 수 있는 파일이 만들어진다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6kr-xsyx0bOi"},"outputs":[],"source":["test_type = ['대화형' if i==0 else '사실형' if i==1 else '예측형' if i==2 else '추론형' for i in [np.argmax(p) for p in test_pred_type]]\n","test_polarity = ['긍정' if i==0 else '미정' if i==1 else '부정' for i in [np.argmax(p) for p in test_pred_polarity]]\n","test_tense = ['과거' if i==0 else '미래' if i==1 else '현재' for i in [np.argmax(p) for p in test_pred_tense]]\n","test_certainty = ['불확실' if i==0 else '확실' for i in [np.argmax(p) for p in test_pred_certainty]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oDmErskP0bOi"},"outputs":[],"source":["label_sum = []\n","for i in range(len(test_type)):\n","    label_sum.append(f'{test_type[i]}-{test_polarity[i]}-{test_tense[i]}-{test_certainty[i]}')\n","\n","submission['label'] = label_sum\n","submission.to_csv('submission/klue1.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WI87egOb0bOi","outputId":"d0f5bddc-529f-4525-e8d9-a0e83ddb79c8"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TEST_0000</td>\n","      <td>사실형-긍정-현재-확실</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TEST_0001</td>\n","      <td>사실형-긍정-현재-확실</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TEST_0002</td>\n","      <td>사실형-긍정-과거-확실</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TEST_0003</td>\n","      <td>사실형-긍정-과거-확실</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TEST_0004</td>\n","      <td>사실형-긍정-과거-확실</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7085</th>\n","      <td>TEST_7085</td>\n","      <td>사실형-긍정-현재-확실</td>\n","    </tr>\n","    <tr>\n","      <th>7086</th>\n","      <td>TEST_7086</td>\n","      <td>추론형-긍정-현재-확실</td>\n","    </tr>\n","    <tr>\n","      <th>7087</th>\n","      <td>TEST_7087</td>\n","      <td>사실형-긍정-미래-확실</td>\n","    </tr>\n","    <tr>\n","      <th>7088</th>\n","      <td>TEST_7088</td>\n","      <td>추론형-긍정-미래-확실</td>\n","    </tr>\n","    <tr>\n","      <th>7089</th>\n","      <td>TEST_7089</td>\n","      <td>사실형-긍정-과거-확실</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7090 rows × 2 columns</p>\n","</div>"],"text/plain":["             ID         label\n","0     TEST_0000  사실형-긍정-현재-확실\n","1     TEST_0001  사실형-긍정-현재-확실\n","2     TEST_0002  사실형-긍정-과거-확실\n","3     TEST_0003  사실형-긍정-과거-확실\n","4     TEST_0004  사실형-긍정-과거-확실\n","...         ...           ...\n","7085  TEST_7085  사실형-긍정-현재-확실\n","7086  TEST_7086  추론형-긍정-현재-확실\n","7087  TEST_7087  사실형-긍정-미래-확실\n","7088  TEST_7088  추론형-긍정-미래-확실\n","7089  TEST_7089  사실형-긍정-과거-확실\n","\n","[7090 rows x 2 columns]"]},"execution_count":186,"metadata":{},"output_type":"execute_result"}],"source":["submission"]},{"cell_type":"markdown","metadata":{"id":"x9aSewwq0bOi"},"source":["궁금한 부분이나 조언이 있다면 댓글에 남겨주세요"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.13 ('tf_env')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"1201aed7278f566d08684214e947d9aa97ba318061e22672851b23b6bee3a7a3"}},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"38c595c1895e4ef98bc462e7fa326694":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7fa81a44b1194ea3b966355bbde8ed25","IPY_MODEL_f7172bf8c4d241f5ac21c92a7d214a40","IPY_MODEL_ce7c498c94144fc0bed01993218bfae3"],"layout":"IPY_MODEL_c3d5c617eb7a4ba88b89c096902edb8c"}},"7fa81a44b1194ea3b966355bbde8ed25":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d12a0cb16d9a4aa5ae5422c88a34f4c0","placeholder":"​","style":"IPY_MODEL_6fb3d2f5f6434a578d2da1b07fa7c0a5","value":"Downloading (…)lve/main/config.json: 100%"}},"f7172bf8c4d241f5ac21c92a7d214a40":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_65fc8a54043b4d5f891e311deb1b81c2","max":545,"min":0,"orientation":"horizontal","style":"IPY_MODEL_148b5e32eed249b8901387cad050b8bd","value":545}},"ce7c498c94144fc0bed01993218bfae3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c3e9da9e4c54f2b86a3ccd5ff4e6592","placeholder":"​","style":"IPY_MODEL_ce7a415f5e90479aacea0c116e3c0210","value":" 545/545 [00:00&lt;00:00, 23.0kB/s]"}},"c3d5c617eb7a4ba88b89c096902edb8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d12a0cb16d9a4aa5ae5422c88a34f4c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fb3d2f5f6434a578d2da1b07fa7c0a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65fc8a54043b4d5f891e311deb1b81c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"148b5e32eed249b8901387cad050b8bd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7c3e9da9e4c54f2b86a3ccd5ff4e6592":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce7a415f5e90479aacea0c116e3c0210":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3168b02d357949988c3d0301a6c44eba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_35ae58439cfc4a4c85df319bfce4ec3b","IPY_MODEL_d26fa52660c94c40b3837e0ae450d34c","IPY_MODEL_21cf4b94d0ed43c3a5808e2c8833dd4b"],"layout":"IPY_MODEL_4035f6226c044800b903701c6e2f5b69"}},"35ae58439cfc4a4c85df319bfce4ec3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e52c00a914942eebbc3096f3647a252","placeholder":"​","style":"IPY_MODEL_c62bf76fbf02497097a0e5eea6f3ee38","value":"Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"}},"d26fa52660c94c40b3837e0ae450d34c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8e7b842f73a47db9859f6ccdd89f907","max":272545970,"min":0,"orientation":"horizontal","style":"IPY_MODEL_626cc6fcc44a48749c3e19a44df7101e","value":272545970}},"21cf4b94d0ed43c3a5808e2c8833dd4b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce413867e10b46c097cb90ef8f1f6b52","placeholder":"​","style":"IPY_MODEL_38cf2a2ad30442308b89809759a8c635","value":" 273M/273M [00:01&lt;00:00, 247MB/s]"}},"4035f6226c044800b903701c6e2f5b69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e52c00a914942eebbc3096f3647a252":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c62bf76fbf02497097a0e5eea6f3ee38":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8e7b842f73a47db9859f6ccdd89f907":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"626cc6fcc44a48749c3e19a44df7101e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ce413867e10b46c097cb90ef8f1f6b52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38cf2a2ad30442308b89809759a8c635":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed04d02aaf2441759271cd4da2e50662":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c53e63cdceab468885eb2292be9bbd96","IPY_MODEL_b4542c91db974723a641f7f2474b8382","IPY_MODEL_054a66f980e8403f82fcac0c94d559b6"],"layout":"IPY_MODEL_30bbd106a08f47c6b786ef205854364d"}},"c53e63cdceab468885eb2292be9bbd96":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9a13797fca649849afd8cf6015d414e","placeholder":"​","style":"IPY_MODEL_10634896bdfc4060b3d7afc1f8ed916b","value":"Downloading (…)okenizer_config.json: 100%"}},"b4542c91db974723a641f7f2474b8382":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_53613abaec4d44a68c95d665f2df8b5f","max":375,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3cf49fdb25954c31a3e6a76852c9b759","value":375}},"054a66f980e8403f82fcac0c94d559b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_467c7473d5384e07bf4e9b1f60a0cc04","placeholder":"​","style":"IPY_MODEL_9ef00f2b81574a5f9c11cc67e23e638e","value":" 375/375 [00:00&lt;00:00, 17.6kB/s]"}},"30bbd106a08f47c6b786ef205854364d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9a13797fca649849afd8cf6015d414e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10634896bdfc4060b3d7afc1f8ed916b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53613abaec4d44a68c95d665f2df8b5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cf49fdb25954c31a3e6a76852c9b759":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"467c7473d5384e07bf4e9b1f60a0cc04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ef00f2b81574a5f9c11cc67e23e638e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16c8521a29cb45beab61ef0146cd88fc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1b68464257df43b381af822615c96086","IPY_MODEL_9e358229407a40109fb679de2f4f9f73","IPY_MODEL_7346b92a033043b8abbaca8e5de5e0d0"],"layout":"IPY_MODEL_fb6413a472df4bc1a8232a3563813077"}},"1b68464257df43b381af822615c96086":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00e0507d2dde4e76a506c4a62883edbd","placeholder":"​","style":"IPY_MODEL_2e5713c265924e1882a0bea3eb4e013d","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"9e358229407a40109fb679de2f4f9f73":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad1e2b0e1daf4bad9f710d515192a282","max":248477,"min":0,"orientation":"horizontal","style":"IPY_MODEL_42ff018ce2854c038b1680acf15fe2c9","value":248477}},"7346b92a033043b8abbaca8e5de5e0d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_859f2d1ea0f441d3907400d3594d75c8","placeholder":"​","style":"IPY_MODEL_6bc1c3847c4745c499be5a04dd61ffe4","value":" 248k/248k [00:00&lt;00:00, 278kB/s]"}},"fb6413a472df4bc1a8232a3563813077":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00e0507d2dde4e76a506c4a62883edbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e5713c265924e1882a0bea3eb4e013d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad1e2b0e1daf4bad9f710d515192a282":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42ff018ce2854c038b1680acf15fe2c9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"859f2d1ea0f441d3907400d3594d75c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bc1c3847c4745c499be5a04dd61ffe4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34d5293e57084b1ab8c13f5d3cbda554":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f3e99f1faba14f06bdcaaff9c4b4a471","IPY_MODEL_31b2c0d286d94a1bbf24dd06f44947cd","IPY_MODEL_a5fa1936856f453b8e2f2d687f8e90ba"],"layout":"IPY_MODEL_b2558c60c7b144d9a9b538a22e8388ab"}},"f3e99f1faba14f06bdcaaff9c4b4a471":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4d467ff634c4f7ebcb69d7ecc3af1f0","placeholder":"​","style":"IPY_MODEL_b75b9c714e354189a1c7cb82176352c9","value":"Downloading (…)/main/tokenizer.json: 100%"}},"31b2c0d286d94a1bbf24dd06f44947cd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7695fe0750dd42a187338e9f8d49bd3b","max":751504,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d627736d83554deeaeed84b9bb4276e9","value":751504}},"a5fa1936856f453b8e2f2d687f8e90ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3e21d2cf4f04b5e88131ef4402becc1","placeholder":"​","style":"IPY_MODEL_364b6aae14514b599f3728c2be871bc5","value":" 752k/752k [00:01&lt;00:00, 676kB/s]"}},"b2558c60c7b144d9a9b538a22e8388ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4d467ff634c4f7ebcb69d7ecc3af1f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b75b9c714e354189a1c7cb82176352c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7695fe0750dd42a187338e9f8d49bd3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d627736d83554deeaeed84b9bb4276e9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b3e21d2cf4f04b5e88131ef4402becc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"364b6aae14514b599f3728c2be871bc5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a38d70c76184d7ab372360f45fb57ee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e52434da4e1e49acb03cf5a0c44b3f5f","IPY_MODEL_8bb4fd2895d94d6eb6d578415b0aff3d","IPY_MODEL_fc0c8ea8371f4a5ca9ae204134584078"],"layout":"IPY_MODEL_ed58ed4951144ba59e8ba8fd071aee12"}},"e52434da4e1e49acb03cf5a0c44b3f5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19a1389da8464d4081565d58ef9d33d8","placeholder":"​","style":"IPY_MODEL_f1976fc3276349cc8a5812eb76bc52de","value":"Downloading (…)cial_tokens_map.json: 100%"}},"8bb4fd2895d94d6eb6d578415b0aff3d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e59b8a92929549f7a1d98843582474b1","max":173,"min":0,"orientation":"horizontal","style":"IPY_MODEL_774e37e0d6d046e5afe8d2558631f2e0","value":173}},"fc0c8ea8371f4a5ca9ae204134584078":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8d3f693237b4257b23c7796f6e0a5b3","placeholder":"​","style":"IPY_MODEL_a5fe4c9ef3714bf780ae288f63e19771","value":" 173/173 [00:00&lt;00:00, 9.77kB/s]"}},"ed58ed4951144ba59e8ba8fd071aee12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19a1389da8464d4081565d58ef9d33d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1976fc3276349cc8a5812eb76bc52de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e59b8a92929549f7a1d98843582474b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"774e37e0d6d046e5afe8d2558631f2e0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f8d3f693237b4257b23c7796f6e0a5b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5fe4c9ef3714bf780ae288f63e19771":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}